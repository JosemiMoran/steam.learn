{
  "version": 3,
  "sources": ["../../../node_modules/hono/dist/utils/url.js", "../../../node_modules/hono/dist/utils/cookie.js", "../../../node_modules/hono/dist/utils/cookie.js", "../../../node_modules/hono/dist/utils/html.js", "../../../node_modules/hono/dist/utils/stream.js", "../../../node_modules/hono/dist/context.js", "../../../node_modules/hono/dist/compose.js", "../../../node_modules/hono/dist/http-exception.js", "../../../node_modules/hono/dist/utils/body.js", "../../../node_modules/hono/dist/request.js", "../../../node_modules/hono/dist/router.js", "../../../node_modules/hono/dist/hono-base.js", "../../../node_modules/hono/dist/router/reg-exp-router/node.js", "../../../node_modules/hono/dist/router/reg-exp-router/trie.js", "../../../node_modules/hono/dist/router/reg-exp-router/router.js", "../../../node_modules/hono/dist/router/smart-router/router.js", "../../../node_modules/hono/dist/router/trie-router/node.js", "../../../node_modules/hono/dist/router/trie-router/router.js", "../../../node_modules/hono/dist/hono.js", "../../../node_modules/hono/dist/middleware/pretty-json/index.js", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../../node_modules/@xata.io/client/dist/index.mjs", "../../db/src/xata.ts", "../src/users.ts", "../src/index.ts"],
  "sourcesContent": [
    "// src/utils/url.ts\nvar splitPath = (path) => {\n  const paths = path.split(\"/\");\n  if (paths[0] === \"\") {\n    paths.shift();\n  }\n  return paths;\n};\nvar splitRoutingPath = (path) => {\n  const groups = [];\n  for (let i = 0; ; ) {\n    let replaced = false;\n    path = path.replace(/\\{[^}]+\\}/g, (m) => {\n      const mark = `@\\\\${i}`;\n      groups[i] = [mark, m];\n      i++;\n      replaced = true;\n      return mark;\n    });\n    if (!replaced) {\n      break;\n    }\n  }\n  const paths = path.split(\"/\");\n  if (paths[0] === \"\") {\n    paths.shift();\n  }\n  for (let i = groups.length - 1; i >= 0; i--) {\n    const [mark] = groups[i];\n    for (let j = paths.length - 1; j >= 0; j--) {\n      if (paths[j].indexOf(mark) !== -1) {\n        paths[j] = paths[j].replace(mark, groups[i][1]);\n        break;\n      }\n    }\n  }\n  return paths;\n};\nvar patternCache = {};\nvar getPattern = (label) => {\n  if (label === \"*\") {\n    return \"*\";\n  }\n  const match = label.match(/^\\:([^\\{\\}]+)(?:\\{(.+)\\})?$/);\n  if (match) {\n    if (!patternCache[label]) {\n      if (match[2]) {\n        patternCache[label] = [label, match[1], new RegExp(\"^\" + match[2] + \"$\")];\n      } else {\n        patternCache[label] = [label, match[1], true];\n      }\n    }\n    return patternCache[label];\n  }\n  return null;\n};\nvar getPath = (request) => {\n  const match = request.url.match(/^https?:\\/\\/[^/]+(\\/[^?]*)/);\n  return match ? match[1] : \"\";\n};\nvar getQueryStrings = (url) => {\n  const queryIndex = url.indexOf(\"?\", 8);\n  return queryIndex === -1 ? \"\" : \"?\" + url.slice(queryIndex + 1);\n};\nvar getPathNoStrict = (request) => {\n  const result = getPath(request);\n  return result.length > 1 && result[result.length - 1] === \"/\" ? result.slice(0, -1) : result;\n};\nvar mergePath = (...paths) => {\n  let p = \"\";\n  let endsWithSlash = false;\n  for (let path of paths) {\n    if (p[p.length - 1] === \"/\") {\n      p = p.slice(0, -1);\n      endsWithSlash = true;\n    }\n    if (path[0] !== \"/\") {\n      path = `/${path}`;\n    }\n    if (path === \"/\" && endsWithSlash) {\n      p = `${p}/`;\n    } else if (path !== \"/\") {\n      p = `${p}${path}`;\n    }\n    if (path === \"/\" && p === \"\") {\n      p = \"/\";\n    }\n  }\n  return p;\n};\nvar checkOptionalParameter = (path) => {\n  const match = path.match(/^(.+|)(\\/\\:[^\\/]+)\\?$/);\n  if (!match)\n    return null;\n  const base = match[1];\n  const optional = base + match[2];\n  return [base === \"\" ? \"/\" : base.replace(/\\/$/, \"\"), optional];\n};\nvar _decodeURI = (value) => {\n  if (!/[%+]/.test(value)) {\n    return value;\n  }\n  if (value.indexOf(\"+\") !== -1) {\n    value = value.replace(/\\+/g, \" \");\n  }\n  return /%/.test(value) ? decodeURIComponent_(value) : value;\n};\nvar _getQueryParam = (url, key, multiple) => {\n  let encoded;\n  if (!multiple && key && !/[%+]/.test(key)) {\n    let keyIndex2 = url.indexOf(`?${key}`, 8);\n    if (keyIndex2 === -1) {\n      keyIndex2 = url.indexOf(`&${key}`, 8);\n    }\n    while (keyIndex2 !== -1) {\n      const trailingKeyCode = url.charCodeAt(keyIndex2 + key.length + 1);\n      if (trailingKeyCode === 61) {\n        const valueIndex = keyIndex2 + key.length + 2;\n        const endIndex = url.indexOf(\"&\", valueIndex);\n        return _decodeURI(url.slice(valueIndex, endIndex === -1 ? void 0 : endIndex));\n      } else if (trailingKeyCode == 38 || isNaN(trailingKeyCode)) {\n        return \"\";\n      }\n      keyIndex2 = url.indexOf(`&${key}`, keyIndex2 + 1);\n    }\n    encoded = /[%+]/.test(url);\n    if (!encoded) {\n      return void 0;\n    }\n  }\n  const results = {};\n  encoded ?? (encoded = /[%+]/.test(url));\n  let keyIndex = url.indexOf(\"?\", 8);\n  while (keyIndex !== -1) {\n    const nextKeyIndex = url.indexOf(\"&\", keyIndex + 1);\n    let valueIndex = url.indexOf(\"=\", keyIndex);\n    if (valueIndex > nextKeyIndex && nextKeyIndex !== -1) {\n      valueIndex = -1;\n    }\n    let name = url.slice(\n      keyIndex + 1,\n      valueIndex === -1 ? nextKeyIndex === -1 ? void 0 : nextKeyIndex : valueIndex\n    );\n    if (encoded) {\n      name = _decodeURI(name);\n    }\n    keyIndex = nextKeyIndex;\n    if (name === \"\") {\n      continue;\n    }\n    let value;\n    if (valueIndex === -1) {\n      value = \"\";\n    } else {\n      value = url.slice(valueIndex + 1, nextKeyIndex === -1 ? void 0 : nextKeyIndex);\n      if (encoded) {\n        value = _decodeURI(value);\n      }\n    }\n    if (multiple) {\n      if (!(results[name] && Array.isArray(results[name]))) {\n        results[name] = [];\n      }\n      ;\n      results[name].push(value);\n    } else {\n      results[name] ?? (results[name] = value);\n    }\n  }\n  return key ? results[key] : results;\n};\nvar getQueryParam = _getQueryParam;\nvar getQueryParams = (url, key) => {\n  return _getQueryParam(url, key, true);\n};\nvar decodeURIComponent_ = decodeURIComponent;\nexport {\n  checkOptionalParameter,\n  decodeURIComponent_,\n  getPath,\n  getPathNoStrict,\n  getPattern,\n  getQueryParam,\n  getQueryParams,\n  getQueryStrings,\n  mergePath,\n  splitPath,\n  splitRoutingPath\n};\n",
  "// src/utils/cookie.ts\nimport { decodeURIComponent_ } from \"./url.js\";\nvar algorithm = { name: \"HMAC\", hash: \"SHA-256\" };\nvar getCryptoKey = async (secret) => {\n  const secretBuf = typeof secret === \"string\" ? new TextEncoder().encode(secret) : secret;\n  return await crypto.subtle.importKey(\"raw\", secretBuf, algorithm, false, [\"sign\", \"verify\"]);\n};\nvar makeSignature = async (value, secret) => {\n  const key = await getCryptoKey(secret);\n  const signature = await crypto.subtle.sign(algorithm.name, key, new TextEncoder().encode(value));\n  return btoa(String.fromCharCode(...new Uint8Array(signature)));\n};\nvar verifySignature = async (base64Signature, value, secret) => {\n  try {\n    const signatureBinStr = atob(base64Signature);\n    const signature = new Uint8Array(signatureBinStr.length);\n    for (let i = 0; i < signatureBinStr.length; i++)\n      signature[i] = signatureBinStr.charCodeAt(i);\n    return await crypto.subtle.verify(algorithm, secret, signature, new TextEncoder().encode(value));\n  } catch (e) {\n    return false;\n  }\n};\nvar validCookieNameRegEx = /^[\\w!#$%&'*.^`|~+-]+$/;\nvar validCookieValueRegEx = /^[ !#-:<-[\\]-~]*$/;\nvar parse = (cookie, name) => {\n  const pairs = cookie.trim().split(\";\");\n  return pairs.reduce((parsedCookie, pairStr) => {\n    pairStr = pairStr.trim();\n    const valueStartPos = pairStr.indexOf(\"=\");\n    if (valueStartPos === -1)\n      return parsedCookie;\n    const cookieName = pairStr.substring(0, valueStartPos).trim();\n    if (name && name !== cookieName || !validCookieNameRegEx.test(cookieName))\n      return parsedCookie;\n    let cookieValue = pairStr.substring(valueStartPos + 1).trim();\n    if (cookieValue.startsWith('\"') && cookieValue.endsWith('\"'))\n      cookieValue = cookieValue.slice(1, -1);\n    if (validCookieValueRegEx.test(cookieValue))\n      parsedCookie[cookieName] = decodeURIComponent_(cookieValue);\n    return parsedCookie;\n  }, {});\n};\nvar parseSigned = async (cookie, secret, name) => {\n  const parsedCookie = {};\n  const secretKey = await getCryptoKey(secret);\n  for (const [key, value] of Object.entries(parse(cookie, name))) {\n    const signatureStartPos = value.lastIndexOf(\".\");\n    if (signatureStartPos < 1)\n      continue;\n    const signedValue = value.substring(0, signatureStartPos);\n    const signature = value.substring(signatureStartPos + 1);\n    if (signature.length !== 44 || !signature.endsWith(\"=\"))\n      continue;\n    const isVerified = await verifySignature(signature, signedValue, secretKey);\n    parsedCookie[key] = isVerified ? signedValue : false;\n  }\n  return parsedCookie;\n};\nvar _serialize = (name, value, opt = {}) => {\n  let cookie = `${name}=${value}`;\n  if (opt && typeof opt.maxAge === \"number\" && opt.maxAge >= 0) {\n    cookie += `; Max-Age=${Math.floor(opt.maxAge)}`;\n  }\n  if (opt.domain) {\n    cookie += `; Domain=${opt.domain}`;\n  }\n  if (opt.path) {\n    cookie += `; Path=${opt.path}`;\n  }\n  if (opt.expires) {\n    cookie += `; Expires=${opt.expires.toUTCString()}`;\n  }\n  if (opt.httpOnly) {\n    cookie += \"; HttpOnly\";\n  }\n  if (opt.secure) {\n    cookie += \"; Secure\";\n  }\n  if (opt.sameSite) {\n    cookie += `; SameSite=${opt.sameSite}`;\n  }\n  if (opt.partitioned) {\n    cookie += \"; Partitioned\";\n  }\n  return cookie;\n};\nvar serialize = (name, value, opt = {}) => {\n  value = encodeURIComponent(value);\n  return _serialize(name, value, opt);\n};\nvar serializeSigned = async (name, value, secret, opt = {}) => {\n  const signature = await makeSignature(value, secret);\n  value = `${value}.${signature}`;\n  value = encodeURIComponent(value);\n  return _serialize(name, value, opt);\n};\nexport {\n  parse,\n  parseSigned,\n  serialize,\n  serializeSigned\n};\n",
  "// src/utils/cookie.ts\nimport { decodeURIComponent_ } from \"./url.js\";\nvar algorithm = { name: \"HMAC\", hash: \"SHA-256\" };\nvar getCryptoKey = async (secret) => {\n  const secretBuf = typeof secret === \"string\" ? new TextEncoder().encode(secret) : secret;\n  return await crypto.subtle.importKey(\"raw\", secretBuf, algorithm, false, [\"sign\", \"verify\"]);\n};\nvar makeSignature = async (value, secret) => {\n  const key = await getCryptoKey(secret);\n  const signature = await crypto.subtle.sign(algorithm.name, key, new TextEncoder().encode(value));\n  return btoa(String.fromCharCode(...new Uint8Array(signature)));\n};\nvar verifySignature = async (base64Signature, value, secret) => {\n  try {\n    const signatureBinStr = atob(base64Signature);\n    const signature = new Uint8Array(signatureBinStr.length);\n    for (let i = 0; i < signatureBinStr.length; i++)\n      signature[i] = signatureBinStr.charCodeAt(i);\n    return await crypto.subtle.verify(algorithm, secret, signature, new TextEncoder().encode(value));\n  } catch (e) {\n    return false;\n  }\n};\nvar validCookieNameRegEx = /^[\\w!#$%&'*.^`|~+-]+$/;\nvar validCookieValueRegEx = /^[ !#-:<-[\\]-~]*$/;\nvar parse = (cookie, name) => {\n  const pairs = cookie.trim().split(\";\");\n  return pairs.reduce((parsedCookie, pairStr) => {\n    pairStr = pairStr.trim();\n    const valueStartPos = pairStr.indexOf(\"=\");\n    if (valueStartPos === -1)\n      return parsedCookie;\n    const cookieName = pairStr.substring(0, valueStartPos).trim();\n    if (name && name !== cookieName || !validCookieNameRegEx.test(cookieName))\n      return parsedCookie;\n    let cookieValue = pairStr.substring(valueStartPos + 1).trim();\n    if (cookieValue.startsWith('\"') && cookieValue.endsWith('\"'))\n      cookieValue = cookieValue.slice(1, -1);\n    if (validCookieValueRegEx.test(cookieValue))\n      parsedCookie[cookieName] = decodeURIComponent_(cookieValue);\n    return parsedCookie;\n  }, {});\n};\nvar parseSigned = async (cookie, secret, name) => {\n  const parsedCookie = {};\n  const secretKey = await getCryptoKey(secret);\n  for (const [key, value] of Object.entries(parse(cookie, name))) {\n    const signatureStartPos = value.lastIndexOf(\".\");\n    if (signatureStartPos < 1)\n      continue;\n    const signedValue = value.substring(0, signatureStartPos);\n    const signature = value.substring(signatureStartPos + 1);\n    if (signature.length !== 44 || !signature.endsWith(\"=\"))\n      continue;\n    const isVerified = await verifySignature(signature, signedValue, secretKey);\n    parsedCookie[key] = isVerified ? signedValue : false;\n  }\n  return parsedCookie;\n};\nvar _serialize = (name, value, opt = {}) => {\n  let cookie = `${name}=${value}`;\n  if (opt && typeof opt.maxAge === \"number\" && opt.maxAge >= 0) {\n    cookie += `; Max-Age=${Math.floor(opt.maxAge)}`;\n  }\n  if (opt.domain) {\n    cookie += `; Domain=${opt.domain}`;\n  }\n  if (opt.path) {\n    cookie += `; Path=${opt.path}`;\n  }\n  if (opt.expires) {\n    cookie += `; Expires=${opt.expires.toUTCString()}`;\n  }\n  if (opt.httpOnly) {\n    cookie += \"; HttpOnly\";\n  }\n  if (opt.secure) {\n    cookie += \"; Secure\";\n  }\n  if (opt.sameSite) {\n    cookie += `; SameSite=${opt.sameSite}`;\n  }\n  if (opt.partitioned) {\n    cookie += \"; Partitioned\";\n  }\n  return cookie;\n};\nvar serialize = (name, value, opt = {}) => {\n  value = encodeURIComponent(value);\n  return _serialize(name, value, opt);\n};\nvar serializeSigned = async (name, value, secret, opt = {}) => {\n  const signature = await makeSignature(value, secret);\n  value = `${value}.${signature}`;\n  value = encodeURIComponent(value);\n  return _serialize(name, value, opt);\n};\nexport {\n  parse,\n  parseSigned,\n  serialize,\n  serializeSigned\n};\n",
  "// src/utils/html.ts\nimport { raw } from \"../helper/html/index.js\";\nvar escapeRe = /[&<>'\"]/;\nvar stringBufferToString = async (buffer) => {\n  let str = \"\";\n  const callbacks = [];\n  for (let i = buffer.length - 1; ; i--) {\n    str += buffer[i];\n    i--;\n    if (i < 0) {\n      break;\n    }\n    let r = await buffer[i];\n    if (typeof r === \"object\") {\n      callbacks.push(...r.callbacks || []);\n    }\n    const isEscaped = r.isEscaped;\n    r = await (typeof r === \"object\" ? r.toString() : r);\n    if (typeof r === \"object\") {\n      callbacks.push(...r.callbacks || []);\n    }\n    if (r.isEscaped ?? isEscaped) {\n      str += r;\n    } else {\n      const buf = [str];\n      escapeToBuffer(r, buf);\n      str = buf[0];\n    }\n  }\n  return raw(str, callbacks);\n};\nvar escapeToBuffer = (str, buffer) => {\n  const match = str.search(escapeRe);\n  if (match === -1) {\n    buffer[0] += str;\n    return;\n  }\n  let escape;\n  let index;\n  let lastIndex = 0;\n  for (index = match; index < str.length; index++) {\n    switch (str.charCodeAt(index)) {\n      case 34:\n        escape = \"&quot;\";\n        break;\n      case 39:\n        escape = \"&#39;\";\n        break;\n      case 38:\n        escape = \"&amp;\";\n        break;\n      case 60:\n        escape = \"&lt;\";\n        break;\n      case 62:\n        escape = \"&gt;\";\n        break;\n      default:\n        continue;\n    }\n    buffer[0] += str.substring(lastIndex, index) + escape;\n    lastIndex = index + 1;\n  }\n  buffer[0] += str.substring(lastIndex, index);\n};\nvar resolveStream = (str, buffer) => {\n  if (!str.callbacks?.length) {\n    return Promise.resolve(str);\n  }\n  const callbacks = str.callbacks;\n  if (buffer) {\n    buffer[0] += str;\n  } else {\n    buffer = [str];\n  }\n  return Promise.all(callbacks.map((c) => c({ buffer }))).then(\n    (res) => Promise.all(res.map((str2) => resolveStream(str2, buffer))).then(() => buffer[0])\n  );\n};\nexport {\n  escapeToBuffer,\n  resolveStream,\n  stringBufferToString\n};\n",
  "// src/utils/stream.ts\nvar StreamingApi = class {\n  constructor(writable) {\n    this.writable = writable;\n    this.writer = writable.getWriter();\n    this.encoder = new TextEncoder();\n  }\n  async write(input) {\n    try {\n      if (typeof input === \"string\") {\n        input = this.encoder.encode(input);\n      }\n      await this.writer.write(input);\n    } catch (e) {\n    }\n    return this;\n  }\n  async writeln(input) {\n    await this.write(input + \"\\n\");\n    return this;\n  }\n  sleep(ms) {\n    return new Promise((res) => setTimeout(res, ms));\n  }\n  async close() {\n    try {\n      await this.writer.close();\n    } catch (e) {\n    }\n  }\n  async pipe(body) {\n    this.writer.releaseLock();\n    await body.pipeTo(this.writable, { preventClose: true });\n    this.writer = this.writable.getWriter();\n  }\n};\nexport {\n  StreamingApi\n};\n",
  "var __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\n\n// src/context.ts\nimport { serialize } from \"./utils/cookie.js\";\nimport { resolveStream } from \"./utils/html.js\";\nimport { StreamingApi } from \"./utils/stream.js\";\nvar TEXT_PLAIN = \"text/plain; charset=UTF-8\";\nvar _status, _executionCtx, _headers, _preparedHeaders, _res, _isFresh;\nvar Context = class {\n  constructor(req, options) {\n    this.env = {};\n    this._var = {};\n    this.finalized = false;\n    this.error = void 0;\n    __privateAdd(this, _status, 200);\n    __privateAdd(this, _executionCtx, void 0);\n    __privateAdd(this, _headers, void 0);\n    __privateAdd(this, _preparedHeaders, void 0);\n    __privateAdd(this, _res, void 0);\n    __privateAdd(this, _isFresh, true);\n    this.renderer = (content) => this.html(content);\n    this.notFoundHandler = () => new Response();\n    this.render = (...args) => this.renderer(...args);\n    this.setRenderer = (renderer) => {\n      this.renderer = renderer;\n    };\n    this.header = (name, value, options) => {\n      if (value === void 0) {\n        if (__privateGet(this, _headers)) {\n          __privateGet(this, _headers).delete(name);\n        } else if (__privateGet(this, _preparedHeaders)) {\n          delete __privateGet(this, _preparedHeaders)[name.toLocaleLowerCase()];\n        }\n        if (this.finalized) {\n          this.res.headers.delete(name);\n        }\n        return;\n      }\n      if (options?.append) {\n        if (!__privateGet(this, _headers)) {\n          __privateSet(this, _isFresh, false);\n          __privateSet(this, _headers, new Headers(__privateGet(this, _preparedHeaders)));\n          __privateSet(this, _preparedHeaders, {});\n        }\n        __privateGet(this, _headers).append(name, value);\n      } else {\n        if (__privateGet(this, _headers)) {\n          __privateGet(this, _headers).set(name, value);\n        } else {\n          __privateGet(this, _preparedHeaders) ?? __privateSet(this, _preparedHeaders, {});\n          __privateGet(this, _preparedHeaders)[name.toLowerCase()] = value;\n        }\n      }\n      if (this.finalized) {\n        if (options?.append) {\n          this.res.headers.append(name, value);\n        } else {\n          this.res.headers.set(name, value);\n        }\n      }\n    };\n    this.status = (status) => {\n      __privateSet(this, _isFresh, false);\n      __privateSet(this, _status, status);\n    };\n    this.set = (key, value) => {\n      this._var ?? (this._var = {});\n      this._var[key] = value;\n    };\n    this.get = (key) => {\n      return this._var ? this._var[key] : void 0;\n    };\n    this.newResponse = (data, arg, headers) => {\n      if (__privateGet(this, _isFresh) && !headers && !arg && __privateGet(this, _status) === 200) {\n        return new Response(data, {\n          headers: __privateGet(this, _preparedHeaders)\n        });\n      }\n      if (arg && typeof arg !== \"number\") {\n        this.res = new Response(data, arg);\n      }\n      const status = typeof arg === \"number\" ? arg : arg ? arg.status : __privateGet(this, _status);\n      __privateGet(this, _preparedHeaders) ?? __privateSet(this, _preparedHeaders, {});\n      __privateGet(this, _headers) ?? __privateSet(this, _headers, new Headers());\n      for (const [k, v] of Object.entries(__privateGet(this, _preparedHeaders))) {\n        __privateGet(this, _headers).set(k, v);\n      }\n      if (__privateGet(this, _res)) {\n        __privateGet(this, _res).headers.forEach((v, k) => {\n          __privateGet(this, _headers)?.set(k, v);\n        });\n        for (const [k, v] of Object.entries(__privateGet(this, _preparedHeaders))) {\n          __privateGet(this, _headers).set(k, v);\n        }\n      }\n      headers ?? (headers = {});\n      for (const [k, v] of Object.entries(headers)) {\n        if (typeof v === \"string\") {\n          __privateGet(this, _headers).set(k, v);\n        } else {\n          __privateGet(this, _headers).delete(k);\n          for (const v2 of v) {\n            __privateGet(this, _headers).append(k, v2);\n          }\n        }\n      }\n      return new Response(data, {\n        status,\n        headers: __privateGet(this, _headers)\n      });\n    };\n    this.body = (data, arg, headers) => {\n      return typeof arg === \"number\" ? this.newResponse(data, arg, headers) : this.newResponse(data, arg);\n    };\n    this.text = (text, arg, headers) => {\n      if (!__privateGet(this, _preparedHeaders)) {\n        if (__privateGet(this, _isFresh) && !headers && !arg) {\n          return new Response(text);\n        }\n        __privateSet(this, _preparedHeaders, {});\n      }\n      __privateGet(this, _preparedHeaders)[\"content-type\"] = TEXT_PLAIN;\n      return typeof arg === \"number\" ? this.newResponse(text, arg, headers) : this.newResponse(text, arg);\n    };\n    this.json = (object, arg, headers) => {\n      const body = JSON.stringify(object);\n      __privateGet(this, _preparedHeaders) ?? __privateSet(this, _preparedHeaders, {});\n      __privateGet(this, _preparedHeaders)[\"content-type\"] = \"application/json; charset=UTF-8\";\n      return typeof arg === \"number\" ? this.newResponse(body, arg, headers) : this.newResponse(body, arg);\n    };\n    this.jsonT = (object, arg, headers) => {\n      return this.json(object, arg, headers);\n    };\n    this.html = (html, arg, headers) => {\n      __privateGet(this, _preparedHeaders) ?? __privateSet(this, _preparedHeaders, {});\n      __privateGet(this, _preparedHeaders)[\"content-type\"] = \"text/html; charset=UTF-8\";\n      if (typeof html === \"object\") {\n        if (!(html instanceof Promise)) {\n          html = html.toString();\n        }\n        if (html instanceof Promise) {\n          return html.then((html2) => resolveStream(html2)).then((html2) => {\n            return typeof arg === \"number\" ? this.newResponse(html2, arg, headers) : this.newResponse(html2, arg);\n          });\n        }\n      }\n      return typeof arg === \"number\" ? this.newResponse(html, arg, headers) : this.newResponse(html, arg);\n    };\n    this.redirect = (location, status = 302) => {\n      __privateGet(this, _headers) ?? __privateSet(this, _headers, new Headers());\n      __privateGet(this, _headers).set(\"Location\", location);\n      return this.newResponse(null, status);\n    };\n    this.streamText = (cb, arg, headers) => {\n      headers ?? (headers = {});\n      this.header(\"content-type\", TEXT_PLAIN);\n      this.header(\"x-content-type-options\", \"nosniff\");\n      this.header(\"transfer-encoding\", \"chunked\");\n      return this.stream(cb, arg, headers);\n    };\n    this.stream = (cb, arg, headers) => {\n      const { readable, writable } = new TransformStream();\n      const stream = new StreamingApi(writable);\n      cb(stream).finally(() => stream.close());\n      return typeof arg === \"number\" ? this.newResponse(readable, arg, headers) : this.newResponse(readable, arg);\n    };\n    this.cookie = (name, value, opt) => {\n      const cookie = serialize(name, value, opt);\n      this.header(\"set-cookie\", cookie, { append: true });\n    };\n    this.notFound = () => {\n      return this.notFoundHandler(this);\n    };\n    this.req = req;\n    if (options) {\n      __privateSet(this, _executionCtx, options.executionCtx);\n      this.env = options.env;\n      if (options.notFoundHandler) {\n        this.notFoundHandler = options.notFoundHandler;\n      }\n    }\n  }\n  get event() {\n    if (__privateGet(this, _executionCtx) && \"respondWith\" in __privateGet(this, _executionCtx)) {\n      return __privateGet(this, _executionCtx);\n    } else {\n      throw Error(\"This context has no FetchEvent\");\n    }\n  }\n  get executionCtx() {\n    if (__privateGet(this, _executionCtx)) {\n      return __privateGet(this, _executionCtx);\n    } else {\n      throw Error(\"This context has no ExecutionContext\");\n    }\n  }\n  get res() {\n    __privateSet(this, _isFresh, false);\n    return __privateGet(this, _res) || __privateSet(this, _res, new Response(\"404 Not Found\", { status: 404 }));\n  }\n  set res(_res2) {\n    __privateSet(this, _isFresh, false);\n    if (__privateGet(this, _res) && _res2) {\n      __privateGet(this, _res).headers.delete(\"content-type\");\n      __privateGet(this, _res).headers.forEach((v, k) => {\n        _res2.headers.set(k, v);\n      });\n    }\n    __privateSet(this, _res, _res2);\n    this.finalized = true;\n  }\n  get var() {\n    return { ...this._var };\n  }\n  get runtime() {\n    const global = globalThis;\n    if (global?.Deno !== void 0) {\n      return \"deno\";\n    }\n    if (global?.Bun !== void 0) {\n      return \"bun\";\n    }\n    if (typeof global?.WebSocketPair === \"function\") {\n      return \"workerd\";\n    }\n    if (typeof global?.EdgeRuntime === \"string\") {\n      return \"edge-light\";\n    }\n    if (global?.fastly !== void 0) {\n      return \"fastly\";\n    }\n    if (global?.__lagon__ !== void 0) {\n      return \"lagon\";\n    }\n    if (global?.process?.release?.name === \"node\") {\n      return \"node\";\n    }\n    return \"other\";\n  }\n};\n_status = new WeakMap();\n_executionCtx = new WeakMap();\n_headers = new WeakMap();\n_preparedHeaders = new WeakMap();\n_res = new WeakMap();\n_isFresh = new WeakMap();\nexport {\n  Context\n};\n",
  "// src/compose.ts\nimport { Context } from \"./context.js\";\nvar compose = (middleware, onError, onNotFound) => {\n  return (context, next) => {\n    let index = -1;\n    return dispatch(0);\n    async function dispatch(i) {\n      if (i <= index) {\n        throw new Error(\"next() called multiple times\");\n      }\n      index = i;\n      let res;\n      let isError = false;\n      let handler;\n      if (middleware[i]) {\n        handler = middleware[i][0][0];\n        if (context instanceof Context) {\n          context.req.routeIndex = i;\n        }\n      } else {\n        handler = i === middleware.length && next || void 0;\n      }\n      if (!handler) {\n        if (context instanceof Context && context.finalized === false && onNotFound) {\n          res = await onNotFound(context);\n        }\n      } else {\n        try {\n          res = await handler(context, () => {\n            return dispatch(i + 1);\n          });\n        } catch (err) {\n          if (err instanceof Error && context instanceof Context && onError) {\n            context.error = err;\n            res = await onError(err, context);\n            isError = true;\n          } else {\n            throw err;\n          }\n        }\n      }\n      if (res && (context.finalized === false || isError)) {\n        context.res = res;\n      }\n      return context;\n    }\n  };\n};\nexport {\n  compose\n};\n",
  "// src/http-exception.ts\nvar HTTPException = class extends Error {\n  constructor(status = 500, options) {\n    super(options?.message);\n    this.res = options?.res;\n    this.status = status;\n  }\n  getResponse() {\n    if (this.res) {\n      return this.res;\n    }\n    return new Response(this.message, {\n      status: this.status\n    });\n  }\n};\nexport {\n  HTTPException\n};\n",
  "// src/utils/body.ts\nvar isArrayField = (value) => {\n  return Array.isArray(value);\n};\nvar parseBody = async (request, options = {\n  all: false\n}) => {\n  let body = {};\n  const contentType = request.headers.get(\"Content-Type\");\n  if (contentType && (contentType.startsWith(\"multipart/form-data\") || contentType.startsWith(\"application/x-www-form-urlencoded\"))) {\n    const formData = await request.formData();\n    if (formData) {\n      const form = {};\n      formData.forEach((value, key) => {\n        const shouldParseAllValues = options.all || key.slice(-2) === \"[]\";\n        if (!shouldParseAllValues) {\n          form[key] = value;\n          return;\n        }\n        if (form[key] && isArrayField(form[key])) {\n          ;\n          form[key].push(value);\n          return;\n        }\n        if (form[key]) {\n          form[key] = [form[key], value];\n          return;\n        }\n        form[key] = value;\n      });\n      body = form;\n    }\n  }\n  return body;\n};\nexport {\n  parseBody\n};\n",
  "var __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\n\n// src/request.ts\nimport { parseBody } from \"./utils/body.js\";\nimport { parse } from \"./utils/cookie.js\";\nimport { getQueryParam, getQueryParams, decodeURIComponent_ } from \"./utils/url.js\";\nvar _validatedData, _matchResult;\nvar HonoRequest = class {\n  constructor(request, path = \"/\", matchResult = [[]]) {\n    __privateAdd(this, _validatedData, void 0);\n    __privateAdd(this, _matchResult, void 0);\n    this.routeIndex = 0;\n    this.bodyCache = {};\n    this.cachedBody = (key) => {\n      const { bodyCache, raw } = this;\n      const cachedBody = bodyCache[key];\n      if (cachedBody)\n        return cachedBody;\n      if (bodyCache.arrayBuffer) {\n        return (async () => {\n          return await new Response(bodyCache.arrayBuffer)[key]();\n        })();\n      }\n      return bodyCache[key] = raw[key]();\n    };\n    this.raw = request;\n    this.path = path;\n    __privateSet(this, _matchResult, matchResult);\n    __privateSet(this, _validatedData, {});\n  }\n  param(key) {\n    if (key) {\n      const param = __privateGet(this, _matchResult)[1] ? __privateGet(this, _matchResult)[1][__privateGet(this, _matchResult)[0][this.routeIndex][1][key]] : __privateGet(this, _matchResult)[0][this.routeIndex][1][key];\n      return param ? /\\%/.test(param) ? decodeURIComponent_(param) : param : void 0;\n    } else {\n      const decoded = {};\n      const keys = Object.keys(__privateGet(this, _matchResult)[0][this.routeIndex][1]);\n      for (let i = 0, len = keys.length; i < len; i++) {\n        const key2 = keys[i];\n        const value = __privateGet(this, _matchResult)[1] ? __privateGet(this, _matchResult)[1][__privateGet(this, _matchResult)[0][this.routeIndex][1][key2]] : __privateGet(this, _matchResult)[0][this.routeIndex][1][key2];\n        if (value && typeof value === \"string\") {\n          decoded[key2] = /\\%/.test(value) ? decodeURIComponent_(value) : value;\n        }\n      }\n      return decoded;\n    }\n  }\n  query(key) {\n    return getQueryParam(this.url, key);\n  }\n  queries(key) {\n    return getQueryParams(this.url, key);\n  }\n  header(name) {\n    if (name)\n      return this.raw.headers.get(name.toLowerCase()) ?? void 0;\n    const headerData = {};\n    this.raw.headers.forEach((value, key) => {\n      headerData[key] = value;\n    });\n    return headerData;\n  }\n  cookie(key) {\n    const cookie = this.raw.headers.get(\"Cookie\");\n    if (!cookie)\n      return;\n    const obj = parse(cookie);\n    if (key) {\n      const value = obj[key];\n      return value;\n    } else {\n      return obj;\n    }\n  }\n  async parseBody(options) {\n    if (this.bodyCache.parsedBody)\n      return this.bodyCache.parsedBody;\n    const parsedBody = await parseBody(this, options);\n    this.bodyCache.parsedBody = parsedBody;\n    return parsedBody;\n  }\n  json() {\n    return this.cachedBody(\"json\");\n  }\n  text() {\n    return this.cachedBody(\"text\");\n  }\n  arrayBuffer() {\n    return this.cachedBody(\"arrayBuffer\");\n  }\n  blob() {\n    return this.cachedBody(\"blob\");\n  }\n  formData() {\n    return this.cachedBody(\"formData\");\n  }\n  addValidatedData(target, data) {\n    __privateGet(this, _validatedData)[target] = data;\n  }\n  valid(target) {\n    return __privateGet(this, _validatedData)[target];\n  }\n  get url() {\n    return this.raw.url;\n  }\n  get method() {\n    return this.raw.method;\n  }\n  get matchedRoutes() {\n    return __privateGet(this, _matchResult)[0].map(([[, route]]) => route);\n  }\n  get routePath() {\n    return __privateGet(this, _matchResult)[0].map(([[, route]]) => route)[this.routeIndex].path;\n  }\n  get headers() {\n    return this.raw.headers;\n  }\n  get body() {\n    return this.raw.body;\n  }\n  get bodyUsed() {\n    return this.raw.bodyUsed;\n  }\n  get integrity() {\n    return this.raw.integrity;\n  }\n  get keepalive() {\n    return this.raw.keepalive;\n  }\n  get referrer() {\n    return this.raw.referrer;\n  }\n  get signal() {\n    return this.raw.signal;\n  }\n};\n_validatedData = new WeakMap();\n_matchResult = new WeakMap();\nexport {\n  HonoRequest\n};\n",
  "// src/router.ts\nvar METHOD_NAME_ALL = \"ALL\";\nvar METHOD_NAME_ALL_LOWERCASE = \"all\";\nvar METHODS = [\"get\", \"post\", \"put\", \"delete\", \"options\", \"patch\"];\nvar MESSAGE_MATCHER_IS_ALREADY_BUILT = \"Can not add a route since the matcher is already built.\";\nvar UnsupportedPathError = class extends Error {\n};\nexport {\n  MESSAGE_MATCHER_IS_ALREADY_BUILT,\n  METHODS,\n  METHOD_NAME_ALL,\n  METHOD_NAME_ALL_LOWERCASE,\n  UnsupportedPathError\n};\n",
  "var __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\n\n// src/hono-base.ts\nimport { compose } from \"./compose.js\";\nimport { Context } from \"./context.js\";\nimport { HTTPException } from \"./http-exception.js\";\nimport { HonoRequest } from \"./request.js\";\nimport { METHOD_NAME_ALL, METHOD_NAME_ALL_LOWERCASE, METHODS } from \"./router.js\";\nimport { getPath, getPathNoStrict, getQueryStrings, mergePath } from \"./utils/url.js\";\nfunction defineDynamicClass() {\n  return class {\n  };\n}\nvar notFoundHandler = (c) => {\n  return c.text(\"404 Not Found\", 404);\n};\nvar errorHandler = (err, c) => {\n  if (err instanceof HTTPException) {\n    return err.getResponse();\n  }\n  console.error(err);\n  const message = \"Internal Server Error\";\n  return c.text(message, 500);\n};\nvar _path;\nvar _Hono = class extends defineDynamicClass() {\n  constructor(options = {}) {\n    super();\n    this._basePath = \"/\";\n    __privateAdd(this, _path, \"/\");\n    this.routes = [];\n    this.notFoundHandler = notFoundHandler;\n    this.errorHandler = errorHandler;\n    this.onError = (handler) => {\n      this.errorHandler = handler;\n      return this;\n    };\n    this.notFound = (handler) => {\n      this.notFoundHandler = handler;\n      return this;\n    };\n    this.head = () => {\n      console.warn(\"`app.head()` is no longer used. `app.get()` implicitly handles the HEAD method.\");\n      return this;\n    };\n    this.handleEvent = (event) => {\n      return this.dispatch(event.request, event, void 0, event.request.method);\n    };\n    this.fetch = (request, Env, executionCtx) => {\n      return this.dispatch(request, executionCtx, Env, request.method);\n    };\n    this.request = (input, requestInit, Env, executionCtx) => {\n      if (input instanceof Request) {\n        if (requestInit !== void 0) {\n          input = new Request(input, requestInit);\n        }\n        return this.fetch(input, Env, executionCtx);\n      }\n      input = input.toString();\n      const path = /^https?:\\/\\//.test(input) ? input : `http://localhost${mergePath(\"/\", input)}`;\n      const req = new Request(path, requestInit);\n      return this.fetch(req, Env, executionCtx);\n    };\n    this.fire = () => {\n      addEventListener(\"fetch\", (event) => {\n        event.respondWith(this.dispatch(event.request, event, void 0, event.request.method));\n      });\n    };\n    const allMethods = [...METHODS, METHOD_NAME_ALL_LOWERCASE];\n    allMethods.map((method) => {\n      this[method] = (args1, ...args) => {\n        if (typeof args1 === \"string\") {\n          __privateSet(this, _path, args1);\n        } else {\n          this.addRoute(method, __privateGet(this, _path), args1);\n        }\n        args.map((handler) => {\n          if (typeof handler !== \"string\") {\n            this.addRoute(method, __privateGet(this, _path), handler);\n          }\n        });\n        return this;\n      };\n    });\n    this.on = (method, path, ...handlers) => {\n      if (!method)\n        return this;\n      __privateSet(this, _path, path);\n      for (const m of [method].flat()) {\n        handlers.map((handler) => {\n          this.addRoute(m.toUpperCase(), __privateGet(this, _path), handler);\n        });\n      }\n      return this;\n    };\n    this.use = (arg1, ...handlers) => {\n      if (typeof arg1 === \"string\") {\n        __privateSet(this, _path, arg1);\n      } else {\n        handlers.unshift(arg1);\n      }\n      handlers.map((handler) => {\n        this.addRoute(METHOD_NAME_ALL, __privateGet(this, _path), handler);\n      });\n      return this;\n    };\n    const strict = options.strict ?? true;\n    delete options.strict;\n    Object.assign(this, options);\n    this.getPath = strict ? options.getPath ?? getPath : getPathNoStrict;\n  }\n  clone() {\n    const clone = new _Hono({\n      router: this.router,\n      getPath: this.getPath\n    });\n    clone.routes = this.routes;\n    return clone;\n  }\n  route(path, app) {\n    const subApp = this.basePath(path);\n    if (!app) {\n      return subApp;\n    }\n    app.routes.map((r) => {\n      const handler = app.errorHandler === errorHandler ? r.handler : async (c, next) => (await compose([], app.errorHandler)(c, () => r.handler(c, next))).res;\n      subApp.addRoute(r.method, r.path, handler);\n    });\n    return this;\n  }\n  basePath(path) {\n    const subApp = this.clone();\n    subApp._basePath = mergePath(this._basePath, path);\n    return subApp;\n  }\n  showRoutes() {\n    const length = 8;\n    this.routes.map((route) => {\n      console.log(\n        `\\x1B[32m${route.method}\\x1B[0m ${\" \".repeat(length - route.method.length)} ${route.path}`\n      );\n    });\n  }\n  mount(path, applicationHandler, optionHandler) {\n    const mergedPath = mergePath(this._basePath, path);\n    const pathPrefixLength = mergedPath === \"/\" ? 0 : mergedPath.length;\n    const handler = async (c, next) => {\n      let executionContext = void 0;\n      try {\n        executionContext = c.executionCtx;\n      } catch {\n      }\n      const options = optionHandler ? optionHandler(c) : [c.env, executionContext];\n      const optionsArray = Array.isArray(options) ? options : [options];\n      const queryStrings = getQueryStrings(c.req.url);\n      const res = await applicationHandler(\n        new Request(\n          new URL((c.req.path.slice(pathPrefixLength) || \"/\") + queryStrings, c.req.url),\n          c.req.raw\n        ),\n        ...optionsArray\n      );\n      if (res)\n        return res;\n      await next();\n    };\n    this.addRoute(METHOD_NAME_ALL, mergePath(path, \"*\"), handler);\n    return this;\n  }\n  get routerName() {\n    this.matchRoute(\"GET\", \"/\");\n    return this.router.name;\n  }\n  addRoute(method, path, handler) {\n    method = method.toUpperCase();\n    path = mergePath(this._basePath, path);\n    const r = { path, method, handler };\n    this.router.add(method, path, [handler, r]);\n    this.routes.push(r);\n  }\n  matchRoute(method, path) {\n    return this.router.match(method, path);\n  }\n  handleError(err, c) {\n    if (err instanceof Error) {\n      return this.errorHandler(err, c);\n    }\n    throw err;\n  }\n  dispatch(request, executionCtx, env, method) {\n    if (method === \"HEAD\") {\n      return (async () => new Response(null, await this.dispatch(request, executionCtx, env, \"GET\")))();\n    }\n    const path = this.getPath(request, { env });\n    const matchResult = this.matchRoute(method, path);\n    const c = new Context(new HonoRequest(request, path, matchResult), {\n      env,\n      executionCtx,\n      notFoundHandler: this.notFoundHandler\n    });\n    if (matchResult[0].length === 1) {\n      let res;\n      try {\n        res = matchResult[0][0][0][0](c, async () => {\n        });\n        if (!res) {\n          return this.notFoundHandler(c);\n        }\n      } catch (err) {\n        return this.handleError(err, c);\n      }\n      if (res instanceof Response)\n        return res;\n      return (async () => {\n        let awaited;\n        try {\n          awaited = await res;\n          if (!awaited) {\n            return this.notFoundHandler(c);\n          }\n        } catch (err) {\n          return this.handleError(err, c);\n        }\n        return awaited;\n      })();\n    }\n    const composed = compose(matchResult[0], this.errorHandler, this.notFoundHandler);\n    return (async () => {\n      try {\n        const context = await composed(c);\n        if (!context.finalized) {\n          throw new Error(\n            \"Context is not finalized. You may forget returning Response object or `await next()`\"\n          );\n        }\n        return context.res;\n      } catch (err) {\n        return this.handleError(err, c);\n      }\n    })();\n  }\n};\nvar Hono = _Hono;\n_path = new WeakMap();\nexport {\n  Hono as HonoBase\n};\n",
  "// src/router/reg-exp-router/node.ts\nvar LABEL_REG_EXP_STR = \"[^/]+\";\nvar ONLY_WILDCARD_REG_EXP_STR = \".*\";\nvar TAIL_WILDCARD_REG_EXP_STR = \"(?:|/.*)\";\nvar PATH_ERROR = Symbol();\nfunction compareKey(a, b) {\n  if (a.length === 1) {\n    return b.length === 1 ? a < b ? -1 : 1 : -1;\n  }\n  if (b.length === 1) {\n    return 1;\n  }\n  if (a === ONLY_WILDCARD_REG_EXP_STR || a === TAIL_WILDCARD_REG_EXP_STR) {\n    return 1;\n  } else if (b === ONLY_WILDCARD_REG_EXP_STR || b === TAIL_WILDCARD_REG_EXP_STR) {\n    return -1;\n  }\n  if (a === LABEL_REG_EXP_STR) {\n    return 1;\n  } else if (b === LABEL_REG_EXP_STR) {\n    return -1;\n  }\n  return a.length === b.length ? a < b ? -1 : 1 : b.length - a.length;\n}\nvar Node = class {\n  constructor() {\n    this.children = {};\n  }\n  insert(tokens, index, paramMap, context, pathErrorCheckOnly) {\n    if (tokens.length === 0) {\n      if (this.index !== void 0) {\n        throw PATH_ERROR;\n      }\n      if (pathErrorCheckOnly) {\n        return;\n      }\n      this.index = index;\n      return;\n    }\n    const [token, ...restTokens] = tokens;\n    const pattern = token === \"*\" ? restTokens.length === 0 ? [\"\", \"\", ONLY_WILDCARD_REG_EXP_STR] : [\"\", \"\", LABEL_REG_EXP_STR] : token === \"/*\" ? [\"\", \"\", TAIL_WILDCARD_REG_EXP_STR] : token.match(/^\\:([^\\{\\}]+)(?:\\{(.+)\\})?$/);\n    let node;\n    if (pattern) {\n      const name = pattern[1];\n      let regexpStr = pattern[2] || LABEL_REG_EXP_STR;\n      if (name && pattern[2]) {\n        regexpStr = regexpStr.replace(/^\\((?!\\?:)(?=[^)]+\\)$)/, \"(?:\");\n        if (/\\((?!\\?:)/.test(regexpStr)) {\n          throw PATH_ERROR;\n        }\n      }\n      node = this.children[regexpStr];\n      if (!node) {\n        if (Object.keys(this.children).some(\n          (k) => k !== ONLY_WILDCARD_REG_EXP_STR && k !== TAIL_WILDCARD_REG_EXP_STR\n        )) {\n          throw PATH_ERROR;\n        }\n        if (pathErrorCheckOnly) {\n          return;\n        }\n        node = this.children[regexpStr] = new Node();\n        if (name !== \"\") {\n          node.varIndex = context.varIndex++;\n        }\n      }\n      if (!pathErrorCheckOnly && name !== \"\") {\n        paramMap.push([name, node.varIndex]);\n      }\n    } else {\n      node = this.children[token];\n      if (!node) {\n        if (Object.keys(this.children).some(\n          (k) => k.length > 1 && k !== ONLY_WILDCARD_REG_EXP_STR && k !== TAIL_WILDCARD_REG_EXP_STR\n        )) {\n          throw PATH_ERROR;\n        }\n        if (pathErrorCheckOnly) {\n          return;\n        }\n        node = this.children[token] = new Node();\n      }\n    }\n    node.insert(restTokens, index, paramMap, context, pathErrorCheckOnly);\n  }\n  buildRegExpStr() {\n    const childKeys = Object.keys(this.children).sort(compareKey);\n    const strList = childKeys.map((k) => {\n      const c = this.children[k];\n      return (typeof c.varIndex === \"number\" ? `(${k})@${c.varIndex}` : k) + c.buildRegExpStr();\n    });\n    if (typeof this.index === \"number\") {\n      strList.unshift(`#${this.index}`);\n    }\n    if (strList.length === 0) {\n      return \"\";\n    }\n    if (strList.length === 1) {\n      return strList[0];\n    }\n    return \"(?:\" + strList.join(\"|\") + \")\";\n  }\n};\nexport {\n  Node,\n  PATH_ERROR\n};\n",
  "// src/router/reg-exp-router/trie.ts\nimport { Node } from \"./node.js\";\nvar Trie = class {\n  constructor() {\n    this.context = { varIndex: 0 };\n    this.root = new Node();\n  }\n  insert(path, index, pathErrorCheckOnly) {\n    const paramAssoc = [];\n    const groups = [];\n    for (let i = 0; ; ) {\n      let replaced = false;\n      path = path.replace(/\\{[^}]+\\}/g, (m) => {\n        const mark = `@\\\\${i}`;\n        groups[i] = [mark, m];\n        i++;\n        replaced = true;\n        return mark;\n      });\n      if (!replaced) {\n        break;\n      }\n    }\n    const tokens = path.match(/(?::[^\\/]+)|(?:\\/\\*$)|./g) || [];\n    for (let i = groups.length - 1; i >= 0; i--) {\n      const [mark] = groups[i];\n      for (let j = tokens.length - 1; j >= 0; j--) {\n        if (tokens[j].indexOf(mark) !== -1) {\n          tokens[j] = tokens[j].replace(mark, groups[i][1]);\n          break;\n        }\n      }\n    }\n    this.root.insert(tokens, index, paramAssoc, this.context, pathErrorCheckOnly);\n    return paramAssoc;\n  }\n  buildRegExp() {\n    let regexp = this.root.buildRegExpStr();\n    if (regexp === \"\") {\n      return [/^$/, [], []];\n    }\n    let captureIndex = 0;\n    const indexReplacementMap = [];\n    const paramReplacementMap = [];\n    regexp = regexp.replace(/#(\\d+)|@(\\d+)|\\.\\*\\$/g, (_, handlerIndex, paramIndex) => {\n      if (typeof handlerIndex !== \"undefined\") {\n        indexReplacementMap[++captureIndex] = Number(handlerIndex);\n        return \"$()\";\n      }\n      if (typeof paramIndex !== \"undefined\") {\n        paramReplacementMap[Number(paramIndex)] = ++captureIndex;\n        return \"\";\n      }\n      return \"\";\n    });\n    return [new RegExp(`^${regexp}`), indexReplacementMap, paramReplacementMap];\n  }\n};\nexport {\n  Trie\n};\n",
  "// src/router/reg-exp-router/router.ts\nimport {\n  METHOD_NAME_ALL,\n  METHODS,\n  UnsupportedPathError,\n  MESSAGE_MATCHER_IS_ALREADY_BUILT\n} from \"../../router.js\";\nimport { checkOptionalParameter } from \"../../utils/url.js\";\nimport { PATH_ERROR } from \"./node.js\";\nimport { Trie } from \"./trie.js\";\nvar methodNames = [METHOD_NAME_ALL, ...METHODS].map((method) => method.toUpperCase());\nvar emptyParam = [];\nvar nullMatcher = [/^$/, [], {}];\nvar wildcardRegExpCache = {};\nfunction buildWildcardRegExp(path) {\n  return wildcardRegExpCache[path] ?? (wildcardRegExpCache[path] = new RegExp(\n    path === \"*\" ? \"\" : `^${path.replace(/\\/\\*/, \"(?:|/.*)\")}$`\n  ));\n}\nfunction clearWildcardRegExpCache() {\n  wildcardRegExpCache = {};\n}\nfunction buildMatcherFromPreprocessedRoutes(routes) {\n  const trie = new Trie();\n  const handlerData = [];\n  if (routes.length === 0) {\n    return nullMatcher;\n  }\n  const routesWithStaticPathFlag = routes.map(\n    (route) => [!/\\*|\\/:/.test(route[0]), ...route]\n  ).sort(\n    ([isStaticA, pathA], [isStaticB, pathB]) => isStaticA ? 1 : isStaticB ? -1 : pathA.length - pathB.length\n  );\n  const staticMap = {};\n  for (let i = 0, j = -1, len = routesWithStaticPathFlag.length; i < len; i++) {\n    const [pathErrorCheckOnly, path, handlers] = routesWithStaticPathFlag[i];\n    if (pathErrorCheckOnly) {\n      staticMap[path] = [handlers.map(([h]) => [h, {}]), emptyParam];\n    } else {\n      j++;\n    }\n    let paramAssoc;\n    try {\n      paramAssoc = trie.insert(path, j, pathErrorCheckOnly);\n    } catch (e) {\n      throw e === PATH_ERROR ? new UnsupportedPathError(path) : e;\n    }\n    if (pathErrorCheckOnly) {\n      continue;\n    }\n    handlerData[j] = handlers.map(([h, paramCount]) => {\n      const paramIndexMap = {};\n      paramCount -= 1;\n      for (; paramCount >= 0; paramCount--) {\n        const [key, value] = paramAssoc[paramCount];\n        paramIndexMap[key] = value;\n      }\n      return [h, paramIndexMap];\n    });\n  }\n  const [regexp, indexReplacementMap, paramReplacementMap] = trie.buildRegExp();\n  for (let i = 0, len = handlerData.length; i < len; i++) {\n    for (let j = 0, len2 = handlerData[i].length; j < len2; j++) {\n      const map = handlerData[i][j]?.[1];\n      if (!map) {\n        continue;\n      }\n      const keys = Object.keys(map);\n      for (let k = 0, len3 = keys.length; k < len3; k++) {\n        map[keys[k]] = paramReplacementMap[map[keys[k]]];\n      }\n    }\n  }\n  const handlerMap = [];\n  for (const i in indexReplacementMap) {\n    handlerMap[i] = handlerData[indexReplacementMap[i]];\n  }\n  return [regexp, handlerMap, staticMap];\n}\nfunction findMiddleware(middleware, path) {\n  if (!middleware) {\n    return void 0;\n  }\n  for (const k of Object.keys(middleware).sort((a, b) => b.length - a.length)) {\n    if (buildWildcardRegExp(k).test(path)) {\n      return [...middleware[k]];\n    }\n  }\n  return void 0;\n}\nvar RegExpRouter = class {\n  constructor() {\n    this.name = \"RegExpRouter\";\n    this.middleware = { [METHOD_NAME_ALL]: {} };\n    this.routes = { [METHOD_NAME_ALL]: {} };\n  }\n  add(method, path, handler) {\n    var _a;\n    const { middleware, routes } = this;\n    if (!middleware || !routes) {\n      throw new Error(MESSAGE_MATCHER_IS_ALREADY_BUILT);\n    }\n    if (methodNames.indexOf(method) === -1)\n      methodNames.push(method);\n    if (!middleware[method]) {\n      ;\n      [middleware, routes].forEach((handlerMap) => {\n        handlerMap[method] = {};\n        Object.keys(handlerMap[METHOD_NAME_ALL]).forEach((p) => {\n          handlerMap[method][p] = [...handlerMap[METHOD_NAME_ALL][p]];\n        });\n      });\n    }\n    if (path === \"/*\") {\n      path = \"*\";\n    }\n    const paramCount = (path.match(/\\/:/g) || []).length;\n    if (/\\*$/.test(path)) {\n      const re = buildWildcardRegExp(path);\n      if (method === METHOD_NAME_ALL) {\n        Object.keys(middleware).forEach((m) => {\n          var _a2;\n          (_a2 = middleware[m])[path] || (_a2[path] = findMiddleware(middleware[m], path) || findMiddleware(middleware[METHOD_NAME_ALL], path) || []);\n        });\n      } else {\n        (_a = middleware[method])[path] || (_a[path] = findMiddleware(middleware[method], path) || findMiddleware(middleware[METHOD_NAME_ALL], path) || []);\n      }\n      Object.keys(middleware).forEach((m) => {\n        if (method === METHOD_NAME_ALL || method === m) {\n          Object.keys(middleware[m]).forEach((p) => {\n            re.test(p) && middleware[m][p].push([handler, paramCount]);\n          });\n        }\n      });\n      Object.keys(routes).forEach((m) => {\n        if (method === METHOD_NAME_ALL || method === m) {\n          Object.keys(routes[m]).forEach(\n            (p) => re.test(p) && routes[m][p].push([handler, paramCount])\n          );\n        }\n      });\n      return;\n    }\n    const paths = checkOptionalParameter(path) || [path];\n    for (let i = 0, len = paths.length; i < len; i++) {\n      const path2 = paths[i];\n      Object.keys(routes).forEach((m) => {\n        var _a2;\n        if (method === METHOD_NAME_ALL || method === m) {\n          (_a2 = routes[m])[path2] || (_a2[path2] = [\n            ...findMiddleware(middleware[m], path2) || findMiddleware(middleware[METHOD_NAME_ALL], path2) || []\n          ]);\n          routes[m][path2].push([\n            handler,\n            paths.length === 2 && i === 0 ? paramCount - 1 : paramCount\n          ]);\n        }\n      });\n    }\n  }\n  match(method, path) {\n    clearWildcardRegExpCache();\n    const matchers = this.buildAllMatchers();\n    this.match = (method2, path2) => {\n      const matcher = matchers[method2];\n      const staticMatch = matcher[2][path2];\n      if (staticMatch) {\n        return staticMatch;\n      }\n      const match = path2.match(matcher[0]);\n      if (!match) {\n        return [[], emptyParam];\n      }\n      const index = match.indexOf(\"\", 1);\n      return [matcher[1][index], match];\n    };\n    return this.match(method, path);\n  }\n  buildAllMatchers() {\n    const matchers = {};\n    methodNames.forEach((method) => {\n      matchers[method] = this.buildMatcher(method) || matchers[METHOD_NAME_ALL];\n    });\n    this.middleware = this.routes = void 0;\n    return matchers;\n  }\n  buildMatcher(method) {\n    const routes = [];\n    let hasOwnRoute = method === METHOD_NAME_ALL;\n    [this.middleware, this.routes].forEach((r) => {\n      const ownRoute = r[method] ? Object.keys(r[method]).map((path) => [path, r[method][path]]) : [];\n      if (ownRoute.length !== 0) {\n        hasOwnRoute || (hasOwnRoute = true);\n        routes.push(...ownRoute);\n      } else if (method !== METHOD_NAME_ALL) {\n        routes.push(\n          ...Object.keys(r[METHOD_NAME_ALL]).map((path) => [path, r[METHOD_NAME_ALL][path]])\n        );\n      }\n    });\n    if (!hasOwnRoute) {\n      return null;\n    } else {\n      return buildMatcherFromPreprocessedRoutes(routes);\n    }\n  }\n};\nexport {\n  RegExpRouter\n};\n",
  "// src/router/smart-router/router.ts\nimport { UnsupportedPathError, MESSAGE_MATCHER_IS_ALREADY_BUILT } from \"../../router.js\";\nvar SmartRouter = class {\n  constructor(init) {\n    this.name = \"SmartRouter\";\n    this.routers = [];\n    this.routes = [];\n    Object.assign(this, init);\n  }\n  add(method, path, handler) {\n    if (!this.routes) {\n      throw new Error(MESSAGE_MATCHER_IS_ALREADY_BUILT);\n    }\n    this.routes.push([method, path, handler]);\n  }\n  match(method, path) {\n    if (!this.routes) {\n      throw new Error(\"Fatal error\");\n    }\n    const { routers, routes } = this;\n    const len = routers.length;\n    let i = 0;\n    let res;\n    for (; i < len; i++) {\n      const router = routers[i];\n      try {\n        routes.forEach((args) => {\n          router.add(...args);\n        });\n        res = router.match(method, path);\n      } catch (e) {\n        if (e instanceof UnsupportedPathError) {\n          continue;\n        }\n        throw e;\n      }\n      this.match = router.match.bind(router);\n      this.routers = [router];\n      this.routes = void 0;\n      break;\n    }\n    if (i === len) {\n      throw new Error(\"Fatal error\");\n    }\n    this.name = `SmartRouter + ${this.activeRouter.name}`;\n    return res;\n  }\n  get activeRouter() {\n    if (this.routes || this.routers.length !== 1) {\n      throw new Error(\"No active router has been determined yet.\");\n    }\n    return this.routers[0];\n  }\n};\nexport {\n  SmartRouter\n};\n",
  "// src/router/trie-router/node.ts\nimport { METHOD_NAME_ALL } from \"../../router.js\";\nimport { splitPath, splitRoutingPath, getPattern } from \"../../utils/url.js\";\nvar Node = class {\n  constructor(method, handler, children) {\n    this.order = 0;\n    this.params = {};\n    this.children = children || {};\n    this.methods = [];\n    this.name = \"\";\n    if (method && handler) {\n      const m = {};\n      m[method] = { handler, possibleKeys: [], score: 0, name: this.name };\n      this.methods = [m];\n    }\n    this.patterns = [];\n  }\n  insert(method, path, handler) {\n    this.name = `${method} ${path}`;\n    this.order = ++this.order;\n    let curNode = this;\n    const parts = splitRoutingPath(path);\n    const possibleKeys = [];\n    const parentPatterns = [];\n    for (let i = 0, len = parts.length; i < len; i++) {\n      const p = parts[i];\n      if (Object.keys(curNode.children).includes(p)) {\n        parentPatterns.push(...curNode.patterns);\n        curNode = curNode.children[p];\n        const pattern2 = getPattern(p);\n        if (pattern2)\n          possibleKeys.push(pattern2[1]);\n        continue;\n      }\n      curNode.children[p] = new Node();\n      const pattern = getPattern(p);\n      if (pattern) {\n        curNode.patterns.push(pattern);\n        parentPatterns.push(...curNode.patterns);\n        possibleKeys.push(pattern[1]);\n      }\n      parentPatterns.push(...curNode.patterns);\n      curNode = curNode.children[p];\n    }\n    if (!curNode.methods.length) {\n      curNode.methods = [];\n    }\n    const m = {};\n    const handlerSet = {\n      handler,\n      possibleKeys,\n      name: this.name,\n      score: this.order\n    };\n    m[method] = handlerSet;\n    curNode.methods.push(m);\n    return curNode;\n  }\n  gHSets(node, method, params) {\n    const handlerSets = [];\n    for (let i = 0, len = node.methods.length; i < len; i++) {\n      const m = node.methods[i];\n      const handlerSet = m[method] || m[METHOD_NAME_ALL];\n      if (handlerSet !== void 0) {\n        handlerSet.params = {};\n        handlerSet.possibleKeys.map((key) => {\n          handlerSet.params[key] = params[key];\n        });\n        handlerSets.push(handlerSet);\n      }\n    }\n    return handlerSets;\n  }\n  search(method, path) {\n    const handlerSets = [];\n    const params = {};\n    this.params = {};\n    const curNode = this;\n    let curNodes = [curNode];\n    const parts = splitPath(path);\n    for (let i = 0, len = parts.length; i < len; i++) {\n      const part = parts[i];\n      const isLast = i === len - 1;\n      const tempNodes = [];\n      for (let j = 0, len2 = curNodes.length; j < len2; j++) {\n        const node = curNodes[j];\n        const nextNode = node.children[part];\n        if (nextNode) {\n          nextNode.params = node.params;\n          if (isLast === true) {\n            if (nextNode.children[\"*\"]) {\n              handlerSets.push(...this.gHSets(nextNode.children[\"*\"], method, node.params));\n            }\n            handlerSets.push(...this.gHSets(nextNode, method, node.params));\n          } else {\n            tempNodes.push(nextNode);\n          }\n        }\n        for (let k = 0, len3 = node.patterns.length; k < len3; k++) {\n          const pattern = node.patterns[k];\n          if (pattern === \"*\") {\n            const astNode = node.children[\"*\"];\n            if (astNode) {\n              handlerSets.push(...this.gHSets(astNode, method, node.params));\n              tempNodes.push(astNode);\n            }\n            continue;\n          }\n          if (part === \"\")\n            continue;\n          const [key, name, matcher] = pattern;\n          const child = node.children[key];\n          const restPathString = parts.slice(i).join(\"/\");\n          if (matcher instanceof RegExp && matcher.test(restPathString)) {\n            params[name] = restPathString;\n            handlerSets.push(...this.gHSets(child, method, { ...params, ...node.params }));\n            continue;\n          }\n          if (matcher === true || matcher instanceof RegExp && matcher.test(part)) {\n            if (typeof key === \"string\") {\n              params[name] = part;\n              if (isLast === true) {\n                handlerSets.push(...this.gHSets(child, method, { ...params, ...node.params }));\n                if (child.children[\"*\"]) {\n                  handlerSets.push(\n                    ...this.gHSets(child.children[\"*\"], method, { ...params, ...node.params })\n                  );\n                }\n              } else {\n                child.params = { ...params };\n                tempNodes.push(child);\n              }\n            }\n          }\n        }\n      }\n      curNodes = tempNodes;\n    }\n    const results = handlerSets.sort((a, b) => {\n      return a.score - b.score;\n    });\n    return [results.map(({ handler, params: params2 }) => [handler, params2])];\n  }\n};\nexport {\n  Node\n};\n",
  "// src/router/trie-router/router.ts\nimport { checkOptionalParameter } from \"../../utils/url.js\";\nimport { Node } from \"./node.js\";\nvar TrieRouter = class {\n  constructor() {\n    this.name = \"TrieRouter\";\n    this.node = new Node();\n  }\n  add(method, path, handler) {\n    const results = checkOptionalParameter(path);\n    if (results) {\n      for (const p of results) {\n        this.node.insert(method, p, handler);\n      }\n      return;\n    }\n    this.node.insert(method, path, handler);\n  }\n  match(method, path) {\n    return this.node.search(method, path);\n  }\n};\nexport {\n  TrieRouter\n};\n",
  "// src/hono.ts\nimport { HonoBase } from \"./hono-base.js\";\nimport { RegExpRouter } from \"./router/reg-exp-router/index.js\";\nimport { SmartRouter } from \"./router/smart-router/index.js\";\nimport { TrieRouter } from \"./router/trie-router/index.js\";\nvar Hono = class extends HonoBase {\n  constructor(options = {}) {\n    super(options);\n    this.router = options.router ?? new SmartRouter({\n      routers: [new RegExpRouter(), new TrieRouter()]\n    });\n  }\n};\nexport {\n  Hono\n};\n",
  "// src/middleware/pretty-json/index.ts\nvar prettyJSON = (options = { space: 2 }) => {\n  return async function prettyJSON2(c, next) {\n    const pretty = c.req.query(\"pretty\") || c.req.query(\"pretty\") === \"\" ? true : false;\n    await next();\n    if (pretty && c.res.headers.get(\"Content-Type\")?.startsWith(\"application/json\")) {\n      const obj = await c.res.json();\n      c.res = new Response(JSON.stringify(obj, null, options.space), c.res);\n    }\n  };\n};\nexport {\n  prettyJSON\n};\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "const defaultTrace = async (name, fn, _options) => {\n  return await fn({\n    name,\n    setAttributes: () => {\n      return;\n    }\n  });\n};\nconst TraceAttributes = {\n  KIND: \"xata.trace.kind\",\n  VERSION: \"xata.sdk.version\",\n  TABLE: \"xata.table\",\n  HTTP_REQUEST_ID: \"http.request_id\",\n  HTTP_STATUS_CODE: \"http.status_code\",\n  HTTP_HOST: \"http.host\",\n  HTTP_SCHEME: \"http.scheme\",\n  HTTP_USER_AGENT: \"http.user_agent\",\n  HTTP_METHOD: \"http.method\",\n  HTTP_URL: \"http.url\",\n  HTTP_ROUTE: \"http.route\",\n  HTTP_TARGET: \"http.target\",\n  CLOUDFLARE_RAY_ID: \"cf.ray\"\n};\n\nfunction notEmpty(value) {\n  return value !== null && value !== void 0;\n}\nfunction compact(arr) {\n  return arr.filter(notEmpty);\n}\nfunction compactObject(obj) {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => notEmpty(value)));\n}\nfunction isBlob(value) {\n  try {\n    return value instanceof Blob;\n  } catch (error) {\n    return false;\n  }\n}\nfunction isObject(value) {\n  return Boolean(value) && typeof value === \"object\" && !Array.isArray(value) && !(value instanceof Date) && !isBlob(value);\n}\nfunction isDefined(value) {\n  return value !== null && value !== void 0;\n}\nfunction isString(value) {\n  return isDefined(value) && typeof value === \"string\";\n}\nfunction isStringArray(value) {\n  return isDefined(value) && Array.isArray(value) && value.every(isString);\n}\nfunction isNumber(value) {\n  return isDefined(value) && typeof value === \"number\";\n}\nfunction parseNumber(value) {\n  if (isNumber(value)) {\n    return value;\n  }\n  if (isString(value)) {\n    const parsed = Number(value);\n    if (!Number.isNaN(parsed)) {\n      return parsed;\n    }\n  }\n  return void 0;\n}\nfunction toBase64(value) {\n  try {\n    return btoa(value);\n  } catch (err) {\n    const buf = Buffer;\n    return buf.from(value).toString(\"base64\");\n  }\n}\nfunction deepMerge(a, b) {\n  const result = { ...a };\n  for (const [key, value] of Object.entries(b)) {\n    if (isObject(value) && isObject(result[key])) {\n      result[key] = deepMerge(result[key], value);\n    } else {\n      result[key] = value;\n    }\n  }\n  return result;\n}\nfunction chunk(array, chunkSize) {\n  const result = [];\n  for (let i = 0; i < array.length; i += chunkSize) {\n    result.push(array.slice(i, i + chunkSize));\n  }\n  return result;\n}\nasync function timeout(ms) {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n}\nfunction timeoutWithCancel(ms) {\n  let timeoutId;\n  const promise = new Promise((resolve) => {\n    timeoutId = setTimeout(() => {\n      resolve();\n    }, ms);\n  });\n  return {\n    cancel: () => clearTimeout(timeoutId),\n    promise\n  };\n}\nfunction promiseMap(inputValues, mapper) {\n  const reducer = (acc$, inputValue) => acc$.then(\n    (acc) => mapper(inputValue).then((result) => {\n      acc.push(result);\n      return acc;\n    })\n  );\n  return inputValues.reduce(reducer, Promise.resolve([]));\n}\n\nfunction getEnvironment() {\n  try {\n    if (isDefined(process) && isDefined(process.env)) {\n      return {\n        apiKey: process.env.XATA_API_KEY ?? getGlobalApiKey(),\n        databaseURL: process.env.XATA_DATABASE_URL ?? getGlobalDatabaseURL(),\n        branch: process.env.XATA_BRANCH ?? getGlobalBranch(),\n        deployPreview: process.env.XATA_PREVIEW,\n        deployPreviewBranch: process.env.XATA_PREVIEW_BRANCH,\n        vercelGitCommitRef: process.env.VERCEL_GIT_COMMIT_REF,\n        vercelGitRepoOwner: process.env.VERCEL_GIT_REPO_OWNER\n      };\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env)) {\n      return {\n        apiKey: Deno.env.get(\"XATA_API_KEY\") ?? getGlobalApiKey(),\n        databaseURL: Deno.env.get(\"XATA_DATABASE_URL\") ?? getGlobalDatabaseURL(),\n        branch: Deno.env.get(\"XATA_BRANCH\") ?? getGlobalBranch(),\n        deployPreview: Deno.env.get(\"XATA_PREVIEW\"),\n        deployPreviewBranch: Deno.env.get(\"XATA_PREVIEW_BRANCH\"),\n        vercelGitCommitRef: Deno.env.get(\"VERCEL_GIT_COMMIT_REF\"),\n        vercelGitRepoOwner: Deno.env.get(\"VERCEL_GIT_REPO_OWNER\")\n      };\n    }\n  } catch (err) {\n  }\n  return {\n    apiKey: getGlobalApiKey(),\n    databaseURL: getGlobalDatabaseURL(),\n    branch: getGlobalBranch(),\n    deployPreview: void 0,\n    deployPreviewBranch: void 0,\n    vercelGitCommitRef: void 0,\n    vercelGitRepoOwner: void 0\n  };\n}\nfunction getEnableBrowserVariable() {\n  try {\n    if (isObject(process) && isObject(process.env) && process.env.XATA_ENABLE_BROWSER !== void 0) {\n      return process.env.XATA_ENABLE_BROWSER === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    if (isObject(Deno) && isObject(Deno.env) && Deno.env.get(\"XATA_ENABLE_BROWSER\") !== void 0) {\n      return Deno.env.get(\"XATA_ENABLE_BROWSER\") === \"true\";\n    }\n  } catch (err) {\n  }\n  try {\n    return XATA_ENABLE_BROWSER === true || XATA_ENABLE_BROWSER === \"true\";\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalApiKey() {\n  try {\n    return XATA_API_KEY;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalDatabaseURL() {\n  try {\n    return XATA_DATABASE_URL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getGlobalBranch() {\n  try {\n    return XATA_BRANCH;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getDatabaseURL() {\n  try {\n    const { databaseURL } = getEnvironment();\n    return databaseURL;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getAPIKey() {\n  try {\n    const { apiKey } = getEnvironment();\n    return apiKey;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction getBranch() {\n  try {\n    const { branch } = getEnvironment();\n    return branch;\n  } catch (err) {\n    return void 0;\n  }\n}\nfunction buildPreviewBranchName({ org, branch }) {\n  return `preview-${org}-${branch}`;\n}\nfunction getPreviewBranch() {\n  try {\n    const { deployPreview, deployPreviewBranch, vercelGitCommitRef, vercelGitRepoOwner } = getEnvironment();\n    if (deployPreviewBranch)\n      return deployPreviewBranch;\n    switch (deployPreview) {\n      case \"vercel\": {\n        if (!vercelGitCommitRef || !vercelGitRepoOwner) {\n          console.warn(\"XATA_PREVIEW=vercel but VERCEL_GIT_COMMIT_REF or VERCEL_GIT_REPO_OWNER is not valid\");\n          return void 0;\n        }\n        return buildPreviewBranchName({ org: vercelGitRepoOwner, branch: vercelGitCommitRef });\n      }\n    }\n    return void 0;\n  } catch (err) {\n    return void 0;\n  }\n}\n\nvar __accessCheck$8 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$8 = (obj, member, getter) => {\n  __accessCheck$8(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$8 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$8 = (obj, member, value, setter) => {\n  __accessCheck$8(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$4 = (obj, member, method) => {\n  __accessCheck$8(obj, member, \"access private method\");\n  return method;\n};\nvar _fetch, _queue, _concurrency, _enqueue, enqueue_fn;\nconst REQUEST_TIMEOUT = 5 * 60 * 1e3;\nfunction getFetchImplementation(userFetch) {\n  const globalFetch = typeof fetch !== \"undefined\" ? fetch : void 0;\n  const globalThisFetch = typeof globalThis !== \"undefined\" ? globalThis.fetch : void 0;\n  const fetchImpl = userFetch ?? globalFetch ?? globalThisFetch;\n  if (!fetchImpl) {\n    throw new Error(`Couldn't find a global \\`fetch\\`. Pass a fetch implementation explicitly.`);\n  }\n  return fetchImpl;\n}\nclass ApiRequestPool {\n  constructor(concurrency = 10) {\n    __privateAdd$8(this, _enqueue);\n    __privateAdd$8(this, _fetch, void 0);\n    __privateAdd$8(this, _queue, void 0);\n    __privateAdd$8(this, _concurrency, void 0);\n    __privateSet$8(this, _queue, []);\n    __privateSet$8(this, _concurrency, concurrency);\n    this.running = 0;\n    this.started = 0;\n  }\n  setFetch(fetch2) {\n    __privateSet$8(this, _fetch, fetch2);\n  }\n  getFetch() {\n    if (!__privateGet$8(this, _fetch)) {\n      throw new Error(\"Fetch not set\");\n    }\n    return __privateGet$8(this, _fetch);\n  }\n  request(url, options) {\n    const start = /* @__PURE__ */ new Date();\n    const fetchImpl = this.getFetch();\n    const runRequest = async (stalled = false) => {\n      const { promise, cancel } = timeoutWithCancel(REQUEST_TIMEOUT);\n      const response = await Promise.race([fetchImpl(url, options), promise.then(() => null)]).finally(cancel);\n      if (!response) {\n        throw new Error(\"Request timed out\");\n      }\n      if (response.status === 429) {\n        const rateLimitReset = parseNumber(response.headers?.get(\"x-ratelimit-reset\")) ?? 1;\n        await timeout(rateLimitReset * 1e3);\n        return await runRequest(true);\n      }\n      if (stalled) {\n        const stalledTime = (/* @__PURE__ */ new Date()).getTime() - start.getTime();\n        console.warn(`A request to Xata hit branch rate limits, was retried and stalled for ${stalledTime}ms`);\n      }\n      return response;\n    };\n    return __privateMethod$4(this, _enqueue, enqueue_fn).call(this, async () => {\n      return await runRequest();\n    });\n  }\n}\n_fetch = new WeakMap();\n_queue = new WeakMap();\n_concurrency = new WeakMap();\n_enqueue = new WeakSet();\nenqueue_fn = function(task) {\n  const promise = new Promise((resolve) => __privateGet$8(this, _queue).push(resolve)).finally(() => {\n    this.started--;\n    this.running++;\n  }).then(() => task()).finally(() => {\n    this.running--;\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  });\n  if (this.running + this.started < __privateGet$8(this, _concurrency)) {\n    const next = __privateGet$8(this, _queue).shift();\n    if (next !== void 0) {\n      this.started++;\n      next();\n    }\n  }\n  return promise;\n};\n\nfunction generateUUID() {\n  return \"xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\".replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0, v = c == \"x\" ? r : r & 3 | 8;\n    return v.toString(16);\n  });\n}\n\nasync function getBytes(stream, onChunk) {\n  const reader = stream.getReader();\n  let result;\n  while (!(result = await reader.read()).done) {\n    onChunk(result.value);\n  }\n}\nfunction getLines(onLine) {\n  let buffer;\n  let position;\n  let fieldLength;\n  let discardTrailingNewline = false;\n  return function onChunk(arr) {\n    if (buffer === void 0) {\n      buffer = arr;\n      position = 0;\n      fieldLength = -1;\n    } else {\n      buffer = concat(buffer, arr);\n    }\n    const bufLength = buffer.length;\n    let lineStart = 0;\n    while (position < bufLength) {\n      if (discardTrailingNewline) {\n        if (buffer[position] === 10 /* NewLine */) {\n          lineStart = ++position;\n        }\n        discardTrailingNewline = false;\n      }\n      let lineEnd = -1;\n      for (; position < bufLength && lineEnd === -1; ++position) {\n        switch (buffer[position]) {\n          case 58 /* Colon */:\n            if (fieldLength === -1) {\n              fieldLength = position - lineStart;\n            }\n            break;\n          case 13 /* CarriageReturn */:\n            discardTrailingNewline = true;\n          case 10 /* NewLine */:\n            lineEnd = position;\n            break;\n        }\n      }\n      if (lineEnd === -1) {\n        break;\n      }\n      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n      lineStart = position;\n      fieldLength = -1;\n    }\n    if (lineStart === bufLength) {\n      buffer = void 0;\n    } else if (lineStart !== 0) {\n      buffer = buffer.subarray(lineStart);\n      position -= lineStart;\n    }\n  };\n}\nfunction getMessages(onId, onRetry, onMessage) {\n  let message = newMessage();\n  const decoder = new TextDecoder();\n  return function onLine(line, fieldLength) {\n    if (line.length === 0) {\n      onMessage?.(message);\n      message = newMessage();\n    } else if (fieldLength > 0) {\n      const field = decoder.decode(line.subarray(0, fieldLength));\n      const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* Space */ ? 2 : 1);\n      const value = decoder.decode(line.subarray(valueOffset));\n      switch (field) {\n        case \"data\":\n          message.data = message.data ? message.data + \"\\n\" + value : value;\n          break;\n        case \"event\":\n          message.event = value;\n          break;\n        case \"id\":\n          onId(message.id = value);\n          break;\n        case \"retry\":\n          const retry = parseInt(value, 10);\n          if (!isNaN(retry)) {\n            onRetry(message.retry = retry);\n          }\n          break;\n      }\n    }\n  };\n}\nfunction concat(a, b) {\n  const res = new Uint8Array(a.length + b.length);\n  res.set(a);\n  res.set(b, a.length);\n  return res;\n}\nfunction newMessage() {\n  return {\n    data: \"\",\n    event: \"\",\n    id: \"\",\n    retry: void 0\n  };\n}\nconst EventStreamContentType = \"text/event-stream\";\nconst LastEventId = \"last-event-id\";\nfunction fetchEventSource(input, {\n  signal: inputSignal,\n  headers: inputHeaders,\n  onopen: inputOnOpen,\n  onmessage,\n  onclose,\n  onerror,\n  fetch: inputFetch,\n  ...rest\n}) {\n  return new Promise((resolve, reject) => {\n    const headers = { ...inputHeaders };\n    if (!headers.accept) {\n      headers.accept = EventStreamContentType;\n    }\n    let curRequestController;\n    function dispose() {\n      curRequestController.abort();\n    }\n    inputSignal?.addEventListener(\"abort\", () => {\n      dispose();\n      resolve();\n    });\n    const fetchImpl = inputFetch ?? fetch;\n    const onopen = inputOnOpen ?? defaultOnOpen;\n    async function create() {\n      curRequestController = new AbortController();\n      try {\n        const response = await fetchImpl(input, {\n          ...rest,\n          headers,\n          signal: curRequestController.signal\n        });\n        await onopen(response);\n        await getBytes(\n          response.body,\n          getLines(\n            getMessages(\n              (id) => {\n                if (id) {\n                  headers[LastEventId] = id;\n                } else {\n                  delete headers[LastEventId];\n                }\n              },\n              (_retry) => {\n              },\n              onmessage\n            )\n          )\n        );\n        onclose?.();\n        dispose();\n        resolve();\n      } catch (err) {\n      }\n    }\n    create();\n  });\n}\nfunction defaultOnOpen(response) {\n  const contentType = response.headers?.get(\"content-type\");\n  if (!contentType?.startsWith(EventStreamContentType)) {\n    throw new Error(`Expected content-type to be ${EventStreamContentType}, Actual: ${contentType}`);\n  }\n}\n\nconst VERSION = \"0.28.3\";\n\nclass ErrorWithCause extends Error {\n  constructor(message, options) {\n    super(message, options);\n  }\n}\nclass FetcherError extends ErrorWithCause {\n  constructor(status, data, requestId) {\n    super(getMessage(data));\n    this.status = status;\n    this.errors = isBulkError(data) ? data.errors : [{ message: getMessage(data), status }];\n    this.requestId = requestId;\n    if (data instanceof Error) {\n      this.stack = data.stack;\n      this.cause = data.cause;\n    }\n  }\n  toString() {\n    const error = super.toString();\n    return `[${this.status}] (${this.requestId ?? \"Unknown\"}): ${error}`;\n  }\n}\nfunction isBulkError(error) {\n  return isObject(error) && Array.isArray(error.errors);\n}\nfunction isErrorWithMessage(error) {\n  return isObject(error) && isString(error.message);\n}\nfunction getMessage(data) {\n  if (data instanceof Error) {\n    return data.message;\n  } else if (isString(data)) {\n    return data;\n  } else if (isErrorWithMessage(data)) {\n    return data.message;\n  } else if (isBulkError(data)) {\n    return \"Bulk operation failed\";\n  } else {\n    return \"Unexpected error\";\n  }\n}\n\nfunction getHostUrl(provider, type) {\n  if (isHostProviderAlias(provider)) {\n    return providers[provider][type];\n  } else if (isHostProviderBuilder(provider)) {\n    return provider[type];\n  }\n  throw new Error(\"Invalid API provider\");\n}\nconst providers = {\n  production: {\n    main: \"https://api.xata.io\",\n    workspaces: \"https://{workspaceId}.{region}.xata.sh\"\n  },\n  staging: {\n    main: \"https://api.staging-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.staging-xata.dev\"\n  },\n  dev: {\n    main: \"https://api.dev-xata.dev\",\n    workspaces: \"https://{workspaceId}.{region}.dev-xata.dev\"\n  }\n};\nfunction isHostProviderAlias(alias) {\n  return isString(alias) && Object.keys(providers).includes(alias);\n}\nfunction isHostProviderBuilder(builder) {\n  return isObject(builder) && isString(builder.main) && isString(builder.workspaces);\n}\nfunction parseProviderString(provider = \"production\") {\n  if (isHostProviderAlias(provider)) {\n    return provider;\n  }\n  const [main, workspaces] = provider.split(\",\");\n  if (!main || !workspaces)\n    return null;\n  return { main, workspaces };\n}\nfunction buildProviderString(provider) {\n  if (isHostProviderAlias(provider))\n    return provider;\n  return `${provider.main},${provider.workspaces}`;\n}\nfunction parseWorkspacesUrlParts(url) {\n  if (!isString(url))\n    return null;\n  const matches = {\n    production: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.xata\\.sh.*/),\n    staging: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.staging-xata\\.dev.*/),\n    dev: url.match(/(?:https:\\/\\/)?([^.]+)(?:\\.([^.]+))\\.dev-xata\\.dev.*/)\n  };\n  const [host, match] = Object.entries(matches).find(([, match2]) => match2 !== null) ?? [];\n  if (!isHostProviderAlias(host) || !match)\n    return null;\n  return { workspace: match[1], region: match[2], host };\n}\n\nconst pool = new ApiRequestPool();\nconst resolveUrl = (url, queryParams = {}, pathParams = {}) => {\n  const cleanQueryParams = Object.entries(queryParams).reduce((acc, [key, value]) => {\n    if (value === void 0 || value === null)\n      return acc;\n    return { ...acc, [key]: value };\n  }, {});\n  const query = new URLSearchParams(cleanQueryParams).toString();\n  const queryString = query.length > 0 ? `?${query}` : \"\";\n  const cleanPathParams = Object.entries(pathParams).reduce((acc, [key, value]) => {\n    return { ...acc, [key]: encodeURIComponent(String(value ?? \"\")).replace(\"%3A\", \":\") };\n  }, {});\n  return url.replace(/\\{\\w*\\}/g, (key) => cleanPathParams[key.slice(1, -1)]) + queryString;\n};\nfunction buildBaseUrl({\n  method,\n  endpoint,\n  path,\n  workspacesApiUrl,\n  apiUrl,\n  pathParams = {}\n}) {\n  if (endpoint === \"dataPlane\") {\n    let url = isString(workspacesApiUrl) ? `${workspacesApiUrl}${path}` : workspacesApiUrl(path, pathParams);\n    if (method.toUpperCase() === \"PUT\" && [\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n      \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\"\n    ].includes(path)) {\n      const { host } = parseWorkspacesUrlParts(url) ?? {};\n      switch (host) {\n        case \"production\":\n          url = url.replace(\"xata.sh\", \"upload.xata.sh\");\n          break;\n        case \"staging\":\n          url = url.replace(\"staging-xata.dev\", \"upload.staging-xata.dev\");\n          break;\n        case \"dev\":\n          url = url.replace(\"dev-xata.dev\", \"upload.dev-xata.dev\");\n          break;\n      }\n    }\n    const urlWithWorkspace = isString(pathParams.workspace) ? url.replace(\"{workspaceId}\", String(pathParams.workspace)) : url;\n    return isString(pathParams.region) ? urlWithWorkspace.replace(\"{region}\", String(pathParams.region)) : urlWithWorkspace;\n  }\n  return `${apiUrl}${path}`;\n}\nfunction hostHeader(url) {\n  const pattern = /.*:\\/\\/(?<host>[^/]+).*/;\n  const { groups } = pattern.exec(url) ?? {};\n  return groups?.host ? { Host: groups.host } : {};\n}\nasync function parseBody(body, headers) {\n  if (!isDefined(body))\n    return void 0;\n  if (isBlob(body) || typeof body.text === \"function\") {\n    return body;\n  }\n  const { \"Content-Type\": contentType } = headers ?? {};\n  if (String(contentType).toLowerCase() === \"application/json\" && isObject(body)) {\n    return JSON.stringify(body);\n  }\n  return body;\n}\nconst defaultClientID = generateUUID();\nasync function fetch$1({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  trace,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra,\n  fetchOptions = {},\n  rawResponse = false\n}) {\n  pool.setFetch(fetch2);\n  return await trace(\n    `${method.toUpperCase()} ${path}`,\n    async ({ setAttributes }) => {\n      const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n      const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n      const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n      setAttributes({\n        [TraceAttributes.HTTP_URL]: url,\n        [TraceAttributes.HTTP_TARGET]: resolveUrl(path, queryParams, pathParams)\n      });\n      const xataAgent = compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \");\n      const headers = compactObject({\n        \"Accept-Encoding\": \"identity\",\n        \"Content-Type\": \"application/json\",\n        \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n        \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n        \"X-Xata-Agent\": xataAgent,\n        ...customHeaders,\n        ...hostHeader(fullUrl),\n        Authorization: `Bearer ${apiKey}`\n      });\n      const response = await pool.request(url, {\n        ...fetchOptions,\n        method: method.toUpperCase(),\n        body: await parseBody(body, headers),\n        headers,\n        signal\n      });\n      const { host, protocol } = parseUrl(response.url);\n      const requestId = response.headers?.get(\"x-request-id\") ?? void 0;\n      setAttributes({\n        [TraceAttributes.KIND]: \"http\",\n        [TraceAttributes.HTTP_REQUEST_ID]: requestId,\n        [TraceAttributes.HTTP_STATUS_CODE]: response.status,\n        [TraceAttributes.HTTP_HOST]: host,\n        [TraceAttributes.HTTP_SCHEME]: protocol?.replace(\":\", \"\"),\n        [TraceAttributes.CLOUDFLARE_RAY_ID]: response.headers?.get(\"cf-ray\") ?? void 0\n      });\n      const message = response.headers?.get(\"x-xata-message\");\n      if (message)\n        console.warn(message);\n      if (response.status === 204) {\n        return {};\n      }\n      if (response.status === 429) {\n        throw new FetcherError(response.status, \"Rate limit exceeded\", requestId);\n      }\n      try {\n        const jsonResponse = rawResponse ? await response.blob() : await response.json();\n        if (response.ok) {\n          return jsonResponse;\n        }\n        throw new FetcherError(response.status, jsonResponse, requestId);\n      } catch (error) {\n        throw new FetcherError(response.status, error, requestId);\n      }\n    },\n    { [TraceAttributes.HTTP_METHOD]: method.toUpperCase(), [TraceAttributes.HTTP_ROUTE]: path }\n  );\n}\nfunction fetchSSERequest({\n  url: path,\n  method,\n  body,\n  headers: customHeaders,\n  pathParams,\n  queryParams,\n  fetch: fetch2,\n  apiKey,\n  endpoint,\n  apiUrl,\n  workspacesApiUrl,\n  onMessage,\n  onError,\n  onClose,\n  signal,\n  clientID,\n  sessionID,\n  clientName,\n  xataAgentExtra\n}) {\n  const baseUrl = buildBaseUrl({ method, endpoint, path, workspacesApiUrl, pathParams, apiUrl });\n  const fullUrl = resolveUrl(baseUrl, queryParams, pathParams);\n  const url = fullUrl.includes(\"localhost\") ? fullUrl.replace(/^[^.]+\\./, \"http://\") : fullUrl;\n  void fetchEventSource(url, {\n    method,\n    body: JSON.stringify(body),\n    fetch: fetch2,\n    signal,\n    headers: {\n      \"X-Xata-Client-ID\": clientID ?? defaultClientID,\n      \"X-Xata-Session-ID\": sessionID ?? generateUUID(),\n      \"X-Xata-Agent\": compact([\n        [\"client\", \"TS_SDK\"],\n        [\"version\", VERSION],\n        isDefined(clientName) ? [\"service\", clientName] : void 0,\n        ...Object.entries(xataAgentExtra ?? {})\n      ]).map(([key, value]) => `${key}=${value}`).join(\"; \"),\n      ...customHeaders,\n      Authorization: `Bearer ${apiKey}`,\n      \"Content-Type\": \"application/json\"\n    },\n    onmessage(ev) {\n      onMessage?.(JSON.parse(ev.data));\n    },\n    onerror(ev) {\n      onError?.(JSON.parse(ev.data));\n    },\n    onclose() {\n      onClose?.();\n    }\n  });\n}\nfunction parseUrl(url) {\n  try {\n    const { host, protocol } = new URL(url);\n    return { host, protocol };\n  } catch (error) {\n    return {};\n  }\n}\n\nconst dataPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"dataPlane\" });\n\nconst applyMigration = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/pgroll/apply\", method: \"post\", ...variables, signal });\nconst pgRollStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/status\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst pgRollJobStatus = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/pgroll/jobs/{jobId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchList = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchDetails = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createBranch = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}\", method: \"put\", ...variables, signal });\nconst deleteBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst copyBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/copy\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst updateBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst getBranchMetadata = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/metadata\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getBranchStats = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/stats\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst getGitBranchesMapping = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"get\", ...variables, signal });\nconst addGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"post\", ...variables, signal });\nconst removeGitBranchesEntry = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/gitBranches\", method: \"delete\", ...variables, signal });\nconst resolveBranch = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/resolveBranch\", method: \"get\", ...variables, signal });\nconst getBranchMigrationHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations\", method: \"get\", ...variables, signal });\nconst getBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/plan\", method: \"post\", ...variables, signal });\nconst executeBranchMigrationPlan = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/migrations/execute\", method: \"post\", ...variables, signal });\nconst queryMigrationRequests = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/query\", method: \"post\", ...variables, signal });\nconst createMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations\", method: \"post\", ...variables, signal });\nconst getMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}\", method: \"patch\", ...variables, signal });\nconst listMigrationRequestsCommits = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/commits\", method: \"post\", ...variables, signal });\nconst compareMigrationRequest = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/compare\", method: \"post\", ...variables, signal });\nconst getMigrationRequestIsMerged = (variables, signal) => dataPlaneFetch({ url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\", method: \"get\", ...variables, signal });\nconst mergeMigrationRequest = (variables, signal) => dataPlaneFetch({\n  url: \"/dbs/{dbName}/migrations/{mrNumber}/merge\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getBranchSchemaHistory = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/history\", method: \"post\", ...variables, signal });\nconst compareBranchWithUserSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare\", method: \"post\", ...variables, signal });\nconst compareBranchSchemas = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/compare/{branchName}\", method: \"post\", ...variables, signal });\nconst updateBranchSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/update\", method: \"post\", ...variables, signal });\nconst previewBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/preview\", method: \"post\", ...variables, signal });\nconst applyBranchSchemaEdit = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/apply\", method: \"post\", ...variables, signal });\nconst pushBranchMigrations = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/schema/push\", method: \"post\", ...variables, signal });\nconst createTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}\", method: \"patch\", ...variables, signal });\nconst getTableSchema = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/schema\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst setTableSchema = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/schema\", method: \"put\", ...variables, signal });\nconst getTableColumns = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst addTableColumn = (variables, signal) => dataPlaneFetch(\n  { url: \"/db/{dbBranchName}/tables/{tableName}/columns\", method: \"post\", ...variables, signal }\n);\nconst getColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateColumn = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\", method: \"patch\", ...variables, signal });\nconst deleteColumn = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/columns/{columnName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst branchTransaction = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/transaction\", method: \"post\", ...variables, signal });\nconst insertRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data\", method: \"post\", ...variables, signal });\nconst getFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFileItem = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file/{fileId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst putFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteFile = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}/column/{columnName}/file\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getRecord = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst insertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"put\", ...variables, signal });\nconst updateRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"patch\", ...variables, signal });\nconst upsertRecordWithID = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"post\", ...variables, signal });\nconst deleteRecord = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/data/{recordId}\", method: \"delete\", ...variables, signal });\nconst bulkInsertTableRecords = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/bulk\", method: \"post\", ...variables, signal });\nconst queryTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/query\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchBranch = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst searchTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/search\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst vectorSearchTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/vectorSearch\", method: \"post\", ...variables, signal });\nconst askTable = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/tables/{tableName}/ask\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst askTableSession = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\", method: \"post\", ...variables, signal });\nconst summarizeTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/summarize\", method: \"post\", ...variables, signal });\nconst aggregateTable = (variables, signal) => dataPlaneFetch({ url: \"/db/{dbBranchName}/tables/{tableName}/aggregate\", method: \"post\", ...variables, signal });\nconst fileAccess = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst fileUpload = (variables, signal) => dataPlaneFetch({\n  url: \"/file/{fileId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst sqlQuery = (variables, signal) => dataPlaneFetch({\n  url: \"/db/{dbBranchName}/sql\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst operationsByTag$2 = {\n  branch: {\n    applyMigration,\n    pgRollStatus,\n    pgRollJobStatus,\n    getBranchList,\n    getBranchDetails,\n    createBranch,\n    deleteBranch,\n    copyBranch,\n    updateBranchMetadata,\n    getBranchMetadata,\n    getBranchStats,\n    getGitBranchesMapping,\n    addGitBranchesEntry,\n    removeGitBranchesEntry,\n    resolveBranch\n  },\n  migrations: {\n    getSchema,\n    getBranchMigrationHistory,\n    getBranchMigrationPlan,\n    executeBranchMigrationPlan,\n    getBranchSchemaHistory,\n    compareBranchWithUserSchema,\n    compareBranchSchemas,\n    updateBranchSchema,\n    previewBranchSchemaEdit,\n    applyBranchSchemaEdit,\n    pushBranchMigrations\n  },\n  migrationRequests: {\n    queryMigrationRequests,\n    createMigrationRequest,\n    getMigrationRequest,\n    updateMigrationRequest,\n    listMigrationRequestsCommits,\n    compareMigrationRequest,\n    getMigrationRequestIsMerged,\n    mergeMigrationRequest\n  },\n  table: {\n    createTable,\n    deleteTable,\n    updateTable,\n    getTableSchema,\n    setTableSchema,\n    getTableColumns,\n    addTableColumn,\n    getColumn,\n    updateColumn,\n    deleteColumn\n  },\n  records: {\n    branchTransaction,\n    insertRecord,\n    getRecord,\n    insertRecordWithID,\n    updateRecordWithID,\n    upsertRecordWithID,\n    deleteRecord,\n    bulkInsertTableRecords\n  },\n  files: { getFileItem, putFileItem, deleteFileItem, getFile, putFile, deleteFile, fileAccess, fileUpload },\n  searchAndFilter: {\n    queryTable,\n    searchBranch,\n    searchTable,\n    vectorSearchTable,\n    askTable,\n    askTableSession,\n    summarizeTable,\n    aggregateTable\n  },\n  sql: { sqlQuery }\n};\n\nconst controlPlaneFetch = async (options) => fetch$1({ ...options, endpoint: \"controlPlane\" });\n\nconst getAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"get\", ...variables, signal });\nconst grantAuthorizationCode = (variables, signal) => controlPlaneFetch({ url: \"/oauth/authorize\", method: \"post\", ...variables, signal });\nconst getUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteUser = (variables, signal) => controlPlaneFetch({\n  url: \"/user\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserAPIKeys = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst deleteUserAPIKey = (variables, signal) => controlPlaneFetch({\n  url: \"/user/keys/{keyName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthClients = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteUserOAuthClient = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/clients/{clientId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getUserOAuthAccessTokens = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst deleteOAuthAccessToken = (variables, signal) => controlPlaneFetch({\n  url: \"/user/oauth/tokens/{token}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst updateOAuthAccessToken = (variables, signal) => controlPlaneFetch({ url: \"/user/oauth/tokens/{token}\", method: \"patch\", ...variables, signal });\nconst getWorkspacesList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces\",\n  method: \"post\",\n  ...variables,\n  signal\n});\nconst getWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"put\",\n  ...variables,\n  signal\n});\nconst deleteWorkspace = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getWorkspaceMembersList = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members\", method: \"get\", ...variables, signal });\nconst updateWorkspaceMemberRole = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/members/{userId}\", method: \"put\", ...variables, signal });\nconst removeWorkspaceMember = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/members/{userId}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst inviteWorkspaceMember = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites\", method: \"post\", ...variables, signal });\nconst updateWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"patch\", ...variables, signal });\nconst cancelWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}\", method: \"delete\", ...variables, signal });\nconst acceptWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteKey}/accept\", method: \"post\", ...variables, signal });\nconst resendWorkspaceMemberInvite = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/invites/{inviteId}/resend\", method: \"post\", ...variables, signal });\nconst listClusters = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters\", method: \"post\", ...variables, signal });\nconst getCluster = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/clusters/{clusterId}\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst updateCluster = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/clusters/{clusterId}\", method: \"patch\", ...variables, signal });\nconst getDatabaseList = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst createDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"put\", ...variables, signal });\nconst deleteDatabase = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/dbs/{dbName}\",\n  method: \"delete\",\n  ...variables,\n  signal\n});\nconst getDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"get\", ...variables, signal });\nconst updateDatabaseMetadata = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}\", method: \"patch\", ...variables, signal });\nconst renameDatabase = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/rename\", method: \"post\", ...variables, signal });\nconst getDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"get\", ...variables, signal });\nconst updateDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"put\", ...variables, signal });\nconst deleteDatabaseGithubSettings = (variables, signal) => controlPlaneFetch({ url: \"/workspaces/{workspaceId}/dbs/{dbName}/github\", method: \"delete\", ...variables, signal });\nconst listRegions = (variables, signal) => controlPlaneFetch({\n  url: \"/workspaces/{workspaceId}/regions\",\n  method: \"get\",\n  ...variables,\n  signal\n});\nconst operationsByTag$1 = {\n  oAuth: {\n    getAuthorizationCode,\n    grantAuthorizationCode,\n    getUserOAuthClients,\n    deleteUserOAuthClient,\n    getUserOAuthAccessTokens,\n    deleteOAuthAccessToken,\n    updateOAuthAccessToken\n  },\n  users: { getUser, updateUser, deleteUser },\n  authentication: { getUserAPIKeys, createUserAPIKey, deleteUserAPIKey },\n  workspaces: {\n    getWorkspacesList,\n    createWorkspace,\n    getWorkspace,\n    updateWorkspace,\n    deleteWorkspace,\n    getWorkspaceMembersList,\n    updateWorkspaceMemberRole,\n    removeWorkspaceMember\n  },\n  invites: {\n    inviteWorkspaceMember,\n    updateWorkspaceMemberInvite,\n    cancelWorkspaceMemberInvite,\n    acceptWorkspaceMemberInvite,\n    resendWorkspaceMemberInvite\n  },\n  xbcontrolOther: { listClusters, createCluster, getCluster, updateCluster },\n  databases: {\n    getDatabaseList,\n    createDatabase,\n    deleteDatabase,\n    getDatabaseMetadata,\n    updateDatabaseMetadata,\n    renameDatabase,\n    getDatabaseGithubSettings,\n    updateDatabaseGithubSettings,\n    deleteDatabaseGithubSettings,\n    listRegions\n  }\n};\n\nconst operationsByTag = deepMerge(operationsByTag$2, operationsByTag$1);\n\nvar __accessCheck$7 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$7 = (obj, member, getter) => {\n  __accessCheck$7(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$7 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$7 = (obj, member, value, setter) => {\n  __accessCheck$7(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _extraProps, _namespaces;\nclass XataApiClient {\n  constructor(options = {}) {\n    __privateAdd$7(this, _extraProps, void 0);\n    __privateAdd$7(this, _namespaces, {});\n    const provider = options.host ?? \"production\";\n    const apiKey = options.apiKey ?? getAPIKey();\n    const trace = options.trace ?? defaultTrace;\n    const clientID = generateUUID();\n    if (!apiKey) {\n      throw new Error(\"Could not resolve a valid apiKey\");\n    }\n    __privateSet$7(this, _extraProps, {\n      apiUrl: getHostUrl(provider, \"main\"),\n      workspacesApiUrl: getHostUrl(provider, \"workspaces\"),\n      fetch: getFetchImplementation(options.fetch),\n      apiKey,\n      trace,\n      clientName: options.clientName,\n      xataAgentExtra: options.xataAgentExtra,\n      clientID\n    });\n  }\n  get user() {\n    if (!__privateGet$7(this, _namespaces).user)\n      __privateGet$7(this, _namespaces).user = new UserApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).user;\n  }\n  get authentication() {\n    if (!__privateGet$7(this, _namespaces).authentication)\n      __privateGet$7(this, _namespaces).authentication = new AuthenticationApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).authentication;\n  }\n  get workspaces() {\n    if (!__privateGet$7(this, _namespaces).workspaces)\n      __privateGet$7(this, _namespaces).workspaces = new WorkspaceApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).workspaces;\n  }\n  get invites() {\n    if (!__privateGet$7(this, _namespaces).invites)\n      __privateGet$7(this, _namespaces).invites = new InvitesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).invites;\n  }\n  get database() {\n    if (!__privateGet$7(this, _namespaces).database)\n      __privateGet$7(this, _namespaces).database = new DatabaseApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).database;\n  }\n  get branches() {\n    if (!__privateGet$7(this, _namespaces).branches)\n      __privateGet$7(this, _namespaces).branches = new BranchApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).branches;\n  }\n  get migrations() {\n    if (!__privateGet$7(this, _namespaces).migrations)\n      __privateGet$7(this, _namespaces).migrations = new MigrationsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrations;\n  }\n  get migrationRequests() {\n    if (!__privateGet$7(this, _namespaces).migrationRequests)\n      __privateGet$7(this, _namespaces).migrationRequests = new MigrationRequestsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).migrationRequests;\n  }\n  get tables() {\n    if (!__privateGet$7(this, _namespaces).tables)\n      __privateGet$7(this, _namespaces).tables = new TableApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).tables;\n  }\n  get records() {\n    if (!__privateGet$7(this, _namespaces).records)\n      __privateGet$7(this, _namespaces).records = new RecordsApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).records;\n  }\n  get files() {\n    if (!__privateGet$7(this, _namespaces).files)\n      __privateGet$7(this, _namespaces).files = new FilesApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).files;\n  }\n  get searchAndFilter() {\n    if (!__privateGet$7(this, _namespaces).searchAndFilter)\n      __privateGet$7(this, _namespaces).searchAndFilter = new SearchAndFilterApi(__privateGet$7(this, _extraProps));\n    return __privateGet$7(this, _namespaces).searchAndFilter;\n  }\n}\n_extraProps = new WeakMap();\n_namespaces = new WeakMap();\nclass UserApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUser() {\n    return operationsByTag.users.getUser({ ...this.extraProps });\n  }\n  updateUser({ user }) {\n    return operationsByTag.users.updateUser({ body: user, ...this.extraProps });\n  }\n  deleteUser() {\n    return operationsByTag.users.deleteUser({ ...this.extraProps });\n  }\n}\nclass AuthenticationApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getUserAPIKeys() {\n    return operationsByTag.authentication.getUserAPIKeys({ ...this.extraProps });\n  }\n  createUserAPIKey({ name }) {\n    return operationsByTag.authentication.createUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n  deleteUserAPIKey({ name }) {\n    return operationsByTag.authentication.deleteUserAPIKey({\n      pathParams: { keyName: name },\n      ...this.extraProps\n    });\n  }\n}\nclass WorkspaceApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getWorkspacesList() {\n    return operationsByTag.workspaces.getWorkspacesList({ ...this.extraProps });\n  }\n  createWorkspace({ data }) {\n    return operationsByTag.workspaces.createWorkspace({\n      body: data,\n      ...this.extraProps\n    });\n  }\n  getWorkspace({ workspace }) {\n    return operationsByTag.workspaces.getWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspace({\n    workspace,\n    update\n  }) {\n    return operationsByTag.workspaces.updateWorkspace({\n      pathParams: { workspaceId: workspace },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteWorkspace({ workspace }) {\n    return operationsByTag.workspaces.deleteWorkspace({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  getWorkspaceMembersList({ workspace }) {\n    return operationsByTag.workspaces.getWorkspaceMembersList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberRole({\n    workspace,\n    user,\n    role\n  }) {\n    return operationsByTag.workspaces.updateWorkspaceMemberRole({\n      pathParams: { workspaceId: workspace, userId: user },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  removeWorkspaceMember({\n    workspace,\n    user\n  }) {\n    return operationsByTag.workspaces.removeWorkspaceMember({\n      pathParams: { workspaceId: workspace, userId: user },\n      ...this.extraProps\n    });\n  }\n}\nclass InvitesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  inviteWorkspaceMember({\n    workspace,\n    email,\n    role\n  }) {\n    return operationsByTag.invites.inviteWorkspaceMember({\n      pathParams: { workspaceId: workspace },\n      body: { email, role },\n      ...this.extraProps\n    });\n  }\n  updateWorkspaceMemberInvite({\n    workspace,\n    invite,\n    role\n  }) {\n    return operationsByTag.invites.updateWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      body: { role },\n      ...this.extraProps\n    });\n  }\n  cancelWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.cancelWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n  acceptWorkspaceMemberInvite({\n    workspace,\n    key\n  }) {\n    return operationsByTag.invites.acceptWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteKey: key },\n      ...this.extraProps\n    });\n  }\n  resendWorkspaceMemberInvite({\n    workspace,\n    invite\n  }) {\n    return operationsByTag.invites.resendWorkspaceMemberInvite({\n      pathParams: { workspaceId: workspace, inviteId: invite },\n      ...this.extraProps\n    });\n  }\n}\nclass BranchApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchList({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getBranchList({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getBranchDetails({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchDetails({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  createBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    from,\n    metadata\n  }) {\n    return operationsByTag.branch.createBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { from, metadata },\n      ...this.extraProps\n    });\n  }\n  deleteBranch({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.deleteBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  copyBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    destinationBranch,\n    limit\n  }) {\n    return operationsByTag.branch.copyBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { destinationBranch, limit },\n      ...this.extraProps\n    });\n  }\n  updateBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch,\n    metadata\n  }) {\n    return operationsByTag.branch.updateBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  getBranchMetadata({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchMetadata({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getBranchStats({\n    workspace,\n    region,\n    database,\n    branch\n  }) {\n    return operationsByTag.branch.getBranchStats({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      ...this.extraProps\n    });\n  }\n  getGitBranchesMapping({\n    workspace,\n    region,\n    database\n  }) {\n    return operationsByTag.branch.getGitBranchesMapping({\n      pathParams: { workspace, region, dbName: database },\n      ...this.extraProps\n    });\n  }\n  addGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    xataBranch\n  }) {\n    return operationsByTag.branch.addGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      body: { gitBranch, xataBranch },\n      ...this.extraProps\n    });\n  }\n  removeGitBranchesEntry({\n    workspace,\n    region,\n    database,\n    gitBranch\n  }) {\n    return operationsByTag.branch.removeGitBranchesEntry({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch },\n      ...this.extraProps\n    });\n  }\n  resolveBranch({\n    workspace,\n    region,\n    database,\n    gitBranch,\n    fallbackBranch\n  }) {\n    return operationsByTag.branch.resolveBranch({\n      pathParams: { workspace, region, dbName: database },\n      queryParams: { gitBranch, fallbackBranch },\n      ...this.extraProps\n    });\n  }\n}\nclass TableApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  createTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.createTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  deleteTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.deleteTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  updateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    update\n  }) {\n    return operationsByTag.table.updateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  getTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  setTableSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    schema\n  }) {\n    return operationsByTag.table.setTableSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  getTableColumns({\n    workspace,\n    region,\n    database,\n    branch,\n    table\n  }) {\n    return operationsByTag.table.getTableColumns({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      ...this.extraProps\n    });\n  }\n  addTableColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.addTableColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: column,\n      ...this.extraProps\n    });\n  }\n  getColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.getColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n  updateColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column,\n    update\n  }) {\n    return operationsByTag.table.updateColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  deleteColumn({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    column\n  }) {\n    return operationsByTag.table.deleteColumn({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, columnName: column },\n      ...this.extraProps\n    });\n  }\n}\nclass RecordsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  insertRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    columns\n  }) {\n    return operationsByTag.records.insertRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  getRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.getRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  insertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    createOnly,\n    ifVersion\n  }) {\n    return operationsByTag.records.insertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, createOnly, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  updateRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.updateRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  upsertRecordWithID({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    record,\n    columns,\n    ifVersion\n  }) {\n    return operationsByTag.records.upsertRecordWithID({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...this.extraProps\n    });\n  }\n  deleteRecord({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    id,\n    columns\n  }) {\n    return operationsByTag.records.deleteRecord({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, recordId: id },\n      queryParams: { columns },\n      ...this.extraProps\n    });\n  }\n  bulkInsertTableRecords({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    records,\n    columns\n  }) {\n    return operationsByTag.records.bulkInsertTableRecords({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      queryParams: { columns },\n      body: { records },\n      ...this.extraProps\n    });\n  }\n  branchTransaction({\n    workspace,\n    region,\n    database,\n    branch,\n    operations\n  }) {\n    return operationsByTag.records.branchTransaction({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { operations },\n      ...this.extraProps\n    });\n  }\n}\nclass FilesApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.getFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  putFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId,\n    file\n  }) {\n    return operationsByTag.files.putFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      // @ts-ignore\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFileItem({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    fileId\n  }) {\n    return operationsByTag.files.deleteFileItem({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column,\n        fileId\n      },\n      ...this.extraProps\n    });\n  }\n  getFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.getFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  putFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column,\n    file\n  }) {\n    return operationsByTag.files.putFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      body: file,\n      ...this.extraProps\n    });\n  }\n  deleteFile({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    record,\n    column\n  }) {\n    return operationsByTag.files.deleteFile({\n      pathParams: {\n        workspace,\n        region,\n        dbBranchName: `${database}:${branch}`,\n        tableName: table,\n        recordId: record,\n        columnName: column\n      },\n      ...this.extraProps\n    });\n  }\n  fileAccess({\n    workspace,\n    region,\n    fileId,\n    verify\n  }) {\n    return operationsByTag.files.fileAccess({\n      pathParams: {\n        workspace,\n        region,\n        fileId\n      },\n      queryParams: { verify },\n      ...this.extraProps\n    });\n  }\n}\nclass SearchAndFilterApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    sort,\n    page,\n    columns,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.queryTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, sort, page, columns, consistency },\n      ...this.extraProps\n    });\n  }\n  searchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    query,\n    fuzziness,\n    target,\n    prefix,\n    filter,\n    highlight,\n    boosters\n  }) {\n    return operationsByTag.searchAndFilter.searchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { query, fuzziness, target, prefix, filter, highlight, boosters },\n      ...this.extraProps\n    });\n  }\n  searchBranch({\n    workspace,\n    region,\n    database,\n    branch,\n    tables,\n    query,\n    fuzziness,\n    prefix,\n    highlight\n  }) {\n    return operationsByTag.searchAndFilter.searchBranch({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { tables, query, fuzziness, prefix, highlight },\n      ...this.extraProps\n    });\n  }\n  vectorSearchTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    queryVector,\n    column,\n    similarityFunction,\n    size,\n    filter\n  }) {\n    return operationsByTag.searchAndFilter.vectorSearchTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { queryVector, column, similarityFunction, size, filter },\n      ...this.extraProps\n    });\n  }\n  askTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    options\n  }) {\n    return operationsByTag.searchAndFilter.askTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { ...options },\n      ...this.extraProps\n    });\n  }\n  askTableSession({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    sessionId,\n    message\n  }) {\n    return operationsByTag.searchAndFilter.askTableSession({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table, sessionId },\n      body: { message },\n      ...this.extraProps\n    });\n  }\n  summarizeTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    columns,\n    summaries,\n    sort,\n    summariesFilter,\n    page,\n    consistency\n  }) {\n    return operationsByTag.searchAndFilter.summarizeTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, columns, summaries, sort, summariesFilter, page, consistency },\n      ...this.extraProps\n    });\n  }\n  aggregateTable({\n    workspace,\n    region,\n    database,\n    branch,\n    table,\n    filter,\n    aggs\n  }) {\n    return operationsByTag.searchAndFilter.aggregateTable({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, tableName: table },\n      body: { filter, aggs },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationRequestsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  queryMigrationRequests({\n    workspace,\n    region,\n    database,\n    filter,\n    sort,\n    page,\n    columns\n  }) {\n    return operationsByTag.migrationRequests.queryMigrationRequests({\n      pathParams: { workspace, region, dbName: database },\n      body: { filter, sort, page, columns },\n      ...this.extraProps\n    });\n  }\n  createMigrationRequest({\n    workspace,\n    region,\n    database,\n    migration\n  }) {\n    return operationsByTag.migrationRequests.createMigrationRequest({\n      pathParams: { workspace, region, dbName: database },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  getMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  updateMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    update\n  }) {\n    return operationsByTag.migrationRequests.updateMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: update,\n      ...this.extraProps\n    });\n  }\n  listMigrationRequestsCommits({\n    workspace,\n    region,\n    database,\n    migrationRequest,\n    page\n  }) {\n    return operationsByTag.migrationRequests.listMigrationRequestsCommits({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.compareMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  getMigrationRequestIsMerged({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.getMigrationRequestIsMerged({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n  mergeMigrationRequest({\n    workspace,\n    region,\n    database,\n    migrationRequest\n  }) {\n    return operationsByTag.migrationRequests.mergeMigrationRequest({\n      pathParams: { workspace, region, dbName: database, mrNumber: migrationRequest },\n      ...this.extraProps\n    });\n  }\n}\nclass MigrationsApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getBranchMigrationHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    limit,\n    startFrom\n  }) {\n    return operationsByTag.migrations.getBranchMigrationHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { limit, startFrom },\n      ...this.extraProps\n    });\n  }\n  getBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    schema\n  }) {\n    return operationsByTag.migrations.getBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: schema,\n      ...this.extraProps\n    });\n  }\n  executeBranchMigrationPlan({\n    workspace,\n    region,\n    database,\n    branch,\n    plan\n  }) {\n    return operationsByTag.migrations.executeBranchMigrationPlan({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: plan,\n      ...this.extraProps\n    });\n  }\n  getBranchSchemaHistory({\n    workspace,\n    region,\n    database,\n    branch,\n    page\n  }) {\n    return operationsByTag.migrations.getBranchSchemaHistory({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { page },\n      ...this.extraProps\n    });\n  }\n  compareBranchWithUserSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    schema,\n    schemaOperations,\n    branchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchWithUserSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { schema, schemaOperations, branchOperations },\n      ...this.extraProps\n    });\n  }\n  compareBranchSchemas({\n    workspace,\n    region,\n    database,\n    branch,\n    compare,\n    sourceBranchOperations,\n    targetBranchOperations\n  }) {\n    return operationsByTag.migrations.compareBranchSchemas({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}`, branchName: compare },\n      body: { sourceBranchOperations, targetBranchOperations },\n      ...this.extraProps\n    });\n  }\n  updateBranchSchema({\n    workspace,\n    region,\n    database,\n    branch,\n    migration\n  }) {\n    return operationsByTag.migrations.updateBranchSchema({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: migration,\n      ...this.extraProps\n    });\n  }\n  previewBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    data\n  }) {\n    return operationsByTag.migrations.previewBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: data,\n      ...this.extraProps\n    });\n  }\n  applyBranchSchemaEdit({\n    workspace,\n    region,\n    database,\n    branch,\n    edits\n  }) {\n    return operationsByTag.migrations.applyBranchSchemaEdit({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { edits },\n      ...this.extraProps\n    });\n  }\n  pushBranchMigrations({\n    workspace,\n    region,\n    database,\n    branch,\n    migrations\n  }) {\n    return operationsByTag.migrations.pushBranchMigrations({\n      pathParams: { workspace, region, dbBranchName: `${database}:${branch}` },\n      body: { migrations },\n      ...this.extraProps\n    });\n  }\n}\nclass DatabaseApi {\n  constructor(extraProps) {\n    this.extraProps = extraProps;\n  }\n  getDatabaseList({ workspace }) {\n    return operationsByTag.databases.getDatabaseList({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n  createDatabase({\n    workspace,\n    database,\n    data,\n    headers\n  }) {\n    return operationsByTag.databases.createDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: data,\n      headers,\n      ...this.extraProps\n    });\n  }\n  deleteDatabase({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  getDatabaseMetadata({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseMetadata({\n    workspace,\n    database,\n    metadata\n  }) {\n    return operationsByTag.databases.updateDatabaseMetadata({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: metadata,\n      ...this.extraProps\n    });\n  }\n  renameDatabase({\n    workspace,\n    database,\n    newName\n  }) {\n    return operationsByTag.databases.renameDatabase({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: { newName },\n      ...this.extraProps\n    });\n  }\n  getDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.getDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  updateDatabaseGithubSettings({\n    workspace,\n    database,\n    settings\n  }) {\n    return operationsByTag.databases.updateDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      body: settings,\n      ...this.extraProps\n    });\n  }\n  deleteDatabaseGithubSettings({\n    workspace,\n    database\n  }) {\n    return operationsByTag.databases.deleteDatabaseGithubSettings({\n      pathParams: { workspaceId: workspace, dbName: database },\n      ...this.extraProps\n    });\n  }\n  listRegions({ workspace }) {\n    return operationsByTag.databases.listRegions({\n      pathParams: { workspaceId: workspace },\n      ...this.extraProps\n    });\n  }\n}\n\nclass XataApiPlugin {\n  build(options) {\n    return new XataApiClient(options);\n  }\n}\n\nclass XataPlugin {\n}\n\nfunction buildTransformString(transformations) {\n  return transformations.flatMap(\n    (t) => Object.entries(t).map(([key, value]) => {\n      if (key === \"trim\") {\n        const { left = 0, top = 0, right = 0, bottom = 0 } = value;\n        return `${key}=${[top, right, bottom, left].join(\";\")}`;\n      }\n      if (key === \"gravity\" && typeof value === \"object\") {\n        const { x = 0.5, y = 0.5 } = value;\n        return `${key}=${[x, y].join(\"x\")}`;\n      }\n      return `${key}=${value}`;\n    })\n  ).join(\",\");\n}\nfunction transformImage(url, ...transformations) {\n  if (!isDefined(url))\n    return void 0;\n  const newTransformations = buildTransformString(transformations);\n  const { hostname, pathname, search } = new URL(url);\n  const pathParts = pathname.split(\"/\");\n  const transformIndex = pathParts.findIndex((part) => part === \"transform\");\n  const removedItems = transformIndex >= 0 ? pathParts.splice(transformIndex, 2) : [];\n  const transform = `/transform/${[removedItems[1], newTransformations].filter(isDefined).join(\",\")}`;\n  const path = pathParts.join(\"/\");\n  return `https://${hostname}${transform}${path}${search}`;\n}\n\nclass XataFile {\n  constructor(file) {\n    this.id = file.id;\n    this.name = file.name;\n    this.mediaType = file.mediaType;\n    this.base64Content = file.base64Content;\n    this.enablePublicUrl = file.enablePublicUrl;\n    this.signedUrlTimeout = file.signedUrlTimeout;\n    this.uploadUrlTimeout = file.uploadUrlTimeout;\n    this.size = file.size;\n    this.version = file.version;\n    this.url = file.url;\n    this.signedUrl = file.signedUrl;\n    this.uploadUrl = file.uploadUrl;\n    this.attributes = file.attributes;\n  }\n  static fromBuffer(buffer, options = {}) {\n    const base64Content = buffer.toString(\"base64\");\n    return new XataFile({ ...options, base64Content });\n  }\n  toBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return Buffer.from(this.base64Content, \"base64\");\n  }\n  static fromArrayBuffer(arrayBuffer, options = {}) {\n    const uint8Array = new Uint8Array(arrayBuffer);\n    return this.fromUint8Array(uint8Array, options);\n  }\n  toArrayBuffer() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    return new ArrayBuffer(binary.length);\n  }\n  static fromUint8Array(uint8Array, options = {}) {\n    let binary = \"\";\n    for (let i = 0; i < uint8Array.byteLength; i++) {\n      binary += String.fromCharCode(uint8Array[i]);\n    }\n    const base64Content = btoa(binary);\n    return new XataFile({ ...options, base64Content });\n  }\n  toUint8Array() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return uint8Array;\n  }\n  static async fromBlob(file, options = {}) {\n    const name = options.name ?? file.name;\n    const mediaType = file.type;\n    const arrayBuffer = await file.arrayBuffer();\n    return this.fromArrayBuffer(arrayBuffer, { ...options, name, mediaType });\n  }\n  toBlob() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    const binary = atob(this.base64Content);\n    const uint8Array = new Uint8Array(binary.length);\n    for (let i = 0; i < binary.length; i++) {\n      uint8Array[i] = binary.charCodeAt(i);\n    }\n    return new Blob([uint8Array], { type: this.mediaType });\n  }\n  static fromString(string, options = {}) {\n    const base64Content = btoa(string);\n    return new XataFile({ ...options, base64Content });\n  }\n  toString() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return atob(this.base64Content);\n  }\n  static fromBase64(base64Content, options = {}) {\n    return new XataFile({ ...options, base64Content });\n  }\n  toBase64() {\n    if (!this.base64Content) {\n      throw new Error(`File content is not available, please select property \"base64Content\" when querying the file`);\n    }\n    return this.base64Content;\n  }\n  transform(...options) {\n    return {\n      url: transformImage(this.url, ...options),\n      signedUrl: transformImage(this.signedUrl, ...options),\n      metadataUrl: transformImage(this.url, ...options, { format: \"json\" }),\n      metadataSignedUrl: transformImage(this.signedUrl, ...options, { format: \"json\" })\n    };\n  }\n}\nconst parseInputFileEntry = async (entry) => {\n  if (!isDefined(entry))\n    return null;\n  const { id, name, mediaType, base64Content, enablePublicUrl, signedUrlTimeout, uploadUrlTimeout } = await entry;\n  return compactObject({\n    id,\n    // Name cannot be an empty string in our API\n    name: name ? name : void 0,\n    mediaType,\n    base64Content,\n    enablePublicUrl,\n    signedUrlTimeout,\n    uploadUrlTimeout\n  });\n};\n\nfunction cleanFilter(filter) {\n  if (!isDefined(filter))\n    return void 0;\n  if (!isObject(filter))\n    return filter;\n  const values = Object.fromEntries(\n    Object.entries(filter).reduce((acc, [key, value]) => {\n      if (!isDefined(value))\n        return acc;\n      if (Array.isArray(value)) {\n        const clean = value.map((item) => cleanFilter(item)).filter((item) => isDefined(item));\n        if (clean.length === 0)\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      if (isObject(value)) {\n        const clean = cleanFilter(value);\n        if (!isDefined(clean))\n          return acc;\n        return [...acc, [key, clean]];\n      }\n      return [...acc, [key, value]];\n    }, [])\n  );\n  return Object.keys(values).length > 0 ? values : void 0;\n}\n\nfunction stringifyJson(value) {\n  if (!isDefined(value))\n    return value;\n  if (isString(value))\n    return value;\n  try {\n    return JSON.stringify(value);\n  } catch (e) {\n    return value;\n  }\n}\nfunction parseJson(value) {\n  try {\n    return JSON.parse(value);\n  } catch (e) {\n    return value;\n  }\n}\n\nvar __accessCheck$6 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$6 = (obj, member, getter) => {\n  __accessCheck$6(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$6 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$6 = (obj, member, value, setter) => {\n  __accessCheck$6(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _query, _page;\nclass Page {\n  constructor(query, meta, records = []) {\n    __privateAdd$6(this, _query, void 0);\n    __privateSet$6(this, _query, query);\n    this.meta = meta;\n    this.records = new RecordArray(this, records);\n  }\n  /**\n   * Retrieves the next page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The next page or results.\n   */\n  async nextPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, after: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the previous page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The previous page or results.\n   */\n  async previousPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, before: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the start page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The start page or results.\n   */\n  async startPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, start: this.meta.page.cursor } });\n  }\n  /**\n   * Retrieves the end page of results.\n   * @param size Maximum number of results to be retrieved.\n   * @param offset Number of results to skip when retrieving the results.\n   * @returns The end page or results.\n   */\n  async endPage(size, offset) {\n    return __privateGet$6(this, _query).getPaginated({ pagination: { size, offset, end: this.meta.page.cursor } });\n  }\n  /**\n   * Shortcut method to check if there will be additional results if the next page of results is retrieved.\n   * @returns Whether or not there will be additional results in the next page of results.\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n}\n_query = new WeakMap();\nconst PAGINATION_MAX_SIZE = 1e3;\nconst PAGINATION_DEFAULT_SIZE = 20;\nconst PAGINATION_MAX_OFFSET = 49e3;\nconst PAGINATION_DEFAULT_OFFSET = 0;\nfunction isCursorPaginationOptions(options) {\n  return isDefined(options) && (isDefined(options.start) || isDefined(options.end) || isDefined(options.after) || isDefined(options.before));\n}\nconst _RecordArray = class _RecordArray extends Array {\n  constructor(...args) {\n    super(..._RecordArray.parseConstructorParams(...args));\n    __privateAdd$6(this, _page, void 0);\n    __privateSet$6(this, _page, isObject(args[0]?.meta) ? args[0] : { meta: { page: { cursor: \"\", more: false } }, records: [] });\n  }\n  static parseConstructorParams(...args) {\n    if (args.length === 1 && typeof args[0] === \"number\") {\n      return new Array(args[0]);\n    }\n    if (args.length <= 2 && isObject(args[0]?.meta) && Array.isArray(args[1] ?? [])) {\n      const result = args[1] ?? args[0].records ?? [];\n      return new Array(...result);\n    }\n    return new Array(...args);\n  }\n  toArray() {\n    return new Array(...this);\n  }\n  toSerializable() {\n    return JSON.parse(this.toString());\n  }\n  toString() {\n    return JSON.stringify(this.toArray());\n  }\n  map(callbackfn, thisArg) {\n    return this.toArray().map(callbackfn, thisArg);\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new array of objects\n   */\n  async nextPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).nextPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new array of objects\n   */\n  async previousPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).previousPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new array of objects\n   */\n  async startPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).startPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * Retrieve end page of records\n   *\n   * @returns A new array of objects\n   */\n  async endPage(size, offset) {\n    const newPage = await __privateGet$6(this, _page).endPage(size, offset);\n    return new _RecordArray(newPage);\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return __privateGet$6(this, _page).meta.page.more;\n  }\n};\n_page = new WeakMap();\nlet RecordArray = _RecordArray;\n\nvar __accessCheck$5 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$5 = (obj, member, getter) => {\n  __accessCheck$5(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$5 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$5 = (obj, member, value, setter) => {\n  __accessCheck$5(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$3 = (obj, member, method) => {\n  __accessCheck$5(obj, member, \"access private method\");\n  return method;\n};\nvar _table$1, _repository, _data, _cleanFilterConstraint, cleanFilterConstraint_fn;\nconst _Query = class _Query {\n  constructor(repository, table, data, rawParent) {\n    __privateAdd$5(this, _cleanFilterConstraint);\n    __privateAdd$5(this, _table$1, void 0);\n    __privateAdd$5(this, _repository, void 0);\n    __privateAdd$5(this, _data, { filter: {} });\n    // Implements pagination\n    this.meta = { page: { cursor: \"start\", more: true, size: PAGINATION_DEFAULT_SIZE } };\n    this.records = new RecordArray(this, []);\n    __privateSet$5(this, _table$1, table);\n    if (repository) {\n      __privateSet$5(this, _repository, repository);\n    } else {\n      __privateSet$5(this, _repository, this);\n    }\n    const parent = cleanParent(data, rawParent);\n    __privateGet$5(this, _data).filter = data.filter ?? parent?.filter ?? {};\n    __privateGet$5(this, _data).filter.$any = data.filter?.$any ?? parent?.filter?.$any;\n    __privateGet$5(this, _data).filter.$all = data.filter?.$all ?? parent?.filter?.$all;\n    __privateGet$5(this, _data).filter.$not = data.filter?.$not ?? parent?.filter?.$not;\n    __privateGet$5(this, _data).filter.$none = data.filter?.$none ?? parent?.filter?.$none;\n    __privateGet$5(this, _data).sort = data.sort ?? parent?.sort;\n    __privateGet$5(this, _data).columns = data.columns ?? parent?.columns;\n    __privateGet$5(this, _data).consistency = data.consistency ?? parent?.consistency;\n    __privateGet$5(this, _data).pagination = data.pagination ?? parent?.pagination;\n    __privateGet$5(this, _data).cache = data.cache ?? parent?.cache;\n    __privateGet$5(this, _data).fetchOptions = data.fetchOptions ?? parent?.fetchOptions;\n    this.any = this.any.bind(this);\n    this.all = this.all.bind(this);\n    this.not = this.not.bind(this);\n    this.filter = this.filter.bind(this);\n    this.sort = this.sort.bind(this);\n    this.none = this.none.bind(this);\n    Object.defineProperty(this, \"table\", { enumerable: false });\n    Object.defineProperty(this, \"repository\", { enumerable: false });\n  }\n  getQueryOptions() {\n    return __privateGet$5(this, _data);\n  }\n  key() {\n    const { columns = [], filter = {}, sort = [], pagination = {} } = __privateGet$5(this, _data);\n    const key = JSON.stringify({ columns, filter, sort, pagination });\n    return toBase64(key);\n  }\n  /**\n   * Builds a new query object representing a logical OR between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  any(...queries) {\n    const $any = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $any } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND between the given subqueries.\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  all(...queries) {\n    const $all = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical OR negating each subquery. In pseudo-code: !q1 OR !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  not(...queries) {\n    const $not = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $not } }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query object representing a logical AND negating each subquery. In pseudo-code: !q1 AND !q2\n   * @param queries An array of subqueries.\n   * @returns A new Query object.\n   */\n  none(...queries) {\n    const $none = queries.map((query) => query.getQueryOptions().filter ?? {});\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $none } }, __privateGet$5(this, _data));\n  }\n  filter(a, b) {\n    if (arguments.length === 1) {\n      const constraints = Object.entries(a ?? {}).map(([column, constraint]) => ({\n        [column]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, column, constraint)\n      }));\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    } else {\n      const constraints = isDefined(a) && isDefined(b) ? [{ [a]: __privateMethod$3(this, _cleanFilterConstraint, cleanFilterConstraint_fn).call(this, a, b) }] : void 0;\n      const $all = compact([__privateGet$5(this, _data).filter?.$all].flat().concat(constraints));\n      return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { filter: { $all } }, __privateGet$5(this, _data));\n    }\n  }\n  sort(column, direction = \"asc\") {\n    const originalSort = [__privateGet$5(this, _data).sort ?? []].flat();\n    const sort = [...originalSort, { column, direction }];\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { sort }, __privateGet$5(this, _data));\n  }\n  /**\n   * Builds a new query specifying the set of columns to be returned in the query response.\n   * @param columns Array of column names to be returned by the query.\n   * @returns A new Query object.\n   */\n  select(columns) {\n    return new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      { columns },\n      __privateGet$5(this, _data)\n    );\n  }\n  getPaginated(options = {}) {\n    const query = new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), options, __privateGet$5(this, _data));\n    return __privateGet$5(this, _repository).query(query);\n  }\n  /**\n   * Get results in an iterator\n   *\n   * @async\n   * @returns Async interable of results\n   */\n  async *[Symbol.asyncIterator]() {\n    for await (const [record] of this.getIterator({ batchSize: 1 })) {\n      yield record;\n    }\n  }\n  async *getIterator(options = {}) {\n    const { batchSize = 1 } = options;\n    let page = await this.getPaginated({ ...options, pagination: { size: batchSize, offset: 0 } });\n    let more = page.hasNextPage();\n    yield page.records;\n    while (more) {\n      page = await page.nextPage();\n      more = page.hasNextPage();\n      yield page.records;\n    }\n  }\n  async getMany(options = {}) {\n    const { pagination = {}, ...rest } = options;\n    const { size = PAGINATION_DEFAULT_SIZE, offset } = pagination;\n    const batchSize = size <= PAGINATION_MAX_SIZE ? size : PAGINATION_MAX_SIZE;\n    let page = await this.getPaginated({ ...rest, pagination: { size: batchSize, offset } });\n    const results = [...page.records];\n    while (page.hasNextPage() && results.length < size) {\n      page = await page.nextPage();\n      results.push(...page.records);\n    }\n    if (page.hasNextPage() && options.pagination?.size === void 0) {\n      console.trace(\"Calling getMany does not return all results. Paginate to get all results or call getAll.\");\n    }\n    const array = new RecordArray(page, results.slice(0, size));\n    return array;\n  }\n  async getAll(options = {}) {\n    const { batchSize = PAGINATION_MAX_SIZE, ...rest } = options;\n    const results = [];\n    for await (const page of this.getIterator({ ...rest, batchSize })) {\n      results.push(...page);\n    }\n    return results;\n  }\n  async getFirst(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    return records[0] ?? null;\n  }\n  async getFirstOrThrow(options = {}) {\n    const records = await this.getMany({ ...options, pagination: { size: 1 } });\n    if (records[0] === void 0)\n      throw new Error(\"No results found.\");\n    return records[0];\n  }\n  async summarize(params = {}) {\n    const { summaries, summariesFilter, ...options } = params;\n    const query = new _Query(\n      __privateGet$5(this, _repository),\n      __privateGet$5(this, _table$1),\n      options,\n      __privateGet$5(this, _data)\n    );\n    return __privateGet$5(this, _repository).summarizeTable(query, summaries, summariesFilter);\n  }\n  /**\n   * Builds a new query object adding a cache TTL in milliseconds.\n   * @param ttl The cache TTL in milliseconds.\n   * @returns A new Query object.\n   */\n  cache(ttl) {\n    return new _Query(__privateGet$5(this, _repository), __privateGet$5(this, _table$1), { cache: ttl }, __privateGet$5(this, _data));\n  }\n  /**\n   * Retrieve next page of records\n   *\n   * @returns A new page object.\n   */\n  nextPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve previous page of records\n   *\n   * @returns A new page object\n   */\n  previousPage(size, offset) {\n    return this.startPage(size, offset);\n  }\n  /**\n   * Retrieve start page of records\n   *\n   * @returns A new page object\n   */\n  startPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset } });\n  }\n  /**\n   * Retrieve last page of records\n   *\n   * @returns A new page object\n   */\n  endPage(size, offset) {\n    return this.getPaginated({ pagination: { size, offset, before: \"end\" } });\n  }\n  /**\n   * @returns Boolean indicating if there is a next page\n   */\n  hasNextPage() {\n    return this.meta.page.more;\n  }\n};\n_table$1 = new WeakMap();\n_repository = new WeakMap();\n_data = new WeakMap();\n_cleanFilterConstraint = new WeakSet();\ncleanFilterConstraint_fn = function(column, value) {\n  const columnType = __privateGet$5(this, _table$1).schema?.columns.find(({ name }) => name === column)?.type;\n  if (columnType === \"multiple\" && (isString(value) || isStringArray(value))) {\n    return { $includes: value };\n  }\n  if (columnType === \"link\" && isObject(value) && isString(value.id)) {\n    return value.id;\n  }\n  return value;\n};\nlet Query = _Query;\nfunction cleanParent(data, parent) {\n  if (isCursorPaginationOptions(data.pagination)) {\n    return { ...parent, sort: void 0, filter: void 0 };\n  }\n  return parent;\n}\n\nconst RecordColumnTypes = [\n  \"bool\",\n  \"int\",\n  \"float\",\n  \"string\",\n  \"text\",\n  \"email\",\n  \"multiple\",\n  \"link\",\n  \"object\",\n  \"datetime\",\n  \"vector\",\n  \"file[]\",\n  \"file\",\n  \"json\"\n];\nfunction isIdentifiable(x) {\n  return isObject(x) && isString(x?.id);\n}\nfunction isXataRecord(x) {\n  const record = x;\n  const metadata = record?.getMetadata();\n  return isIdentifiable(x) && isObject(metadata) && typeof metadata.version === \"number\";\n}\n\nfunction isValidExpandedColumn(column) {\n  return isObject(column) && isString(column.name);\n}\nfunction isValidSelectableColumns(columns) {\n  if (!Array.isArray(columns)) {\n    return false;\n  }\n  return columns.every((column) => {\n    if (typeof column === \"string\") {\n      return true;\n    }\n    if (typeof column === \"object\") {\n      return isValidExpandedColumn(column);\n    }\n    return false;\n  });\n}\n\nfunction isSortFilterString(value) {\n  return isString(value);\n}\nfunction isSortFilterBase(filter) {\n  return isObject(filter) && Object.entries(filter).every(([key, value]) => {\n    if (key === \"*\")\n      return value === \"random\";\n    return value === \"asc\" || value === \"desc\";\n  });\n}\nfunction isSortFilterObject(filter) {\n  return isObject(filter) && !isSortFilterBase(filter) && filter.column !== void 0;\n}\nfunction buildSortFilter(filter) {\n  if (isSortFilterString(filter)) {\n    return { [filter]: \"asc\" };\n  } else if (Array.isArray(filter)) {\n    return filter.map((item) => buildSortFilter(item));\n  } else if (isSortFilterBase(filter)) {\n    return filter;\n  } else if (isSortFilterObject(filter)) {\n    return { [filter.column]: filter.direction ?? \"asc\" };\n  } else {\n    throw new Error(`Invalid sort filter: ${filter}`);\n  }\n}\n\nvar __accessCheck$4 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$4 = (obj, member, getter) => {\n  __accessCheck$4(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$4 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$4 = (obj, member, value, setter) => {\n  __accessCheck$4(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$2 = (obj, member, method) => {\n  __accessCheck$4(obj, member, \"access private method\");\n  return method;\n};\nvar _table, _getFetchProps, _db, _cache, _schemaTables$2, _trace, _insertRecordWithoutId, insertRecordWithoutId_fn, _insertRecordWithId, insertRecordWithId_fn, _insertRecords, insertRecords_fn, _updateRecordWithID, updateRecordWithID_fn, _updateRecords, updateRecords_fn, _upsertRecordWithID, upsertRecordWithID_fn, _deleteRecord, deleteRecord_fn, _deleteRecords, deleteRecords_fn, _setCacheQuery, setCacheQuery_fn, _getCacheQuery, getCacheQuery_fn, _getSchemaTables$1, getSchemaTables_fn$1, _transformObjectToApi, transformObjectToApi_fn;\nconst BULK_OPERATION_MAX_SIZE = 1e3;\nclass Repository extends Query {\n}\nclass RestRepository extends Query {\n  constructor(options) {\n    super(\n      null,\n      { name: options.table, schema: options.schemaTables?.find((table) => table.name === options.table) },\n      {}\n    );\n    __privateAdd$4(this, _insertRecordWithoutId);\n    __privateAdd$4(this, _insertRecordWithId);\n    __privateAdd$4(this, _insertRecords);\n    __privateAdd$4(this, _updateRecordWithID);\n    __privateAdd$4(this, _updateRecords);\n    __privateAdd$4(this, _upsertRecordWithID);\n    __privateAdd$4(this, _deleteRecord);\n    __privateAdd$4(this, _deleteRecords);\n    __privateAdd$4(this, _setCacheQuery);\n    __privateAdd$4(this, _getCacheQuery);\n    __privateAdd$4(this, _getSchemaTables$1);\n    __privateAdd$4(this, _transformObjectToApi);\n    __privateAdd$4(this, _table, void 0);\n    __privateAdd$4(this, _getFetchProps, void 0);\n    __privateAdd$4(this, _db, void 0);\n    __privateAdd$4(this, _cache, void 0);\n    __privateAdd$4(this, _schemaTables$2, void 0);\n    __privateAdd$4(this, _trace, void 0);\n    __privateSet$4(this, _table, options.table);\n    __privateSet$4(this, _db, options.db);\n    __privateSet$4(this, _cache, options.pluginOptions.cache);\n    __privateSet$4(this, _schemaTables$2, options.schemaTables);\n    __privateSet$4(this, _getFetchProps, () => ({ ...options.pluginOptions, sessionID: generateUUID() }));\n    const trace = options.pluginOptions.trace ?? defaultTrace;\n    __privateSet$4(this, _trace, async (name, fn, options2 = {}) => {\n      return trace(name, fn, {\n        ...options2,\n        [TraceAttributes.TABLE]: __privateGet$4(this, _table),\n        [TraceAttributes.KIND]: \"sdk-operation\",\n        [TraceAttributes.VERSION]: VERSION\n      });\n    });\n  }\n  async create(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"create\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: true });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: true, ifVersion });\n      }\n      if (isObject(a)) {\n        const columns = isValidSelectableColumns(b) ? b : void 0;\n        return __privateMethod$2(this, _insertRecordWithoutId, insertRecordWithoutId_fn).call(this, a, columns);\n      }\n      throw new Error(\"Invalid arguments for create method\");\n    });\n  }\n  async read(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"read\", async () => {\n      const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((item) => extractId(item));\n        const finalObjects = await this.getAll({ filter: { id: { $any: compact(ids) } }, columns });\n        const dictionary = finalObjects.reduce((acc, object) => {\n          acc[object.id] = object;\n          return acc;\n        }, {});\n        return ids.map((id2) => dictionary[id2 ?? \"\"] ?? null);\n      }\n      const id = extractId(a);\n      if (id) {\n        try {\n          const response = await getRecord({\n            pathParams: {\n              workspace: \"{workspaceId}\",\n              dbBranchName: \"{dbBranch}\",\n              region: \"{region}\",\n              tableName: __privateGet$4(this, _table),\n              recordId: id\n            },\n            queryParams: { columns },\n            ...__privateGet$4(this, _getFetchProps).call(this)\n          });\n          const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n          return initObject(\n            __privateGet$4(this, _db),\n            schemaTables,\n            __privateGet$4(this, _table),\n            response,\n            columns\n          );\n        } catch (e) {\n          if (isObject(e) && e.status === 404) {\n            return null;\n          }\n          throw e;\n        }\n      }\n      return null;\n    });\n  }\n  async readOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"readOrThrow\", async () => {\n      const result = await this.read(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async update(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"update\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const existing = await this.read(a, [\"id\"]);\n        const updates = a.filter((_item, index) => existing[index] !== null);\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, updates, {\n          ifVersion,\n          upsert: false\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      try {\n        if (isString(a) && isObject(b)) {\n          const columns = isValidSelectableColumns(c) ? c : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n        }\n        if (isObject(a) && isString(a.id)) {\n          const columns = isValidSelectableColumns(b) ? b : void 0;\n          return await __privateMethod$2(this, _updateRecordWithID, updateRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n        }\n      } catch (error) {\n        if (error.status === 422)\n          return null;\n        throw error;\n      }\n      throw new Error(\"Invalid arguments for update method\");\n    });\n  }\n  async updateOrThrow(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"updateOrThrow\", async () => {\n      const result = await this.update(a, b, c, d);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      }\n      if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async createOrUpdate(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrUpdate\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        await __privateMethod$2(this, _updateRecords, updateRecords_fn).call(this, a, {\n          ifVersion,\n          upsert: true\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a, b, columns, { ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _upsertRecordWithID, upsertRecordWithID_fn).call(this, a.id, { ...a, id: void 0 }, columns, { ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrUpdate method\");\n    });\n  }\n  async createOrReplace(a, b, c, d) {\n    return __privateGet$4(this, _trace).call(this, \"createOrReplace\", async () => {\n      const ifVersion = parseIfVersion(b, c, d);\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = await __privateMethod$2(this, _insertRecords, insertRecords_fn).call(this, a, { ifVersion, createOnly: false });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(ids, columns);\n        return result;\n      }\n      if (isString(a) && isObject(b)) {\n        if (a === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a, b, columns, { createOnly: false, ifVersion });\n      }\n      if (isObject(a) && isString(a.id)) {\n        if (a.id === \"\")\n          throw new Error(\"The id can't be empty\");\n        const columns = isValidSelectableColumns(c) ? c : void 0;\n        return await __privateMethod$2(this, _insertRecordWithId, insertRecordWithId_fn).call(this, a.id, { ...a, id: void 0 }, columns, { createOnly: false, ifVersion });\n      }\n      if (!isDefined(a) && isObject(b)) {\n        return await this.create(b, c);\n      }\n      if (isObject(a) && !isDefined(a.id)) {\n        return await this.create(a, b);\n      }\n      throw new Error(\"Invalid arguments for createOrReplace method\");\n    });\n  }\n  async delete(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"delete\", async () => {\n      if (Array.isArray(a)) {\n        if (a.length === 0)\n          return [];\n        const ids = a.map((o) => {\n          if (isString(o))\n            return o;\n          if (isString(o.id))\n            return o.id;\n          throw new Error(\"Invalid arguments for delete method\");\n        });\n        const columns = isValidSelectableColumns(b) ? b : [\"*\"];\n        const result = await this.read(a, columns);\n        await __privateMethod$2(this, _deleteRecords, deleteRecords_fn).call(this, ids);\n        return result;\n      }\n      if (isString(a)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a, b);\n      }\n      if (isObject(a) && isString(a.id)) {\n        return __privateMethod$2(this, _deleteRecord, deleteRecord_fn).call(this, a.id, b);\n      }\n      throw new Error(\"Invalid arguments for delete method\");\n    });\n  }\n  async deleteOrThrow(a, b) {\n    return __privateGet$4(this, _trace).call(this, \"deleteOrThrow\", async () => {\n      const result = await this.delete(a, b);\n      if (Array.isArray(result)) {\n        const missingIds = compact(\n          a.filter((_item, index) => result[index] === null).map((item) => extractId(item))\n        );\n        if (missingIds.length > 0) {\n          throw new Error(`Could not find records with ids: ${missingIds.join(\", \")}`);\n        }\n        return result;\n      } else if (result === null) {\n        const id = extractId(a) ?? \"unknown\";\n        throw new Error(`Record with id ${id} not found`);\n      }\n      return result;\n    });\n  }\n  async search(query, options = {}) {\n    return __privateGet$4(this, _trace).call(this, \"search\", async () => {\n      const { records, totalCount } = await searchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          query,\n          fuzziness: options.fuzziness,\n          prefix: options.prefix,\n          highlight: options.highlight,\n          filter: options.filter,\n          boosters: options.boosters,\n          page: options.page,\n          target: options.target\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async vectorSearch(column, query, options) {\n    return __privateGet$4(this, _trace).call(this, \"vectorSearch\", async () => {\n      const { records, totalCount } = await vectorSearchTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          column,\n          queryVector: query,\n          similarityFunction: options?.similarityFunction,\n          size: options?.size,\n          filter: options?.filter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        records: records.map((item) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), item, [\"*\"])),\n        totalCount\n      };\n    });\n  }\n  async aggregate(aggs, filter) {\n    return __privateGet$4(this, _trace).call(this, \"aggregate\", async () => {\n      const result = await aggregateTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: { aggs, filter },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      return result;\n    });\n  }\n  async query(query) {\n    return __privateGet$4(this, _trace).call(this, \"query\", async () => {\n      const cacheQuery = await __privateMethod$2(this, _getCacheQuery, getCacheQuery_fn).call(this, query);\n      if (cacheQuery)\n        return new Page(query, cacheQuery.meta, cacheQuery.records);\n      const data = query.getQueryOptions();\n      const { meta, records: objects } = await queryTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          page: data.pagination,\n          columns: data.columns ?? [\"*\"],\n          consistency: data.consistency\n        },\n        fetchOptions: data.fetchOptions,\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      const records = objects.map(\n        (record) => initObject(\n          __privateGet$4(this, _db),\n          schemaTables,\n          __privateGet$4(this, _table),\n          record,\n          data.columns ?? [\"*\"]\n        )\n      );\n      await __privateMethod$2(this, _setCacheQuery, setCacheQuery_fn).call(this, query, meta, records);\n      return new Page(query, meta, records);\n    });\n  }\n  async summarizeTable(query, summaries, summariesFilter) {\n    return __privateGet$4(this, _trace).call(this, \"summarize\", async () => {\n      const data = query.getQueryOptions();\n      const result = await summarizeTable({\n        pathParams: {\n          workspace: \"{workspaceId}\",\n          dbBranchName: \"{dbBranch}\",\n          region: \"{region}\",\n          tableName: __privateGet$4(this, _table)\n        },\n        body: {\n          filter: cleanFilter(data.filter),\n          sort: data.sort !== void 0 ? buildSortFilter(data.sort) : void 0,\n          columns: data.columns,\n          consistency: data.consistency,\n          page: data.pagination?.size !== void 0 ? { size: data.pagination?.size } : void 0,\n          summaries,\n          summariesFilter\n        },\n        ...__privateGet$4(this, _getFetchProps).call(this)\n      });\n      const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n      return {\n        ...result,\n        summaries: result.summaries.map(\n          (summary) => initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), summary, data.columns ?? [])\n        )\n      };\n    });\n  }\n  ask(question, options) {\n    const questionParam = options?.sessionId ? { message: question } : { question };\n    const params = {\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        sessionId: options?.sessionId\n      },\n      body: {\n        ...questionParam,\n        rules: options?.rules,\n        searchType: options?.searchType,\n        search: options?.searchType === \"keyword\" ? options?.search : void 0,\n        vectorSearch: options?.searchType === \"vector\" ? options?.vectorSearch : void 0\n      },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    };\n    if (options?.onMessage) {\n      fetchSSERequest({\n        endpoint: \"dataPlane\",\n        url: \"/db/{dbBranchName}/tables/{tableName}/ask/{sessionId}\",\n        method: \"POST\",\n        onMessage: (message) => {\n          options.onMessage?.({ answer: message.text, records: message.records });\n        },\n        ...params\n      });\n    } else {\n      return askTableSession(params);\n    }\n  }\n}\n_table = new WeakMap();\n_getFetchProps = new WeakMap();\n_db = new WeakMap();\n_cache = new WeakMap();\n_schemaTables$2 = new WeakMap();\n_trace = new WeakMap();\n_insertRecordWithoutId = new WeakSet();\ninsertRecordWithoutId_fn = async function(object, columns = [\"*\"]) {\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecord({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table)\n    },\n    queryParams: { columns },\n    body: record,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecordWithId = new WeakSet();\ninsertRecordWithId_fn = async function(recordId, object, columns = [\"*\"], { createOnly, ifVersion }) {\n  if (!recordId)\n    return null;\n  const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  const response = await insertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    body: record,\n    queryParams: { createOnly, columns, ifVersion },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_insertRecords = new WeakSet();\ninsertRecords_fn = async function(objects, { createOnly, ifVersion }) {\n  const operations = await promiseMap(objects, async (object) => {\n    const record = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { insert: { table: __privateGet$4(this, _table), record, createOnly, ifVersion } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"insert\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_updateRecordWithID = new WeakSet();\nupdateRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const { id: _id, ...record } = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n  try {\n    const response = await updateRecordWithID({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns, ifVersion },\n      body: record,\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_updateRecords = new WeakSet();\nupdateRecords_fn = async function(objects, { ifVersion, upsert }) {\n  const operations = await promiseMap(objects, async ({ id, ...object }) => {\n    const fields = await __privateMethod$2(this, _transformObjectToApi, transformObjectToApi_fn).call(this, object);\n    return { update: { table: __privateGet$4(this, _table), id, ifVersion, upsert, fields } };\n  });\n  const chunkedOperations = chunk(operations, BULK_OPERATION_MAX_SIZE);\n  const ids = [];\n  for (const operations2 of chunkedOperations) {\n    const { results } = await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations: operations2 },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    for (const result of results) {\n      if (result.operation === \"update\") {\n        ids.push(result.id);\n      } else {\n        ids.push(null);\n      }\n    }\n  }\n  return ids;\n};\n_upsertRecordWithID = new WeakSet();\nupsertRecordWithID_fn = async function(recordId, object, columns = [\"*\"], { ifVersion }) {\n  if (!recordId)\n    return null;\n  const response = await upsertRecordWithID({\n    pathParams: {\n      workspace: \"{workspaceId}\",\n      dbBranchName: \"{dbBranch}\",\n      region: \"{region}\",\n      tableName: __privateGet$4(this, _table),\n      recordId\n    },\n    queryParams: { columns, ifVersion },\n    body: object,\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n};\n_deleteRecord = new WeakSet();\ndeleteRecord_fn = async function(recordId, columns = [\"*\"]) {\n  if (!recordId)\n    return null;\n  try {\n    const response = await deleteRecord({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\",\n        tableName: __privateGet$4(this, _table),\n        recordId\n      },\n      queryParams: { columns },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n    const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n    return initObject(__privateGet$4(this, _db), schemaTables, __privateGet$4(this, _table), response, columns);\n  } catch (e) {\n    if (isObject(e) && e.status === 404) {\n      return null;\n    }\n    throw e;\n  }\n};\n_deleteRecords = new WeakSet();\ndeleteRecords_fn = async function(recordIds) {\n  const chunkedOperations = chunk(\n    compact(recordIds).map((id) => ({ delete: { table: __privateGet$4(this, _table), id } })),\n    BULK_OPERATION_MAX_SIZE\n  );\n  for (const operations of chunkedOperations) {\n    await branchTransaction({\n      pathParams: {\n        workspace: \"{workspaceId}\",\n        dbBranchName: \"{dbBranch}\",\n        region: \"{region}\"\n      },\n      body: { operations },\n      ...__privateGet$4(this, _getFetchProps).call(this)\n    });\n  }\n};\n_setCacheQuery = new WeakSet();\nsetCacheQuery_fn = async function(query, meta, records) {\n  await __privateGet$4(this, _cache)?.set(`query_${__privateGet$4(this, _table)}:${query.key()}`, { date: /* @__PURE__ */ new Date(), meta, records });\n};\n_getCacheQuery = new WeakSet();\ngetCacheQuery_fn = async function(query) {\n  const key = `query_${__privateGet$4(this, _table)}:${query.key()}`;\n  const result = await __privateGet$4(this, _cache)?.get(key);\n  if (!result)\n    return null;\n  const defaultTTL = __privateGet$4(this, _cache)?.defaultQueryTTL ?? -1;\n  const { cache: ttl = defaultTTL } = query.getQueryOptions();\n  if (ttl < 0)\n    return null;\n  const hasExpired = result.date.getTime() + ttl < Date.now();\n  return hasExpired ? null : result;\n};\n_getSchemaTables$1 = new WeakSet();\ngetSchemaTables_fn$1 = async function() {\n  if (__privateGet$4(this, _schemaTables$2))\n    return __privateGet$4(this, _schemaTables$2);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...__privateGet$4(this, _getFetchProps).call(this)\n  });\n  __privateSet$4(this, _schemaTables$2, schema.tables);\n  return schema.tables;\n};\n_transformObjectToApi = new WeakSet();\ntransformObjectToApi_fn = async function(object) {\n  const schemaTables = await __privateMethod$2(this, _getSchemaTables$1, getSchemaTables_fn$1).call(this);\n  const schema = schemaTables.find((table) => table.name === __privateGet$4(this, _table));\n  if (!schema)\n    throw new Error(`Table ${__privateGet$4(this, _table)} not found in schema`);\n  const result = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (key === \"xata\")\n      continue;\n    const type = schema.columns.find((column) => column.name === key)?.type;\n    switch (type) {\n      case \"link\": {\n        result[key] = isIdentifiable(value) ? value.id : value;\n        break;\n      }\n      case \"datetime\": {\n        result[key] = value instanceof Date ? value.toISOString() : value;\n        break;\n      }\n      case `file`:\n        result[key] = await parseInputFileEntry(value);\n        break;\n      case \"file[]\":\n        result[key] = await promiseMap(value, (item) => parseInputFileEntry(item));\n        break;\n      case \"json\":\n        result[key] = stringifyJson(value);\n        break;\n      default:\n        result[key] = value;\n    }\n  }\n  return result;\n};\nconst initObject = (db, schemaTables, table, object, selectedColumns) => {\n  const data = {};\n  const { xata, ...rest } = object ?? {};\n  Object.assign(data, rest);\n  const { columns } = schemaTables.find(({ name }) => name === table) ?? {};\n  if (!columns)\n    console.error(`Table ${table} not found in schema`);\n  for (const column of columns ?? []) {\n    if (!isValidColumn(selectedColumns, column))\n      continue;\n    const value = data[column.name];\n    switch (column.type) {\n      case \"datetime\": {\n        const date = value !== void 0 ? new Date(value) : null;\n        if (date !== null && isNaN(date.getTime())) {\n          console.error(`Failed to parse date ${value} for field ${column.name}`);\n        } else {\n          data[column.name] = date;\n        }\n        break;\n      }\n      case \"link\": {\n        const linkTable = column.link?.table;\n        if (!linkTable) {\n          console.error(`Failed to parse link for field ${column.name}`);\n        } else if (isObject(value)) {\n          const selectedLinkColumns = selectedColumns.reduce((acc, item) => {\n            if (item === column.name) {\n              return [...acc, \"*\"];\n            }\n            if (isString(item) && item.startsWith(`${column.name}.`)) {\n              const [, ...path] = item.split(\".\");\n              return [...acc, path.join(\".\")];\n            }\n            return acc;\n          }, []);\n          data[column.name] = initObject(\n            db,\n            schemaTables,\n            linkTable,\n            value,\n            selectedLinkColumns\n          );\n        } else {\n          data[column.name] = null;\n        }\n        break;\n      }\n      case \"file\":\n        data[column.name] = isDefined(value) ? new XataFile(value) : null;\n        break;\n      case \"file[]\":\n        data[column.name] = value?.map((item) => new XataFile(item)) ?? null;\n        break;\n      case \"json\":\n        data[column.name] = parseJson(value);\n        break;\n      default:\n        data[column.name] = value ?? null;\n        if (column.notNull === true && value === null) {\n          console.error(`Parse error, column ${column.name} is non nullable and value resolves null`);\n        }\n        break;\n    }\n  }\n  const record = { ...data };\n  const metadata = xata !== void 0 ? { ...xata, createdAt: new Date(xata.createdAt), updatedAt: new Date(xata.updatedAt) } : void 0;\n  record.read = function(columns2) {\n    return db[table].read(record[\"id\"], columns2);\n  };\n  record.update = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].update(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.replace = function(data2, b, c) {\n    const columns2 = isValidSelectableColumns(b) ? b : [\"*\"];\n    const ifVersion = parseIfVersion(b, c);\n    return db[table].createOrReplace(record[\"id\"], data2, columns2, { ifVersion });\n  };\n  record.delete = function() {\n    return db[table].delete(record[\"id\"]);\n  };\n  if (metadata !== void 0) {\n    record.xata = Object.freeze(metadata);\n  }\n  record.getMetadata = function() {\n    return record.xata;\n  };\n  record.toSerializable = function() {\n    return JSON.parse(JSON.stringify(record));\n  };\n  record.toString = function() {\n    return JSON.stringify(record);\n  };\n  for (const prop of [\"read\", \"update\", \"replace\", \"delete\", \"getMetadata\", \"toSerializable\", \"toString\"]) {\n    Object.defineProperty(record, prop, { enumerable: false });\n  }\n  Object.freeze(record);\n  return record;\n};\nfunction extractId(value) {\n  if (isString(value))\n    return value;\n  if (isObject(value) && isString(value.id))\n    return value.id;\n  return void 0;\n}\nfunction isValidColumn(columns, column) {\n  if (columns.includes(\"*\"))\n    return true;\n  return columns.filter((item) => isString(item) && item.startsWith(column.name)).length > 0;\n}\nfunction parseIfVersion(...args) {\n  for (const arg of args) {\n    if (isObject(arg) && isNumber(arg.ifVersion)) {\n      return arg.ifVersion;\n    }\n  }\n  return void 0;\n}\n\nvar __accessCheck$3 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$3 = (obj, member, getter) => {\n  __accessCheck$3(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$3 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$3 = (obj, member, value, setter) => {\n  __accessCheck$3(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _map;\nclass SimpleCache {\n  constructor(options = {}) {\n    __privateAdd$3(this, _map, void 0);\n    __privateSet$3(this, _map, /* @__PURE__ */ new Map());\n    this.capacity = options.max ?? 500;\n    this.defaultQueryTTL = options.defaultQueryTTL ?? 60 * 1e3;\n  }\n  async getAll() {\n    return Object.fromEntries(__privateGet$3(this, _map));\n  }\n  async get(key) {\n    return __privateGet$3(this, _map).get(key) ?? null;\n  }\n  async set(key, value) {\n    await this.delete(key);\n    __privateGet$3(this, _map).set(key, value);\n    if (__privateGet$3(this, _map).size > this.capacity) {\n      const leastRecentlyUsed = __privateGet$3(this, _map).keys().next().value;\n      await this.delete(leastRecentlyUsed);\n    }\n  }\n  async delete(key) {\n    __privateGet$3(this, _map).delete(key);\n  }\n  async clear() {\n    return __privateGet$3(this, _map).clear();\n  }\n}\n_map = new WeakMap();\n\nconst greaterThan = (value) => ({ $gt: value });\nconst gt = greaterThan;\nconst greaterThanEquals = (value) => ({ $ge: value });\nconst greaterEquals = greaterThanEquals;\nconst gte = greaterThanEquals;\nconst ge = greaterThanEquals;\nconst lessThan = (value) => ({ $lt: value });\nconst lt = lessThan;\nconst lessThanEquals = (value) => ({ $le: value });\nconst lessEquals = lessThanEquals;\nconst lte = lessThanEquals;\nconst le = lessThanEquals;\nconst exists = (column) => ({ $exists: column });\nconst notExists = (column) => ({ $notExists: column });\nconst startsWith = (value) => ({ $startsWith: value });\nconst endsWith = (value) => ({ $endsWith: value });\nconst pattern = (value) => ({ $pattern: value });\nconst iPattern = (value) => ({ $iPattern: value });\nconst is = (value) => ({ $is: value });\nconst equals = is;\nconst isNot = (value) => ({ $isNot: value });\nconst contains = (value) => ({ $contains: value });\nconst iContains = (value) => ({ $iContains: value });\nconst includes = (value) => ({ $includes: value });\nconst includesAll = (value) => ({ $includesAll: value });\nconst includesNone = (value) => ({ $includesNone: value });\nconst includesAny = (value) => ({ $includesAny: value });\n\nvar __accessCheck$2 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$2 = (obj, member, getter) => {\n  __accessCheck$2(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$2 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$2 = (obj, member, value, setter) => {\n  __accessCheck$2(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar _tables, _schemaTables$1;\nclass SchemaPlugin extends XataPlugin {\n  constructor(schemaTables) {\n    super();\n    __privateAdd$2(this, _tables, {});\n    __privateAdd$2(this, _schemaTables$1, void 0);\n    __privateSet$2(this, _schemaTables$1, schemaTables);\n  }\n  build(pluginOptions) {\n    const db = new Proxy(\n      {},\n      {\n        get: (_target, table) => {\n          if (!isString(table))\n            throw new Error(\"Invalid table name\");\n          if (__privateGet$2(this, _tables)[table] === void 0) {\n            __privateGet$2(this, _tables)[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n          }\n          return __privateGet$2(this, _tables)[table];\n        }\n      }\n    );\n    const tableNames = __privateGet$2(this, _schemaTables$1)?.map(({ name }) => name) ?? [];\n    for (const table of tableNames) {\n      db[table] = new RestRepository({ db, pluginOptions, table, schemaTables: __privateGet$2(this, _schemaTables$1) });\n    }\n    return db;\n  }\n}\n_tables = new WeakMap();\n_schemaTables$1 = new WeakMap();\n\nclass FilesPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      download: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await getFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions,\n          rawResponse: true\n        });\n      },\n      upload: async (location, file, options) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        const resolvedFile = await file;\n        const contentType = options?.mediaType || getContentType(resolvedFile);\n        const body = resolvedFile instanceof XataFile ? resolvedFile.toBlob() : resolvedFile;\n        return await putFileItem({\n          ...pluginOptions,\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          body,\n          headers: { \"Content-Type\": contentType }\n        });\n      },\n      delete: async (location) => {\n        const { table, record, column, fileId = \"\" } = location ?? {};\n        return await deleteFileItem({\n          pathParams: {\n            workspace: \"{workspaceId}\",\n            dbBranchName: \"{dbBranch}\",\n            region: \"{region}\",\n            tableName: table ?? \"\",\n            recordId: record ?? \"\",\n            columnName: column ?? \"\",\n            fileId\n          },\n          ...pluginOptions\n        });\n      }\n    };\n  }\n}\nfunction getContentType(file) {\n  if (typeof file === \"string\") {\n    return \"text/plain\";\n  }\n  if (\"mediaType\" in file && file.mediaType !== void 0) {\n    return file.mediaType;\n  }\n  if (isBlob(file)) {\n    return file.type;\n  }\n  try {\n    return file.type;\n  } catch (e) {\n  }\n  return \"application/octet-stream\";\n}\n\nvar __accessCheck$1 = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet$1 = (obj, member, getter) => {\n  __accessCheck$1(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd$1 = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet$1 = (obj, member, value, setter) => {\n  __accessCheck$1(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod$1 = (obj, member, method) => {\n  __accessCheck$1(obj, member, \"access private method\");\n  return method;\n};\nvar _schemaTables, _search, search_fn, _getSchemaTables, getSchemaTables_fn;\nclass SearchPlugin extends XataPlugin {\n  constructor(db, schemaTables) {\n    super();\n    this.db = db;\n    __privateAdd$1(this, _search);\n    __privateAdd$1(this, _getSchemaTables);\n    __privateAdd$1(this, _schemaTables, void 0);\n    __privateSet$1(this, _schemaTables, schemaTables);\n  }\n  build(pluginOptions) {\n    return {\n      all: async (query, options = {}) => {\n        const { records, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        return {\n          totalCount,\n          records: records.map((record) => {\n            const { table = \"orphan\" } = record.xata;\n            return { table, record: initObject(this.db, schemaTables, table, record, [\"*\"]) };\n          })\n        };\n      },\n      byTable: async (query, options = {}) => {\n        const { records: rawRecords, totalCount } = await __privateMethod$1(this, _search, search_fn).call(this, query, options, pluginOptions);\n        const schemaTables = await __privateMethod$1(this, _getSchemaTables, getSchemaTables_fn).call(this, pluginOptions);\n        const records = rawRecords.reduce((acc, record) => {\n          const { table = \"orphan\" } = record.xata;\n          const items = acc[table] ?? [];\n          const item = initObject(this.db, schemaTables, table, record, [\"*\"]);\n          return { ...acc, [table]: [...items, item] };\n        }, {});\n        return { totalCount, records };\n      }\n    };\n  }\n}\n_schemaTables = new WeakMap();\n_search = new WeakSet();\nsearch_fn = async function(query, options, pluginOptions) {\n  const { tables, fuzziness, highlight, prefix, page } = options ?? {};\n  const { records, totalCount } = await searchBranch({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    // @ts-ignore https://github.com/xataio/client-ts/issues/313\n    body: { tables, query, fuzziness, prefix, highlight, page },\n    ...pluginOptions\n  });\n  return { records, totalCount };\n};\n_getSchemaTables = new WeakSet();\ngetSchemaTables_fn = async function(pluginOptions) {\n  if (__privateGet$1(this, _schemaTables))\n    return __privateGet$1(this, _schemaTables);\n  const { schema } = await getBranchDetails({\n    pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n    ...pluginOptions\n  });\n  __privateSet$1(this, _schemaTables, schema.tables);\n  return schema.tables;\n};\n\nfunction escapeElement(elementRepresentation) {\n  const escaped = elementRepresentation.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, '\\\\\"');\n  return '\"' + escaped + '\"';\n}\nfunction arrayString(val) {\n  let result = \"{\";\n  for (let i = 0; i < val.length; i++) {\n    if (i > 0) {\n      result = result + \",\";\n    }\n    if (val[i] === null || typeof val[i] === \"undefined\") {\n      result = result + \"NULL\";\n    } else if (Array.isArray(val[i])) {\n      result = result + arrayString(val[i]);\n    } else if (val[i] instanceof Buffer) {\n      result += \"\\\\\\\\x\" + val[i].toString(\"hex\");\n    } else {\n      result += escapeElement(prepareValue(val[i]));\n    }\n  }\n  result = result + \"}\";\n  return result;\n}\nfunction prepareValue(value) {\n  if (!isDefined(value))\n    return null;\n  if (value instanceof Date) {\n    return value.toISOString();\n  }\n  if (Array.isArray(value)) {\n    return arrayString(value);\n  }\n  if (isObject(value)) {\n    return JSON.stringify(value);\n  }\n  try {\n    return value.toString();\n  } catch (e) {\n    return value;\n  }\n}\nfunction prepareParams(param1, param2) {\n  if (isString(param1)) {\n    return { statement: param1, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isStringArray(param1)) {\n    const statement = param1.reduce((acc, curr, index) => {\n      return acc + curr + (index < (param2?.length ?? 0) ? \"$\" + (index + 1) : \"\");\n    }, \"\");\n    return { statement, params: param2?.map((value) => prepareValue(value)) };\n  }\n  if (isObject(param1)) {\n    const { statement, params, consistency } = param1;\n    return { statement, params: params?.map((value) => prepareValue(value)), consistency };\n  }\n  throw new Error(\"Invalid query\");\n}\n\nclass SQLPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return async (param1, ...param2) => {\n      const { statement, params, consistency } = prepareParams(param1, param2);\n      const { records, warning } = await sqlQuery({\n        pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n        body: { statement, params, consistency },\n        ...pluginOptions\n      });\n      return { records, warning };\n    };\n  }\n}\n\nclass TransactionPlugin extends XataPlugin {\n  build(pluginOptions) {\n    return {\n      run: async (operations) => {\n        const response = await branchTransaction({\n          pathParams: { workspace: \"{workspaceId}\", dbBranchName: \"{dbBranch}\", region: \"{region}\" },\n          body: { operations },\n          ...pluginOptions\n        });\n        return response;\n      }\n    };\n  }\n}\n\nvar __accessCheck = (obj, member, msg) => {\n  if (!member.has(obj))\n    throw TypeError(\"Cannot \" + msg);\n};\nvar __privateGet = (obj, member, getter) => {\n  __accessCheck(obj, member, \"read from private field\");\n  return getter ? getter.call(obj) : member.get(obj);\n};\nvar __privateAdd = (obj, member, value) => {\n  if (member.has(obj))\n    throw TypeError(\"Cannot add the same private member more than once\");\n  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);\n};\nvar __privateSet = (obj, member, value, setter) => {\n  __accessCheck(obj, member, \"write to private field\");\n  setter ? setter.call(obj, value) : member.set(obj, value);\n  return value;\n};\nvar __privateMethod = (obj, member, method) => {\n  __accessCheck(obj, member, \"access private method\");\n  return method;\n};\nconst buildClient = (plugins) => {\n  var _options, _parseOptions, parseOptions_fn, _getFetchProps, getFetchProps_fn, _a;\n  return _a = class {\n    constructor(options = {}, schemaTables) {\n      __privateAdd(this, _parseOptions);\n      __privateAdd(this, _getFetchProps);\n      __privateAdd(this, _options, void 0);\n      const safeOptions = __privateMethod(this, _parseOptions, parseOptions_fn).call(this, options);\n      __privateSet(this, _options, safeOptions);\n      const pluginOptions = {\n        ...__privateMethod(this, _getFetchProps, getFetchProps_fn).call(this, safeOptions),\n        cache: safeOptions.cache,\n        host: safeOptions.host\n      };\n      const db = new SchemaPlugin(schemaTables).build(pluginOptions);\n      const search = new SearchPlugin(db, schemaTables).build(pluginOptions);\n      const transactions = new TransactionPlugin().build(pluginOptions);\n      const sql = new SQLPlugin().build(pluginOptions);\n      const files = new FilesPlugin().build(pluginOptions);\n      this.db = db;\n      this.search = search;\n      this.transactions = transactions;\n      this.sql = sql;\n      this.files = files;\n      for (const [key, namespace] of Object.entries(plugins ?? {})) {\n        if (namespace === void 0)\n          continue;\n        this[key] = namespace.build(pluginOptions);\n      }\n    }\n    async getConfig() {\n      const databaseURL = __privateGet(this, _options).databaseURL;\n      const branch = __privateGet(this, _options).branch;\n      return { databaseURL, branch };\n    }\n  }, _options = new WeakMap(), _parseOptions = new WeakSet(), parseOptions_fn = function(options) {\n    const enableBrowser = options?.enableBrowser ?? getEnableBrowserVariable() ?? false;\n    const isBrowser = typeof window !== \"undefined\" && typeof Deno === \"undefined\";\n    if (isBrowser && !enableBrowser) {\n      throw new Error(\n        \"You are trying to use Xata from the browser, which is potentially a non-secure environment. If you understand the security concerns, such as leaking your credentials, pass `enableBrowser: true` to the client options to remove this error.\"\n      );\n    }\n    const fetch = getFetchImplementation(options?.fetch);\n    const databaseURL = options?.databaseURL || getDatabaseURL();\n    const apiKey = options?.apiKey || getAPIKey();\n    const cache = options?.cache ?? new SimpleCache({ defaultQueryTTL: 0 });\n    const trace = options?.trace ?? defaultTrace;\n    const clientName = options?.clientName;\n    const host = options?.host ?? \"production\";\n    const xataAgentExtra = options?.xataAgentExtra;\n    if (!apiKey) {\n      throw new Error(\"Option apiKey is required\");\n    }\n    if (!databaseURL) {\n      throw new Error(\"Option databaseURL is required\");\n    }\n    const envBranch = getBranch();\n    const previewBranch = getPreviewBranch();\n    const branch = options?.branch || previewBranch || envBranch || \"main\";\n    if (!!previewBranch && branch !== previewBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!envBranch && branch !== envBranch) {\n      console.warn(\n        `Ignoring branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!!previewBranch && !!envBranch && previewBranch !== envBranch) {\n      console.warn(\n        `Ignoring preview branch ${previewBranch} and branch ${envBranch} because branch option was passed to the client constructor with value ${branch}`\n      );\n    } else if (!previewBranch && !envBranch && options?.branch === void 0) {\n      console.warn(\n        `No branch was passed to the client constructor. Using default branch ${branch}. You can set the branch with the environment variable XATA_BRANCH or by passing the branch option to the client constructor.`\n      );\n    }\n    return {\n      fetch,\n      databaseURL,\n      apiKey,\n      branch,\n      cache,\n      trace,\n      host,\n      clientID: generateUUID(),\n      enableBrowser,\n      clientName,\n      xataAgentExtra\n    };\n  }, _getFetchProps = new WeakSet(), getFetchProps_fn = function({\n    fetch,\n    apiKey,\n    databaseURL,\n    branch,\n    trace,\n    clientID,\n    clientName,\n    xataAgentExtra\n  }) {\n    return {\n      fetch,\n      apiKey,\n      apiUrl: \"\",\n      // Instead of using workspace and dbBranch, we inject a probably CNAME'd URL\n      workspacesApiUrl: (path, params) => {\n        const hasBranch = params.dbBranchName ?? params.branch;\n        const newPath = path.replace(/^\\/db\\/[^/]+/, hasBranch !== void 0 ? `:${branch}` : \"\");\n        return databaseURL + newPath;\n      },\n      trace,\n      clientID,\n      clientName,\n      xataAgentExtra\n    };\n  }, _a;\n};\nclass BaseClient extends buildClient() {\n}\n\nconst META = \"__\";\nconst VALUE = \"___\";\nclass Serializer {\n  constructor() {\n    this.classes = {};\n  }\n  add(clazz) {\n    this.classes[clazz.name] = clazz;\n  }\n  toJSON(data) {\n    function visit(obj) {\n      if (Array.isArray(obj))\n        return obj.map(visit);\n      const type = typeof obj;\n      if (type === \"undefined\")\n        return { [META]: \"undefined\" };\n      if (type === \"bigint\")\n        return { [META]: \"bigint\", [VALUE]: obj.toString() };\n      if (obj === null || type !== \"object\")\n        return obj;\n      const constructor = obj.constructor;\n      const o = { [META]: constructor.name };\n      for (const [key, value] of Object.entries(obj)) {\n        o[key] = visit(value);\n      }\n      if (constructor === Date)\n        o[VALUE] = obj.toISOString();\n      if (constructor === Map)\n        o[VALUE] = Object.fromEntries(obj);\n      if (constructor === Set)\n        o[VALUE] = [...obj];\n      return o;\n    }\n    return JSON.stringify(visit(data));\n  }\n  fromJSON(json) {\n    return JSON.parse(json, (key, value) => {\n      if (value && typeof value === \"object\" && !Array.isArray(value)) {\n        const { [META]: clazz, [VALUE]: val, ...rest } = value;\n        const constructor = this.classes[clazz];\n        if (constructor) {\n          return Object.assign(Object.create(constructor.prototype), rest);\n        }\n        if (clazz === \"Date\")\n          return new Date(val);\n        if (clazz === \"Set\")\n          return new Set(val);\n        if (clazz === \"Map\")\n          return new Map(Object.entries(val));\n        if (clazz === \"bigint\")\n          return BigInt(val);\n        if (clazz === \"undefined\")\n          return void 0;\n        return rest;\n      }\n      return value;\n    });\n  }\n}\nconst defaultSerializer = new Serializer();\nconst serialize = (data) => {\n  return defaultSerializer.toJSON(data);\n};\nconst deserialize = (json) => {\n  return defaultSerializer.fromJSON(json);\n};\n\nclass XataError extends Error {\n  constructor(message, status) {\n    super(message);\n    this.status = status;\n  }\n}\n\nexport { BaseClient, FetcherError, FilesPlugin, operationsByTag as Operations, PAGINATION_DEFAULT_OFFSET, PAGINATION_DEFAULT_SIZE, PAGINATION_MAX_OFFSET, PAGINATION_MAX_SIZE, Page, Query, RecordArray, RecordColumnTypes, Repository, RestRepository, SQLPlugin, SchemaPlugin, SearchPlugin, Serializer, SimpleCache, TransactionPlugin, XataApiClient, XataApiPlugin, XataError, XataFile, XataPlugin, acceptWorkspaceMemberInvite, addGitBranchesEntry, addTableColumn, aggregateTable, applyBranchSchemaEdit, applyMigration, askTable, askTableSession, branchTransaction, buildClient, buildPreviewBranchName, buildProviderString, bulkInsertTableRecords, cancelWorkspaceMemberInvite, compareBranchSchemas, compareBranchWithUserSchema, compareMigrationRequest, contains, copyBranch, createBranch, createCluster, createDatabase, createMigrationRequest, createTable, createUserAPIKey, createWorkspace, deleteBranch, deleteColumn, deleteDatabase, deleteDatabaseGithubSettings, deleteFile, deleteFileItem, deleteOAuthAccessToken, deleteRecord, deleteTable, deleteUser, deleteUserAPIKey, deleteUserOAuthClient, deleteWorkspace, deserialize, endsWith, equals, executeBranchMigrationPlan, exists, fileAccess, fileUpload, ge, getAPIKey, getAuthorizationCode, getBranch, getBranchDetails, getBranchList, getBranchMetadata, getBranchMigrationHistory, getBranchMigrationPlan, getBranchSchemaHistory, getBranchStats, getCluster, getColumn, getDatabaseGithubSettings, getDatabaseList, getDatabaseMetadata, getDatabaseURL, getFile, getFileItem, getGitBranchesMapping, getHostUrl, getMigrationRequest, getMigrationRequestIsMerged, getPreviewBranch, getRecord, getSchema, getTableColumns, getTableSchema, getUser, getUserAPIKeys, getUserOAuthAccessTokens, getUserOAuthClients, getWorkspace, getWorkspaceMembersList, getWorkspacesList, grantAuthorizationCode, greaterEquals, greaterThan, greaterThanEquals, gt, gte, iContains, iPattern, includes, includesAll, includesAny, includesNone, insertRecord, insertRecordWithID, inviteWorkspaceMember, is, isCursorPaginationOptions, isHostProviderAlias, isHostProviderBuilder, isIdentifiable, isNot, isValidExpandedColumn, isValidSelectableColumns, isXataRecord, le, lessEquals, lessThan, lessThanEquals, listClusters, listMigrationRequestsCommits, listRegions, lt, lte, mergeMigrationRequest, notExists, operationsByTag, parseProviderString, parseWorkspacesUrlParts, pattern, pgRollJobStatus, pgRollStatus, previewBranchSchemaEdit, pushBranchMigrations, putFile, putFileItem, queryMigrationRequests, queryTable, removeGitBranchesEntry, removeWorkspaceMember, renameDatabase, resendWorkspaceMemberInvite, resolveBranch, searchBranch, searchTable, serialize, setTableSchema, sqlQuery, startsWith, summarizeTable, transformImage, updateBranchMetadata, updateBranchSchema, updateCluster, updateColumn, updateDatabaseGithubSettings, updateDatabaseMetadata, updateMigrationRequest, updateOAuthAccessToken, updateRecordWithID, updateTable, updateUser, updateWorkspace, updateWorkspaceMemberInvite, updateWorkspaceMemberRole, upsertRecordWithID, vectorSearchTable };\n//# sourceMappingURL=index.mjs.map\n",
  "// Generated by Xata Codegen 0.28.0. Please do not edit.\nimport { buildClient } from \"@xata.io/client\";\nimport type {\n  BaseClientOptions,\n  SchemaInference,\n  XataRecord,\n} from \"@xata.io/client\";\n\nconst tables = [\n  {\n    name: \"user\",\n    columns: [\n      { name: \"firstname\", type: \"text\" },\n      { name: \"lastname\", type: \"text\" },\n      { name: \"password\", type: \"string\" },\n      { name: \"email\", type: \"email\", unique: true },\n      { name: \"username\", type: \"string\", unique: true },\n    ],\n  },\n] as const;\n\nexport type SchemaTables = typeof tables;\nexport type InferredTypes = SchemaInference<SchemaTables>;\n\nexport type User = InferredTypes[\"user\"];\nexport type UserRecord = User & XataRecord;\n\nexport type DatabaseSchema = {\n  user: UserRecord;\n};\n\nconst DatabaseClient = buildClient();\n\nconst defaultOptions = {\n  databaseURL:\n    \"https://steam-learn-db-q51rvp.eu-west-1.xata.sh/db/steamlearndb\",\n};\n\nexport class XataClient extends DatabaseClient<DatabaseSchema> {\n  constructor(options?: BaseClientOptions) {\n    super({ ...defaultOptions, ...options }, tables);\n  }\n}\n\nlet instance: XataClient | undefined = undefined;\n\nexport const getXataClient = () => {\n  if (instance) return instance;\n\n  instance = new XataClient();\n  return instance;\n};\n",
  "import { Hono } from \"hono\";\nimport { getXataClient } from \"../../db/src/xata\";\n\nconst app = new Hono();\nconst xata = getXataClient();\nconst users = xata.db.user.getAll();\nconsole.log(users);\napp.get(\"/\", async (c) => c.json(await users));\napp.get('/:id', (c) => c.json(`get ${c.req.param('id')}`))\nexport default app;\n",
  "import { Hono } from \"hono\";\nimport { prettyJSON } from \"hono/pretty-json\";\nimport users from \"./users\";\nconst hono = new Hono().basePath('/api');\nhono.use(\"*\", prettyJSON());\nconst route = hono.route('/users',users)\n\nconsole.log(hono.all)\n\nexport default {\n    port: 3000,\n    fetch: hono.fetch,\n  };\n\nexport type AppType = typeof route;\n\n"
  ],
  "mappings": "AACA,IAAI,GAAY,CAAC,IAAS,CACxB,MAAM,EAAQ,EAAK,MAAM,GAAG,EAC5B,GAAI,EAAM,KAAO,GACf,EAAM,MAAM,EAEd,OAAO,GAEL,GAAmB,CAAC,IAAS,CAC/B,MAAM,EAAS,CAAC,EAChB,QAAS,EAAI,IAAO,CAClB,IAAI,EAAW,GAQf,GAPA,EAAO,EAAK,QAAQ,aAAc,CAAC,IAAM,CACvC,MAAM,EAAO,MAAM,IAInB,OAHA,EAAO,GAAK,CAAC,EAAM,CAAC,EACpB,IACA,EAAW,GACJ,EACR,GACI,EACH,MAGJ,MAAM,EAAQ,EAAK,MAAM,GAAG,EAC5B,GAAI,EAAM,KAAO,GACf,EAAM,MAAM,EAEd,QAAS,EAAI,EAAO,OAAS,EAAG,GAAK,EAAG,IAAK,CAC3C,MAAO,GAAQ,EAAO,GACtB,QAAS,EAAI,EAAM,OAAS,EAAG,GAAK,EAAG,IACrC,GAAI,EAAM,GAAG,QAAQ,CAAI,KAAM,EAAI,CACjC,EAAM,GAAK,EAAM,GAAG,QAAQ,EAAM,EAAO,GAAG,EAAE,EAC9C,OAIN,OAAO,GAEL,GAAe,CAAC,EAChB,GAAa,CAAC,IAAU,CAC1B,GAAI,IAAU,IACZ,MAAO,IAET,MAAM,EAAQ,EAAM,MAAM,6BAA6B,EACvD,GAAI,EAAO,CACT,IAAK,GAAa,GAChB,GAAI,EAAM,GACR,GAAa,GAAS,CAAC,EAAO,EAAM,GAAI,IAAI,OAAO,IAAM,EAAM,GAAK,GAAG,CAAC,MAExE,IAAa,GAAS,CAAC,EAAO,EAAM,GAAI,EAAI,EAGhD,OAAO,GAAa,GAEtB,OAAO,MAEL,GAAU,CAAC,IAAY,CACzB,MAAM,EAAQ,EAAQ,IAAI,MAAM,4BAA4B,EAC5D,OAAO,EAAQ,EAAM,GAAK,IAExB,GAAkB,CAAC,IAAQ,CAC7B,MAAM,EAAa,EAAI,QAAQ,IAAK,CAAC,EACrC,OAAO,KAAe,EAAK,GAAK,IAAM,EAAI,MAAM,EAAa,CAAC,GAE5D,GAAkB,CAAC,IAAY,CACjC,MAAM,EAAS,GAAQ,CAAO,EAC9B,OAAO,EAAO,OAAS,GAAK,EAAO,EAAO,OAAS,KAAO,IAAM,EAAO,MAAM,GAAG,CAAE,EAAI,GAEpF,GAAY,IAAI,IAAU,CAC5B,IAAI,EAAI,GACJ,EAAgB,GACpB,QAAS,KAAQ,EAAO,CACtB,GAAI,EAAE,EAAE,OAAS,KAAO,IACtB,EAAI,EAAE,MAAM,GAAG,CAAE,EACjB,EAAgB,GAElB,GAAI,EAAK,KAAO,IACd,EAAO,IAAI,IAEb,GAAI,IAAS,KAAO,EAClB,EAAI,GAAG,aACE,IAAS,IAClB,EAAI,GAAG,IAAI,IAEb,GAAI,IAAS,KAAO,IAAM,GACxB,EAAI,IAGR,OAAO,GAEL,GAAyB,CAAC,IAAS,CACrC,MAAM,EAAQ,EAAK,MAAM,uBAAuB,EAChD,IAAK,EACH,OAAO,KACT,MAAM,EAAO,EAAM,GACb,EAAW,EAAO,EAAM,GAC9B,MAAO,CAAC,IAAS,GAAK,IAAM,EAAK,QAAQ,MAAO,EAAE,EAAG,CAAQ,GAE3D,GAAa,CAAC,IAAU,CAC1B,IAAK,OAAO,KAAK,CAAK,EACpB,OAAO,EAET,GAAI,EAAM,QAAQ,GAAG,KAAM,EACzB,EAAQ,EAAM,QAAQ,MAAO,GAAG,EAElC,MAAO,IAAI,KAAK,CAAK,EAAI,GAAoB,CAAK,EAAI,GAEpD,GAAiB,CAAC,EAAK,EAAK,IAAa,CAC3C,IAAI,EACJ,IAAK,GAAY,IAAQ,OAAO,KAAK,CAAG,EAAG,CACzC,IAAI,EAAY,EAAI,QAAQ,IAAI,IAAO,CAAC,EACxC,GAAI,KAAc,EAChB,EAAY,EAAI,QAAQ,IAAI,IAAO,CAAC,EAEtC,MAAO,KAAc,EAAI,CACvB,MAAM,EAAkB,EAAI,WAAW,EAAY,EAAI,OAAS,CAAC,EACjE,GAAI,IAAoB,GAAI,CAC1B,MAAM,EAAa,EAAY,EAAI,OAAS,EACtC,EAAW,EAAI,QAAQ,IAAK,CAAU,EAC5C,OAAO,GAAW,EAAI,MAAM,EAAY,KAAa,EAAU,OAAI,CAAQ,CAAC,UACnE,GAAmB,IAAM,MAAM,CAAe,EACvD,MAAO,GAET,EAAY,EAAI,QAAQ,IAAI,IAAO,EAAY,CAAC,EAGlD,GADA,EAAU,OAAO,KAAK,CAAG,GACpB,EACH,OAGJ,MAAM,EAAU,CAAC,EACjB,IAAY,EAAU,OAAO,KAAK,CAAG,GACrC,IAAI,EAAW,EAAI,QAAQ,IAAK,CAAC,EACjC,MAAO,KAAa,EAAI,CACtB,MAAM,EAAe,EAAI,QAAQ,IAAK,EAAW,CAAC,EAClD,IAAI,EAAa,EAAI,QAAQ,IAAK,CAAQ,EAC1C,GAAI,EAAa,GAAgB,KAAiB,EAChD,GAAa,EAEf,IAAI,EAAO,EAAI,MACb,EAAW,EACX,KAAe,EAAK,KAAiB,EAAU,OAAI,EAAe,CACpE,EACA,GAAI,EACF,EAAO,GAAW,CAAI,EAGxB,GADA,EAAW,EACP,IAAS,GACX,SAEF,IAAI,EACJ,GAAI,KAAe,EACjB,EAAQ,WAER,EAAQ,EAAI,MAAM,EAAa,EAAG,KAAiB,EAAU,OAAI,CAAY,EACzE,EACF,EAAQ,GAAW,CAAK,EAG5B,GAAI,EAAU,CACZ,KAAM,EAAQ,IAAS,MAAM,QAAQ,EAAQ,EAAK,GAChD,EAAQ,GAAQ,CAAC,EAGnB,EAAQ,GAAM,KAAK,CAAK,MAExB,GAAQ,KAAU,EAAQ,GAAQ,GAGtC,OAAO,EAAM,EAAQ,GAAO,GAE1B,GAAgB,GAChB,GAAiB,CAAC,EAAK,IAAQ,CACjC,OAAO,GAAe,EAAK,EAAK,EAAI,GAElC,GAAsBACxJ1B,IAAI,GAAuB,wBACvB,GAAwB,oBACxB,GAAQ,CAAC,EAAQ,IAAS,CAE5B,OADc,EAAO,KAAK,EAAE,MAAM,GAAG,EACxB,OAAO,CAAC,EAAc,IAAY,CAC7C,EAAU,EAAQ,KAAK,EACvB,MAAM,EAAgB,EAAQ,QAAQ,GAAG,EACzC,GAAI,KAAkB,EACpB,OAAO,EACT,MAAM,EAAa,EAAQ,UAAU,EAAG,CAAa,EAAE,KAAK,EAC5D,GAAI,GAAQ,IAAS,IAAe,GAAqB,KAAK,CAAU,EACtE,OAAO,EACT,IAAI,EAAc,EAAQ,UAAU,EAAgB,CAAC,EAAE,KAAK,EAC5D,GAAI,EAAY,WAAW,GAAG,GAAK,EAAY,SAAS,GAAG,EACzD,EAAc,EAAY,MAAM,GAAG,CAAE,EACvC,GAAI,GAAsB,KAAK,CAAW,EACxC,EAAa,GAAc,GAAoB,CAAW,EAC5D,OAAO,GACN,CAAC,CAACACwBP,IAAI,GAAgB,CAAC,EAAK,IAAW,CACnC,IAAK,EAAI,WAAW,OAClB,OAAO,QAAQ,QAAQ,CAAG,EAE5B,MAAM,EAAY,EAAI,UACtB,GAAI,EACF,EAAO,IAAM,MAEb,GAAS,CAAC,CAAG,EAEf,OAAO,QAAQ,IAAI,EAAU,IAAI,CAAC,IAAM,EAAE,CAAE,QAAO,CAAC,CAAC,CAAC,EAAE,KACtD,CAAC,IAAQ,QAAQ,IAAI,EAAI,IAAI,CAAC,IAAS,GAAc,EAAM,CAAM,CAAC,CAAC,EAAE,KAAK,IAAM,EAAO,EAAE,CAC3FAC5EF,IAAI,GAAe,KAAM,CACvB,WAAW,CAAC,EAAU,CACpB,KAAK,SAAW,EAChB,KAAK,OAAS,EAAS,UAAU,EACjC,KAAK,QAAU,IAAI,iBAEf,MAAK,CAAC,EAAO,CACjB,GAAI,CACF,UAAW,IAAU,SACnB,EAAQ,KAAK,QAAQ,OAAO,CAAK,EAEnC,MAAM,KAAK,OAAO,MAAM,CAAK,QACtB,EAAP,EAEF,OAAO,UAEH,QAAO,CAAC,EAAO,CAEnB,OADA,MAAM,KAAK,MAAM,EAAQ,IAAI,EACtB,KAET,KAAK,CAAC,EAAI,CACR,OAAO,IAAI,QAAQ,CAAC,IAAQ,WAAW,EAAK,CAAE,CAAC,OAE3C,MAAK,EAAG,CACZ,GAAI,CACF,MAAM,KAAK,OAAO,MAAM,QACjB,EAAP,QAGE,KAAI,CAAC,EAAM,CACf,KAAK,OAAO,YAAY,EACxB,MAAM,EAAK,OAAO,KAAK,SAAU,CAAE,aAAc,EAAK,CAAC,EACvD,KAAK,OAAS,KAAK,SAAS,UAAU,EAE1CACnCA,IAAI,GAAgB,CAAC,EAAK,EAAQ,IAAQ,CACxC,IAAK,EAAO,IAAI,CAAG,EACjB,MAAM,UAAU,UAAY,CAAG,GAE/B,EAAe,CAAC,EAAK,EAAQ,IAAW,CAE1C,OADA,GAAc,EAAK,EAAQ,yBAAyB,EAC7C,EAAS,EAAO,KAAK,CAAG,EAAI,EAAO,IAAI,CAAG,GAE/C,GAAe,CAAC,EAAK,EAAQ,IAAU,CACzC,GAAI,EAAO,IAAI,CAAG,EAChB,MAAM,UAAU,mDAAmD,EACrE,aAAkB,QAAU,EAAO,IAAI,CAAG,EAAI,EAAO,IAAI,EAAK,CAAK,GAEjE,EAAe,CAAC,EAAK,EAAQ,EAAO,IAAW,CAGjD,OAFA,GAAc,EAAK,EAAQ,wBAAwB,EACnD,EAAS,EAAO,KAAK,EAAK,CAAK,EAAI,EAAO,IAAI,EAAK,CAAK,EACjD,GAOL,GAAa,4BACb,GAAS,GAAe,EAAU,EAAkB,EAAM,GAC1D,GAAU,KAAM,CAClB,WAAW,CAAC,EAAK,EAAS,CAqKxB,GApKA,KAAK,IAAM,CAAC,EACZ,KAAK,KAAO,CAAC,EACb,KAAK,UAAY,GACjB,KAAK,MAAa,OAClB,GAAa,KAAM,GAAS,GAAG,EAC/B,GAAa,KAAM,GAAoB,MAAC,EACxC,GAAa,KAAM,EAAe,MAAC,EACnC,GAAa,KAAM,EAAuB,MAAC,EAC3C,GAAa,KAAM,EAAW,MAAC,EAC/B,GAAa,KAAM,GAAU,EAAI,EACjC,KAAK,SAAW,CAAC,IAAY,KAAK,KAAK,CAAO,EAC9C,KAAK,gBAAkB,IAAM,IAAI,SACjC,KAAK,OAAS,IAAI,IAAS,KAAK,SAAS,GAAG,CAAI,EAChD,KAAK,YAAc,CAAC,IAAa,CAC/B,KAAK,SAAW,GAElB,KAAK,OAAS,CAAC,EAAM,EAAO,IAAY,CACtC,GAAI,IAAe,OAAG,CACpB,GAAI,EAAa,KAAM,CAAQ,EAC7B,EAAa,KAAM,CAAQ,EAAE,OAAO,CAAI,UAC/B,EAAa,KAAM,CAAgB,EAC5C,OAAO,EAAa,KAAM,CAAgB,EAAE,EAAK,kBAAkB,GAErE,GAAI,KAAK,UACP,KAAK,IAAI,QAAQ,OAAO,CAAI,EAE9B,OAEF,GAAI,GAAS,OAAQ,CACnB,IAAK,EAAa,KAAM,CAAQ,EAC9B,EAAa,KAAM,GAAU,EAAK,EAClC,EAAa,KAAM,EAAU,IAAI,QAAQ,EAAa,KAAM,CAAgB,CAAC,CAAC,EAC9E,EAAa,KAAM,EAAkB,CAAC,CAAC,EAEzC,EAAa,KAAM,CAAQ,EAAE,OAAO,EAAM,CAAK,UAE3C,EAAa,KAAM,CAAQ,EAC7B,EAAa,KAAM,CAAQ,EAAE,IAAI,EAAM,CAAK,MAE5C,GAAa,KAAM,CAAgB,GAAK,EAAa,KAAM,EAAkB,CAAC,CAAC,EAC/E,EAAa,KAAM,CAAgB,EAAE,EAAK,YAAY,GAAK,EAG/D,GAAI,KAAK,UACP,GAAI,GAAS,OACX,KAAK,IAAI,QAAQ,OAAO,EAAM,CAAK,MAEnC,MAAK,IAAI,QAAQ,IAAI,EAAM,CAAK,GAItC,KAAK,OAAS,CAAC,IAAW,CACxB,EAAa,KAAM,GAAU,EAAK,EAClC,EAAa,KAAM,GAAS,CAAM,GAEpC,KAAK,IAAM,CAAC,EAAK,IAAU,CACzB,KAAK,OAAS,KAAK,KAAO,CAAC,GAC3B,KAAK,KAAK,GAAO,GAEnB,KAAK,IAAM,CAAC,IAAQ,CAClB,OAAO,KAAK,KAAO,KAAK,KAAK,GAAY,QAE3C,KAAK,YAAc,CAAC,EAAM,EAAK,IAAY,CACzC,GAAI,EAAa,KAAM,EAAQ,IAAM,IAAY,GAAO,EAAa,KAAM,EAAO,IAAM,IACtF,OAAO,IAAI,SAAS,EAAM,CACxB,QAAS,EAAa,KAAM,CAAgB,CAC9C,CAAC,EAEH,GAAI,UAAc,IAAQ,SACxB,KAAK,IAAM,IAAI,SAAS,EAAM,CAAG,EAEnC,MAAM,SAAgB,IAAQ,SAAW,EAAM,EAAM,EAAI,OAAS,EAAa,KAAM,EAAO,EAC5F,EAAa,KAAM,CAAgB,GAAK,EAAa,KAAM,EAAkB,CAAC,CAAC,EAC/E,EAAa,KAAM,CAAQ,GAAK,EAAa,KAAM,EAAU,IAAI,OAAS,EAC1E,QAAY,EAAG,KAAM,OAAO,QAAQ,EAAa,KAAM,CAAgB,CAAC,EACtE,EAAa,KAAM,CAAQ,EAAE,IAAI,EAAG,CAAC,EAEvC,GAAI,EAAa,KAAM,CAAI,EAAG,CAC5B,EAAa,KAAM,CAAI,EAAE,QAAQ,QAAQ,CAAC,EAAG,IAAM,CACjD,EAAa,KAAM,CAAQ,GAAG,IAAI,EAAG,CAAC,EACvC,EACD,QAAY,EAAG,KAAM,OAAO,QAAQ,EAAa,KAAM,CAAgB,CAAC,EACtE,EAAa,KAAM,CAAQ,EAAE,IAAI,EAAG,CAAC,EAGzC,IAAY,EAAU,CAAC,GACvB,QAAY,EAAG,KAAM,OAAO,QAAQ,CAAO,EACzC,UAAW,IAAM,SACf,EAAa,KAAM,CAAQ,EAAE,IAAI,EAAG,CAAC,MAChC,CACL,EAAa,KAAM,CAAQ,EAAE,OAAO,CAAC,EACrC,QAAW,KAAM,EACf,EAAa,KAAM,CAAQ,EAAE,OAAO,EAAG,CAAE,EAI/C,OAAO,IAAI,SAAS,EAAM,CACxB,SACA,QAAS,EAAa,KAAM,CAAQ,CACtC,CAAC,GAEH,KAAK,KAAO,CAAC,EAAM,EAAK,IAAY,CAClC,cAAc,IAAQ,SAAW,KAAK,YAAY,EAAM,EAAK,CAAO,EAAI,KAAK,YAAY,EAAM,CAAG,GAEpG,KAAK,KAAO,CAAC,EAAM,EAAK,IAAY,CAClC,IAAK,EAAa,KAAM,CAAgB,EAAG,CACzC,GAAI,EAAa,KAAM,EAAQ,IAAM,IAAY,EAC/C,OAAO,IAAI,SAAS,CAAI,EAE1B,EAAa,KAAM,EAAkB,CAAC,CAAC,EAGzC,OADA,EAAa,KAAM,CAAgB,EAAE,gBAAkB,UACzC,IAAQ,SAAW,KAAK,YAAY,EAAM,EAAK,CAAO,EAAI,KAAK,YAAY,EAAM,CAAG,GAEpG,KAAK,KAAO,CAAC,EAAQ,EAAK,IAAY,CACpC,MAAM,EAAO,KAAK,UAAU,CAAM,EAGlC,OAFA,EAAa,KAAM,CAAgB,GAAK,EAAa,KAAM,EAAkB,CAAC,CAAC,EAC/E,EAAa,KAAM,CAAgB,EAAE,gBAAkB,yCACzC,IAAQ,SAAW,KAAK,YAAY,EAAM,EAAK,CAAO,EAAI,KAAK,YAAY,EAAM,CAAG,GAEpG,KAAK,MAAQ,CAAC,EAAQ,EAAK,IAAY,CACrC,OAAO,KAAK,KAAK,EAAQ,EAAK,CAAO,GAEvC,KAAK,KAAO,CAAC,EAAM,EAAK,IAAY,CAGlC,GAFA,EAAa,KAAM,CAAgB,GAAK,EAAa,KAAM,EAAkB,CAAC,CAAC,EAC/E,EAAa,KAAM,CAAgB,EAAE,gBAAkB,kCAC5C,IAAS,SAAU,CAC5B,KAAM,aAAgB,SACpB,EAAO,EAAK,SAAS,EAEvB,GAAI,aAAgB,QAClB,OAAO,EAAK,KAAK,CAAC,IAAU,GAAc,CAAK,CAAC,EAAE,KAAK,CAAC,IAAU,CAChE,cAAc,IAAQ,SAAW,KAAK,YAAY,EAAO,EAAK,CAAO,EAAI,KAAK,YAAY,EAAO,CAAG,EACrG,EAGL,cAAc,IAAQ,SAAW,KAAK,YAAY,EAAM,EAAK,CAAO,EAAI,KAAK,YAAY,EAAM,CAAG,GAEpG,KAAK,SAAW,CAAC,EAAU,EAAS,MAAQ,CAG1C,OAFA,EAAa,KAAM,CAAQ,GAAK,EAAa,KAAM,EAAU,IAAI,OAAS,EAC1E,EAAa,KAAM,CAAQ,EAAE,IAAI,WAAY,CAAQ,EAC9C,KAAK,YAAY,KAAM,CAAM,GAEtC,KAAK,WAAa,CAAC,EAAI,EAAK,IAAY,CAKtC,OAJA,IAAY,EAAU,CAAC,GACvB,KAAK,OAAO,eAAgB,EAAU,EACtC,KAAK,OAAO,yBAA0B,SAAS,EAC/C,KAAK,OAAO,oBAAqB,SAAS,EACnC,KAAK,OAAO,EAAI,EAAK,CAAO,GAErC,KAAK,OAAS,CAAC,EAAI,EAAK,IAAY,CAClC,MAAQ,WAAU,YAAa,IAAI,gBAC7B,EAAS,IAAI,GAAa,CAAQ,EAExC,OADA,EAAG,CAAM,EAAE,QAAQ,IAAM,EAAO,MAAM,CAAC,SACzB,IAAQ,SAAW,KAAK,YAAY,EAAU,EAAK,CAAO,EAAI,KAAK,YAAY,EAAU,CAAG,GAE5G,KAAK,OAAS,CAAC,EAAM,EAAO,IAAQ,CAClC,MAAM,EAAS,GAAU,EAAM,EAAO,CAAG,EACzC,KAAK,OAAO,aAAc,EAAQ,CAAE,OAAQ,EAAK,CAAC,GAEpD,KAAK,SAAW,IAAM,CACpB,OAAO,KAAK,gBAAgB,IAAI,GAElC,KAAK,IAAM,EACP,GAGF,GAFA,EAAa,KAAM,GAAe,EAAQ,YAAY,EACtD,KAAK,IAAM,EAAQ,IACf,EAAQ,gBACV,KAAK,gBAAkB,EAAQ,oBAIjC,MAAK,EAAG,CACV,GAAI,EAAa,KAAM,EAAa,GAAK,gBAAiB,EAAa,KAAM,EAAa,EACxF,OAAO,EAAa,KAAM,EAAa,MAEvC,OAAM,MAAM,gCAAgC,KAG5C,aAAY,EAAG,CACjB,GAAI,EAAa,KAAM,EAAa,EAClC,OAAO,EAAa,KAAM,EAAa,MAEvC,OAAM,MAAM,sCAAsC,KAGlD,IAAG,EAAG,CAER,OADA,EAAa,KAAM,GAAU,EAAK,EAC3B,EAAa,KAAM,CAAI,GAAK,EAAa,KAAM,EAAM,IAAI,SAAS,gBAAiB,CAAE,OAAQ,GAAI,CAAC,CAAC,KAExG,IAAG,CAAC,EAAO,CAEb,GADA,EAAa,KAAM,GAAU,EAAK,EAC9B,EAAa,KAAM,CAAI,GAAK,EAC9B,EAAa,KAAM,CAAI,EAAE,QAAQ,OAAO,cAAc,EACtD,EAAa,KAAM,CAAI,EAAE,QAAQ,QAAQ,CAAC,EAAG,IAAM,CACjD,EAAM,QAAQ,IAAI,EAAG,CAAC,EACvB,EAEH,EAAa,KAAM,EAAM,CAAK,EAC9B,KAAK,UAAY,MAEf,IAAG,EAAG,CACR,MAAO,IAAK,KAAK,IAAK,KAEpB,QAAO,EAAG,CACZ,MAAM,EAAS,WACf,GAAI,GAAQ,OAAc,OACxB,MAAO,OAET,GAAI,GAAQ,MAAa,OACvB,MAAO,MAET,UAAW,GAAQ,gBAAkB,WACnC,MAAO,UAET,UAAW,GAAQ,cAAgB,SACjC,MAAO,aAET,GAAI,GAAQ,SAAgB,OAC1B,MAAO,SAET,GAAI,GAAQ,YAAmB,OAC7B,MAAO,QAET,GAAI,GAAQ,SAAS,SAAS,OAAS,OACrC,MAAO,OAET,MAAO,QAEX,EACA,GAAU,IAAI,QACd,GAAgB,IAAI,QACpB,EAAW,IAAI,QACf,EAAmB,IAAI,QACvB,EAAO,IAAI,QACX,GAAW,IAAIACpQf,IAAI,GAAU,CAAC,EAAY,EAAS,IAAe,CACjD,MAAO,CAAC,EAAS,IAAS,CACxB,IAAI,GAAQ,EACZ,OAAO,EAAS,CAAC,EACjB,eAAe,CAAQ,CAAC,EAAG,CACzB,GAAI,GAAK,EACP,MAAM,IAAI,MAAM,8BAA8B,EAEhD,EAAQ,EACR,IAAI,EACA,EAAU,GACV,EACJ,GAAI,EAAW,IAEb,GADA,EAAU,EAAW,GAAG,GAAG,GACvB,aAAmB,GACrB,EAAQ,IAAI,WAAa,MAG3B,GAAU,IAAM,EAAW,QAAU,GAAa,OAEpD,IAAK,GACH,GAAI,aAAmB,IAAW,EAAQ,YAAc,IAAS,EAC/D,EAAM,MAAM,EAAW,CAAO,MAGhC,IAAI,CACF,EAAM,MAAM,EAAQ,EAAS,IAAM,CACjC,OAAO,EAAS,EAAI,CAAC,EACtB,QACM,EAAP,CACA,GAAI,aAAe,OAAS,aAAmB,IAAW,EACxD,EAAQ,MAAQ,EAChB,EAAM,MAAM,EAAQ,EAAK,CAAO,EAChC,EAAU,OAEV,OAAM,EAIZ,GAAI,IAAQ,EAAQ,YAAc,IAAS,GACzC,EAAQ,IAAM,EAEhB,OAAOAC3Cb,IAAI,GAAgB,cAAc,KAAM,CACtC,WAAW,CAAC,EAAS,IAAK,EAAS,CACjC,MAAM,GAAS,OAAO,EACtB,KAAK,IAAM,GAAS,IACpB,KAAK,OAAS,EAEhB,WAAW,EAAG,CACZ,GAAI,KAAK,IACP,OAAO,KAAK,IAEd,OAAO,IAAI,SAAS,KAAK,QAAS,CAChC,OAAQ,KAAK,MACf,CAAC,EAELACdA,IAAI,GAAe,CAAC,IAAU,CAC5B,OAAO,MAAM,QAAQ,CAAK,GAExB,GAAY,MAAO,EAAS,EAAU,CACxC,IAAK,EACP,IAAM,CACJ,IAAI,EAAO,CAAC,EACZ,MAAM,EAAc,EAAQ,QAAQ,IAAI,cAAc,EACtD,GAAI,IAAgB,EAAY,WAAW,qBAAqB,GAAK,EAAY,WAAW,mCAAmC,GAAI,CACjI,MAAM,EAAW,MAAM,EAAQ,SAAS,EACxC,GAAI,EAAU,CACZ,MAAM,EAAO,CAAC,EACd,EAAS,QAAQ,CAAC,EAAO,IAAQ,CAE/B,KAD6B,EAAQ,KAAO,EAAI,OAAM,CAAE,IAAM,MACnC,CACzB,EAAK,GAAO,EACZ,OAEF,GAAI,EAAK,IAAQ,GAAa,EAAK,EAAI,EAAG,CAExC,EAAK,GAAK,KAAK,CAAK,EACpB,OAEF,GAAI,EAAK,GAAM,CACb,EAAK,GAAO,CAAC,EAAK,GAAM,CAAK,EAC7B,OAEF,EAAK,GAAO,EACb,EACD,EAAO,GAGX,OAAOACjCT,IAAI,GAAgB,CAAC,EAAK,EAAQ,IAAQ,CACxC,IAAK,EAAO,IAAI,CAAG,EACjB,MAAM,UAAU,UAAY,CAAG,GAE/B,EAAe,CAAC,EAAK,EAAQ,IAAW,CAE1C,OADA,GAAc,EAAK,EAAQ,yBAAyB,EAC7C,EAAS,EAAO,KAAK,CAAG,EAAI,EAAO,IAAI,CAAG,GAE/C,GAAe,CAAC,EAAK,EAAQ,IAAU,CACzC,GAAI,EAAO,IAAI,CAAG,EAChB,MAAM,UAAU,mDAAmD,EACrE,aAAkB,QAAU,EAAO,IAAI,CAAG,EAAI,EAAO,IAAI,EAAK,CAAK,GAEjE,GAAe,CAAC,EAAK,EAAQ,EAAO,IAAW,CAGjD,OAFA,GAAc,EAAK,EAAQ,wBAAwB,EACnD,EAAS,EAAO,KAAK,EAAK,CAAK,EAAI,EAAO,IAAI,EAAK,CAAK,EACjD,GAOL,GAAgB,EAChB,GAAc,KAAM,CACtB,WAAW,CAAC,EAAS,EAAO,IAAK,EAAc,CAAC,CAAC,CAAC,EAAG,CACnD,GAAa,KAAM,GAAqB,MAAC,EACzC,GAAa,KAAM,EAAmB,MAAC,EACvC,KAAK,WAAa,EAClB,KAAK,UAAY,CAAC,EAClB,KAAK,WAAa,CAAC,IAAQ,CACzB,MAAQ,YAAW,OAAQ,KACrB,EAAa,EAAU,GAC7B,GAAI,EACF,OAAO,EACT,GAAI,EAAU,YACZ,OAAQ,SAAY,CAClB,OAAO,MAAM,IAAI,SAAS,EAAU,WAAW,EAAE,GAAK,IACrD,EAEL,OAAO,EAAU,GAAO,EAAI,GAAK,GAEnC,KAAK,IAAM,EACX,KAAK,KAAO,EACZ,GAAa,KAAM,EAAc,CAAW,EAC5C,GAAa,KAAM,GAAgB,CAAC,CAAC,EAEvC,KAAK,CAAC,EAAK,CACT,GAAI,EAAK,CACP,MAAM,EAAQ,EAAa,KAAM,CAAY,EAAE,GAAK,EAAa,KAAM,CAAY,EAAE,GAAG,EAAa,KAAM,CAAY,EAAE,GAAG,KAAK,YAAY,GAAG,IAAQ,EAAa,KAAM,CAAY,EAAE,GAAG,KAAK,YAAY,GAAG,GAChN,OAAO,EAAQ,KAAK,KAAK,CAAK,EAAI,GAAoB,CAAK,EAAI,EAAa,WACvE,CACL,MAAM,EAAU,CAAC,EACX,EAAO,OAAO,KAAK,EAAa,KAAM,CAAY,EAAE,GAAG,KAAK,YAAY,EAAE,EAChF,QAAS,EAAI,EAAG,EAAM,EAAK,OAAQ,EAAI,EAAK,IAAK,CAC/C,MAAM,EAAO,EAAK,GACZ,EAAQ,EAAa,KAAM,CAAY,EAAE,GAAK,EAAa,KAAM,CAAY,EAAE,GAAG,EAAa,KAAM,CAAY,EAAE,GAAG,KAAK,YAAY,GAAG,IAAS,EAAa,KAAM,CAAY,EAAE,GAAG,KAAK,YAAY,GAAG,GACjN,GAAI,UAAgB,IAAU,SAC5B,EAAQ,GAAQ,KAAK,KAAK,CAAK,EAAI,GAAoB,CAAK,EAAI,EAGpE,OAAO,GAGX,KAAK,CAAC,EAAK,CACT,OAAO,GAAc,KAAK,IAAK,CAAG,EAEpC,OAAO,CAAC,EAAK,CACX,OAAO,GAAe,KAAK,IAAK,CAAG,EAErC,MAAM,CAAC,EAAM,CACX,GAAI,EACF,OAAO,KAAK,IAAI,QAAQ,IAAI,EAAK,YAAY,CAAC,GAAU,OAC1D,MAAM,EAAa,CAAC,EAIpB,OAHA,KAAK,IAAI,QAAQ,QAAQ,CAAC,EAAO,IAAQ,CACvC,EAAW,GAAO,EACnB,EACM,EAET,MAAM,CAAC,EAAK,CACV,MAAM,EAAS,KAAK,IAAI,QAAQ,IAAI,QAAQ,EAC5C,IAAK,EACH,OACF,MAAM,EAAM,GAAM,CAAM,EACxB,GAAI,EAEF,OADc,EAAI,OAGlB,QAAO,OAGL,UAAS,CAAC,EAAS,CACvB,GAAI,KAAK,UAAU,WACjB,OAAO,KAAK,UAAU,WACxB,MAAM,EAAa,MAAM,GAAU,KAAM,CAAO,EAEhD,OADA,KAAK,UAAU,WAAa,EACrB,EAET,IAAI,EAAG,CACL,OAAO,KAAK,WAAW,MAAM,EAE/B,IAAI,EAAG,CACL,OAAO,KAAK,WAAW,MAAM,EAE/B,WAAW,EAAG,CACZ,OAAO,KAAK,WAAW,aAAa,EAEtC,IAAI,EAAG,CACL,OAAO,KAAK,WAAW,MAAM,EAE/B,QAAQ,EAAG,CACT,OAAO,KAAK,WAAW,UAAU,EAEnC,gBAAgB,CAAC,EAAQ,EAAM,CAC7B,EAAa,KAAM,EAAc,EAAE,GAAU,EAE/C,KAAK,CAAC,EAAQ,CACZ,OAAO,EAAa,KAAM,EAAc,EAAE,MAExC,IAAG,EAAG,CACR,OAAO,KAAK,IAAI,OAEd,OAAM,EAAG,CACX,OAAO,KAAK,IAAI,UAEd,cAAa,EAAG,CAClB,OAAO,EAAa,KAAM,CAAY,EAAE,GAAG,IAAI,IAAK,MAAY,CAAK,KAEnE,UAAS,EAAG,CACd,OAAO,EAAa,KAAM,CAAY,EAAE,GAAG,IAAI,IAAK,MAAY,CAAK,EAAE,KAAK,YAAY,QAEtF,QAAO,EAAG,CACZ,OAAO,KAAK,IAAI,WAEd,KAAI,EAAG,CACT,OAAO,KAAK,IAAI,QAEd,SAAQ,EAAG,CACb,OAAO,KAAK,IAAI,YAEd,UAAS,EAAG,CACd,OAAO,KAAK,IAAI,aAEd,UAAS,EAAG,CACd,OAAO,KAAK,IAAI,aAEd,SAAQ,EAAG,CACb,OAAO,KAAK,IAAI,YAEd,OAAM,EAAG,CACX,OAAO,KAAK,IAAI,OAEpB,EACA,GAAiB,IAAI,QACrB,EAAe,IAAIACzJnB,IAAI,EAAkB,MAClB,GAA4B,MAC5B,GAAU,CAAC,MAAO,OAAQ,MAAO,SAAU,UAAW,OAAO,EAC7D,GAAmC,0DACnC,GAAuB,cAAc,KAAM,CAC/CACoBA,IAAS,WAAkB,EAAG,CAC5B,OAAO,KAAM,CACb,GA5BE,GAAgB,CAAC,EAAK,EAAQ,IAAQ,CACxC,IAAK,EAAO,IAAI,CAAG,EACjB,MAAM,UAAU,UAAY,CAAG,GAE/B,GAAe,CAAC,EAAK,EAAQ,IAAW,CAE1C,OADA,GAAc,EAAK,EAAQ,yBAAyB,EAC7C,EAAS,EAAO,KAAK,CAAG,EAAI,EAAO,IAAI,CAAG,GAE/C,GAAe,CAAC,EAAK,EAAQ,IAAU,CACzC,GAAI,EAAO,IAAI,CAAG,EAChB,MAAM,UAAU,mDAAmD,EACrE,aAAkB,QAAU,EAAO,IAAI,CAAG,EAAI,EAAO,IAAI,EAAK,CAAK,GAEjE,GAAe,CAAC,EAAK,EAAQ,EAAO,IAAW,CAGjD,OAFA,GAAc,EAAK,EAAQ,wBAAwB,EACnD,EAAS,EAAO,KAAK,EAAK,CAAK,EAAI,EAAO,IAAI,EAAK,CAAK,EACjD,GAcL,GAAkB,CAAC,IAAM,CAC3B,OAAO,EAAE,KAAK,gBAAiB,GAAG,GAEhC,GAAe,CAAC,EAAK,IAAM,CAC7B,GAAI,aAAe,GACjB,OAAO,EAAI,YAAY,EAEzB,QAAQ,MAAM,CAAG,EACjB,MAAM,EAAU,wBAChB,OAAO,EAAE,KAAK,EAAS,GAAG,GAExB,GACA,GAAQ,cAAc,GAAmB,CAAE,CAC7C,WAAW,CAAC,EAAU,CAAC,EAAG,CACxB,MAAM,EACN,KAAK,UAAY,IACjB,GAAa,KAAM,GAAO,GAAG,EAC7B,KAAK,OAAS,CAAC,EACf,KAAK,gBAAkB,GACvB,KAAK,aAAe,GACpB,KAAK,QAAU,CAAC,IAAY,CAE1B,OADA,KAAK,aAAe,EACb,MAET,KAAK,SAAW,CAAC,IAAY,CAE3B,OADA,KAAK,gBAAkB,EAChB,MAET,KAAK,KAAO,IAAM,CAEhB,OADA,QAAQ,KAAK,iFAAiF,EACvF,MAET,KAAK,YAAc,CAAC,IAAU,CAC5B,OAAO,KAAK,SAAS,EAAM,QAAS,EAAY,OAAG,EAAM,QAAQ,MAAM,GAEzE,KAAK,MAAQ,CAAC,EAAS,EAAK,IAAiB,CAC3C,OAAO,KAAK,SAAS,EAAS,EAAc,EAAK,EAAQ,MAAM,GAEjE,KAAK,QAAU,CAAC,EAAO,EAAa,EAAK,IAAiB,CACxD,GAAI,aAAiB,QAAS,CAC5B,GAAI,IAAqB,OACvB,EAAQ,IAAI,QAAQ,EAAO,CAAW,EAExC,OAAO,KAAK,MAAM,EAAO,EAAK,CAAY,EAE5C,EAAQ,EAAM,SAAS,EACvB,MAAM,EAAO,eAAe,KAAK,CAAK,EAAI,EAAQ,mBAAmB,GAAU,IAAK,CAAK,IACnF,EAAM,IAAI,QAAQ,EAAM,CAAW,EACzC,OAAO,KAAK,MAAM,EAAK,EAAK,CAAY,GAE1C,KAAK,KAAO,IAAM,CAChB,iBAAiB,QAAS,CAAC,IAAU,CACnC,EAAM,YAAY,KAAK,SAAS,EAAM,QAAS,EAAY,OAAG,EAAM,QAAQ,MAAM,CAAC,EACpF,GAEgB,CAAC,GAAG,GAAS,EAAyB,EAC9C,IAAI,CAAC,IAAW,CACzB,KAAK,GAAU,CAAC,KAAU,IAAS,CACjC,UAAW,IAAU,SACnB,GAAa,KAAM,GAAO,CAAK,MAE/B,MAAK,SAAS,EAAQ,GAAa,KAAM,EAAK,EAAG,CAAK,EAOxD,OALA,EAAK,IAAI,CAAC,IAAY,CACpB,UAAW,IAAY,SACrB,KAAK,SAAS,EAAQ,GAAa,KAAM,EAAK,EAAG,CAAO,EAE3D,EACM,MAEV,EACD,KAAK,GAAK,CAAC,EAAQ,KAAS,IAAa,CACvC,IAAK,EACH,OAAO,KACT,GAAa,KAAM,GAAO,CAAI,EAC9B,QAAW,IAAK,CAAC,CAAM,EAAE,KAAK,EAC5B,EAAS,IAAI,CAAC,IAAY,CACxB,KAAK,SAAS,EAAE,YAAY,EAAG,GAAa,KAAM,EAAK,EAAG,CAAO,EAClE,EAEH,OAAO,MAET,KAAK,IAAM,CAAC,KAAS,IAAa,CAChC,UAAW,IAAS,SAClB,GAAa,KAAM,GAAO,CAAI,MAE9B,GAAS,QAAQ,CAAI,EAKvB,OAHA,EAAS,IAAI,CAAC,IAAY,CACxB,KAAK,SAAS,EAAiB,GAAa,KAAM,EAAK,EAAG,CAAO,EAClE,EACM,MAET,MAAM,EAAS,EAAQ,QAAU,GACjC,OAAO,EAAQ,OACf,OAAO,OAAO,KAAM,CAAO,EAC3B,KAAK,QAAU,EAAS,EAAQ,SAAW,GAAU,GAEvD,KAAK,EAAG,CACN,MAAM,EAAQ,IAAI,GAAM,CACtB,OAAQ,KAAK,OACb,QAAS,KAAK,OAChB,CAAC,EAED,OADA,EAAM,OAAS,KAAK,OACb,EAET,KAAK,CAAC,EAAM,EAAK,CACf,MAAM,EAAS,KAAK,SAAS,CAAI,EACjC,IAAK,EACH,OAAO,EAMT,OAJA,EAAI,OAAO,IAAI,CAAC,IAAM,CACpB,MAAM,EAAU,EAAI,eAAiB,GAAe,EAAE,QAAU,MAAO,EAAG,KAAU,MAAM,GAAQ,CAAC,EAAG,EAAI,YAAY,EAAE,EAAG,IAAM,EAAE,QAAQ,EAAG,CAAI,CAAC,GAAG,IACtJ,EAAO,SAAS,EAAE,OAAQ,EAAE,KAAM,CAAO,EAC1C,EACM,KAET,QAAQ,CAAC,EAAM,CACb,MAAM,EAAS,KAAK,MAAM,EAE1B,OADA,EAAO,UAAY,GAAU,KAAK,UAAW,CAAI,EAC1C,EAET,UAAU,EAAG,CAEX,KAAK,OAAO,IAAI,CAAC,IAAU,CACzB,QAAQ,IACN,WAAW,EAAM,iBAAiB,IAAI,OAH3B,EAG2C,EAAM,OAAO,MAAM,KAAK,EAAM,MACtF,EACD,EAEH,KAAK,CAAC,EAAM,EAAoB,EAAe,CAC7C,MAAM,EAAa,GAAU,KAAK,UAAW,CAAI,EAC3C,EAAmB,IAAe,IAAM,EAAI,EAAW,OACvD,EAAU,MAAO,EAAG,IAAS,CACjC,IAAI,EAAwB,OAC5B,GAAI,CACF,EAAmB,EAAE,kBACrB,EAEF,MAAM,EAAU,EAAgB,EAAc,CAAC,EAAI,CAAC,EAAE,IAAK,CAAgB,EACrE,EAAe,MAAM,QAAQ,CAAO,EAAI,EAAU,CAAC,CAAO,EAC1D,EAAe,GAAgB,EAAE,IAAI,GAAG,EACxC,EAAM,MAAM,EAChB,IAAI,QACF,IAAI,KAAK,EAAE,IAAI,KAAK,MAAM,CAAgB,GAAK,KAAO,EAAc,EAAE,IAAI,GAAG,EAC7E,EAAE,IAAI,GACR,EACA,GAAG,CACL,EACA,GAAI,EACF,OAAO,EACT,MAAM,EAAK,GAGb,OADA,KAAK,SAAS,EAAiB,GAAU,EAAM,GAAG,EAAG,CAAO,EACrD,QAEL,WAAU,EAAG,CAEf,OADA,KAAK,WAAW,MAAO,GAAG,EACnB,KAAK,OAAO,KAErB,QAAQ,CAAC,EAAQ,EAAM,EAAS,CAC9B,EAAS,EAAO,YAAY,EAC5B,EAAO,GAAU,KAAK,UAAW,CAAI,EACrC,MAAM,EAAI,CAAE,OAAM,SAAQ,SAAQ,EAClC,KAAK,OAAO,IAAI,EAAQ,EAAM,CAAC,EAAS,CAAC,CAAC,EAC1C,KAAK,OAAO,KAAK,CAAC,EAEpB,UAAU,CAAC,EAAQ,EAAM,CACvB,OAAO,KAAK,OAAO,MAAM,EAAQ,CAAI,EAEvC,WAAW,CAAC,EAAK,EAAG,CAClB,GAAI,aAAe,MACjB,OAAO,KAAK,aAAa,EAAK,CAAC,EAEjC,MAAM,EAER,QAAQ,CAAC,EAAS,EAAc,EAAK,EAAQ,CAC3C,GAAI,IAAW,OACb,OAAQ,SAAY,IAAI,SAAS,KAAM,MAAM,KAAK,SAAS,EAAS,EAAc,EAAK,KAAK,CAAC,GAAG,EAElG,MAAM,EAAO,KAAK,QAAQ,EAAS,CAAE,KAAI,CAAC,EACpC,EAAc,KAAK,WAAW,EAAQ,CAAI,EAC1C,EAAI,IAAI,GAAQ,IAAI,GAAY,EAAS,EAAM,CAAW,EAAG,CACjE,MACA,eACA,gBAAiB,KAAK,eACxB,CAAC,EACD,GAAI,EAAY,GAAG,SAAW,EAAG,CAC/B,IAAI,EACJ,GAAI,CAGF,GAFA,EAAM,EAAY,GAAG,GAAG,GAAG,GAAG,EAAG,SAAY,EAC5C,GACI,EACH,OAAO,KAAK,gBAAgB,CAAC,QAExB,EAAP,CACA,OAAO,KAAK,YAAY,EAAK,CAAC,EAEhC,GAAI,aAAe,SACjB,OAAO,EACT,OAAQ,SAAY,CAClB,IAAI,EACJ,GAAI,CAEF,GADA,EAAU,MAAM,GACX,EACH,OAAO,KAAK,gBAAgB,CAAC,QAExB,EAAP,CACA,OAAO,KAAK,YAAY,EAAK,CAAC,EAEhC,OAAO,IACN,EAEL,MAAM,EAAW,GAAQ,EAAY,GAAI,KAAK,aAAc,KAAK,eAAe,EAChF,OAAQ,SAAY,CAClB,GAAI,CACF,MAAM,EAAU,MAAM,EAAS,CAAC,EAChC,IAAK,EAAQ,UACX,MAAM,IAAI,MACR,sFACF,EAEF,OAAO,EAAQ,UACR,EAAP,CACA,OAAO,KAAK,YAAY,EAAK,CAAC,KAE/B,EAEP,EACI,GAAO,GACX,GAAQ,IAAIAC/PZ,IAAS,WAAU,CAAC,EAAG,EAAG,CACxB,GAAI,EAAE,SAAW,EACf,OAAO,EAAE,SAAW,EAAI,EAAI,GAAI,EAAK,GAAI,EAE3C,GAAI,EAAE,SAAW,EACf,OAAO,EAET,GAAI,IAAM,IAA6B,IAAM,GAC3C,OAAO,UACE,IAAM,IAA6B,IAAM,GAClD,OAAO,EAET,GAAI,IAAM,GACR,OAAO,UACE,IAAM,GACf,OAAO,EAET,OAAO,EAAE,SAAW,EAAE,OAAS,EAAI,GAAI,EAAK,EAAI,EAAE,OAAS,EAAE,QArB3D,GAAoB,QACpB,GAA4B,KAC5B,GAA4B,WAC5B,GAAa,OAAO,EAoBpB,GAAO,KAAM,CACf,WAAW,EAAG,CACZ,KAAK,SAAW,CAAC,EAEnB,MAAM,CAAC,EAAQ,EAAO,EAAU,EAAS,EAAoB,CAC3D,GAAI,EAAO,SAAW,EAAG,CACvB,GAAI,KAAK,QAAe,OACtB,MAAM,GAER,GAAI,EACF,OAEF,KAAK,MAAQ,EACb,OAEF,MAAO,KAAU,GAAc,EACzB,EAAU,IAAU,IAAM,EAAW,SAAW,EAAI,CAAC,GAAI,GAAI,EAAyB,EAAI,CAAC,GAAI,GAAI,EAAiB,EAAI,IAAU,KAAO,CAAC,GAAI,GAAI,EAAyB,EAAI,EAAM,MAAM,6BAA6B,EAC9N,IAAI,EACJ,GAAI,EAAS,CACX,MAAM,EAAO,EAAQ,GACrB,IAAI,EAAY,EAAQ,IAAM,GAC9B,GAAI,GAAQ,EAAQ,IAElB,GADA,EAAY,EAAU,QAAQ,yBAA0B,KAAK,EACzD,YAAY,KAAK,CAAS,EAC5B,MAAM,GAIV,GADA,EAAO,KAAK,SAAS,IAChB,EAAM,CACT,GAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,KAC7B,CAAC,IAAM,IAAM,IAA6B,IAAM,EAClD,EACE,MAAM,GAER,GAAI,EACF,OAGF,GADA,EAAO,KAAK,SAAS,GAAa,IAAI,GAClC,IAAS,GACX,EAAK,SAAW,EAAQ,WAG5B,IAAK,GAAsB,IAAS,GAClC,EAAS,KAAK,CAAC,EAAM,EAAK,QAAQ,CAAC,UAGrC,EAAO,KAAK,SAAS,IAChB,EAAM,CACT,GAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,KAC7B,CAAC,IAAM,EAAE,OAAS,GAAK,IAAM,IAA6B,IAAM,EAClE,EACE,MAAM,GAER,GAAI,EACF,OAEF,EAAO,KAAK,SAAS,GAAS,IAAI,GAGtC,EAAK,OAAO,EAAY,EAAO,EAAU,EAAS,CAAkB,EAEtE,cAAc,EAAG,CAEf,MAAM,EADY,OAAO,KAAK,KAAK,QAAQ,EAAE,KAAK,EAAU,EAClC,IAAI,CAAC,IAAM,CACnC,MAAM,EAAI,KAAK,SAAS,GACxB,cAAe,EAAE,WAAa,SAAW,IAAI,MAAM,EAAE,WAAa,GAAK,EAAE,eAAe,EACzF,EACD,UAAW,KAAK,QAAU,SACxB,EAAQ,QAAQ,IAAI,KAAK,OAAO,EAElC,GAAI,EAAQ,SAAW,EACrB,MAAO,GAET,GAAI,EAAQ,SAAW,EACrB,OAAO,EAAQ,GAEjB,MAAO,MAAQ,EAAQ,KAAK,GAAG,EAAI,IAEvCACpGA,IAAI,GAAO,KAAM,CACf,WAAW,EAAG,CACZ,KAAK,QAAU,CAAE,SAAU,CAAE,EAC7B,KAAK,KAAO,IAAI,GAElB,MAAM,CAAC,EAAM,EAAO,EAAoB,CACtC,MAAM,EAAa,CAAC,EACd,EAAS,CAAC,EAChB,QAAS,EAAI,IAAO,CAClB,IAAI,EAAW,GAQf,GAPA,EAAO,EAAK,QAAQ,aAAc,CAAC,IAAM,CACvC,MAAM,EAAO,MAAM,IAInB,OAHA,EAAO,GAAK,CAAC,EAAM,CAAC,EACpB,IACA,EAAW,GACJ,EACR,GACI,EACH,MAGJ,MAAM,EAAS,EAAK,MAAM,0BAA0B,GAAK,CAAC,EAC1D,QAAS,EAAI,EAAO,OAAS,EAAG,GAAK,EAAG,IAAK,CAC3C,MAAO,GAAQ,EAAO,GACtB,QAAS,EAAI,EAAO,OAAS,EAAG,GAAK,EAAG,IACtC,GAAI,EAAO,GAAG,QAAQ,CAAI,KAAM,EAAI,CAClC,EAAO,GAAK,EAAO,GAAG,QAAQ,EAAM,EAAO,GAAG,EAAE,EAChD,OAKN,OADA,KAAK,KAAK,OAAO,EAAQ,EAAO,EAAY,KAAK,QAAS,CAAkB,EACrE,EAET,WAAW,EAAG,CACZ,IAAI,EAAS,KAAK,KAAK,eAAe,EACtC,GAAI,IAAW,GACb,MAAO,CAAC,KAAM,CAAC,EAAG,CAAC,CAAC,EAEtB,IAAI,EAAe,EACnB,MAAM,EAAsB,CAAC,EACvB,EAAsB,CAAC,EAY7B,OAXA,EAAS,EAAO,QAAQ,wBAAyB,CAAC,EAAG,EAAc,IAAe,CAChF,UAAW,IAAiB,YAE1B,OADA,EAAoB,EAAE,GAAgB,OAAO,CAAY,EAClD,MAET,UAAW,IAAe,YAExB,OADA,EAAoB,OAAO,CAAU,KAAO,EACrC,GAET,MAAO,GACR,EACM,CAAC,IAAI,OAAO,IAAI,GAAQ,EAAG,EAAqB,CAAmB,EAE9EAC3CA,IAAS,WAAmB,CAAC,EAAM,CACjC,OAAO,GAAoB,KAAU,GAAoB,GAAQ,IAAI,OACnE,IAAS,IAAM,GAAK,IAAI,EAAK,QAAQ,OAAQ,UAAU,KACzD,IAEO,WAAwB,EAAG,CAClC,GAAsB,CAAC,GAEhB,WAAkC,CAAC,EAAQ,CAClD,MAAM,EAAO,IAAI,GACX,EAAc,CAAC,EACrB,GAAI,EAAO,SAAW,EACpB,OAAO,GAET,MAAM,EAA2B,EAAO,IACtC,CAAC,IAAU,EAAE,SAAS,KAAK,EAAM,EAAE,EAAG,GAAG,CAAK,CAChD,EAAE,KACA,EAAE,EAAW,IAAS,EAAW,KAAW,EAAY,EAAI,GAAY,EAAK,EAAM,OAAS,EAAM,MACpG,EACM,EAAY,CAAC,EACnB,QAAS,EAAI,EAAG,GAAI,EAAI,EAAM,EAAyB,OAAQ,EAAI,EAAK,IAAK,CAC3E,MAAO,EAAoB,EAAM,GAAY,EAAyB,GACtE,GAAI,EACF,EAAU,GAAQ,CAAC,EAAS,IAAI,EAAE,KAAO,CAAC,EAAG,CAAC,CAAC,CAAC,EAAG,EAAU,MAE7D,KAEF,IAAI,EACJ,GAAI,CACF,EAAa,EAAK,OAAO,EAAM,EAAG,CAAkB,QAC7C,EAAP,CACA,MAAM,IAAM,GAAa,IAAI,GAAqB,CAAI,EAAI,EAE5D,GAAI,EACF,SAEF,EAAY,GAAK,EAAS,IAAI,EAAE,EAAG,KAAgB,CACjD,MAAM,EAAgB,CAAC,EACvB,GAAc,EACd,KAAO,GAAc,EAAG,IAAc,CACpC,MAAO,EAAK,GAAS,EAAW,GAChC,EAAc,GAAO,EAEvB,MAAO,CAAC,EAAG,CAAa,EACzB,EAEH,MAAO,EAAQ,EAAqB,GAAuB,EAAK,YAAY,EAC5E,QAAS,EAAI,EAAG,EAAM,EAAY,OAAQ,EAAI,EAAK,IACjD,QAAS,EAAI,EAAG,EAAO,EAAY,GAAG,OAAQ,EAAI,EAAM,IAAK,CAC3D,MAAM,EAAM,EAAY,GAAG,KAAK,GAChC,IAAK,EACH,SAEF,MAAM,EAAO,OAAO,KAAK,CAAG,EAC5B,QAAS,EAAI,EAAG,EAAO,EAAK,OAAQ,EAAI,EAAM,IAC5C,EAAI,EAAK,IAAM,EAAoB,EAAI,EAAK,KAIlD,MAAM,EAAa,CAAC,EACpB,QAAW,KAAK,EACd,EAAW,GAAK,EAAY,EAAoB,IAElD,MAAO,CAAC,EAAQ,EAAY,CAAS,GAE9B,WAAc,CAAC,EAAY,EAAM,CACxC,IAAK,EACH,OAEF,QAAW,KAAK,OAAO,KAAK,CAAU,EAAE,KAAK,CAAC,EAAG,IAAM,EAAE,OAAS,EAAE,MAAM,EACxE,GAAI,GAAoB,CAAC,EAAE,KAAK,CAAI,EAClC,MAAO,CAAC,GAAG,EAAW,EAAE,EAG5B,QA9EE,GAAc,CAAC,EAAiB,GAAG,EAAO,EAAE,IAAI,CAAC,IAAW,EAAO,YAAY,CAAC,EAChF,GAAa,CAAC,EACd,GAAc,CAAC,KAAM,CAAC,EAAG,CAAC,CAAC,EAC3B,GAAsB,CAAC,EA6EvB,GAAe,KAAM,CACvB,WAAW,EAAG,CACZ,KAAK,KAAO,eACZ,KAAK,WAAa,EAAG,GAAkB,CAAC,CAAE,EAC1C,KAAK,OAAS,EAAG,GAAkB,CAAC,CAAE,EAExC,GAAG,CAAC,EAAQ,EAAM,EAAS,CACzB,IAAI,EACJ,MAAQ,aAAY,UAAW,KAC/B,IAAK,IAAe,EAClB,MAAM,IAAI,MAAM,EAAgC,EAElD,GAAI,GAAY,QAAQ,CAAM,KAAM,EAClC,GAAY,KAAK,CAAM,EACzB,IAAK,EAAW,GAEd,CAAC,EAAY,CAAM,EAAE,QAAQ,CAAC,IAAe,CAC3C,EAAW,GAAU,CAAC,EACtB,OAAO,KAAK,EAAW,EAAgB,EAAE,QAAQ,CAAC,IAAM,CACtD,EAAW,GAAQ,GAAK,CAAC,GAAG,EAAW,GAAiB,EAAE,EAC3D,EACF,EAEH,GAAI,IAAS,KACX,EAAO,IAET,MAAM,GAAc,EAAK,MAAM,MAAM,GAAK,CAAC,GAAG,OAC9C,GAAI,MAAM,KAAK,CAAI,EAAG,CACpB,MAAM,EAAK,GAAoB,CAAI,EACnC,GAAI,IAAW,EACb,OAAO,KAAK,CAAU,EAAE,QAAQ,CAAC,IAAM,CACrC,IAAI,EACJ,CAAC,EAAM,EAAW,IAAI,KAAU,EAAI,GAAQ,GAAe,EAAW,GAAI,CAAI,GAAK,GAAe,EAAW,GAAkB,CAAI,GAAK,CAAC,GAC1I,MAED,CAAC,EAAK,EAAW,IAAS,KAAU,EAAG,GAAQ,GAAe,EAAW,GAAS,CAAI,GAAK,GAAe,EAAW,GAAkB,CAAI,GAAK,CAAC,GAEnJ,OAAO,KAAK,CAAU,EAAE,QAAQ,CAAC,IAAM,CACrC,GAAI,IAAW,GAAmB,IAAW,EAC3C,OAAO,KAAK,EAAW,EAAE,EAAE,QAAQ,CAAC,IAAM,CACxC,EAAG,KAAK,CAAC,GAAK,EAAW,GAAG,GAAG,KAAK,CAAC,EAAS,CAAU,CAAC,EAC1D,EAEJ,EACD,OAAO,KAAK,CAAM,EAAE,QAAQ,CAAC,IAAM,CACjC,GAAI,IAAW,GAAmB,IAAW,EAC3C,OAAO,KAAK,EAAO,EAAE,EAAE,QACrB,CAAC,IAAM,EAAG,KAAK,CAAC,GAAK,EAAO,GAAG,GAAG,KAAK,CAAC,EAAS,CAAU,CAAC,CAC9D,EAEH,EACD,OAEF,MAAM,EAAQ,GAAuB,CAAI,GAAK,CAAC,CAAI,EACnD,QAAS,EAAI,EAAG,EAAM,EAAM,OAAQ,EAAI,EAAK,IAAK,CAChD,MAAM,EAAQ,EAAM,GACpB,OAAO,KAAK,CAAM,EAAE,QAAQ,CAAC,IAAM,CACjC,IAAI,EACJ,GAAI,IAAW,GAAmB,IAAW,EAC3C,CAAC,EAAM,EAAO,IAAI,KAAW,EAAI,GAAS,CACxC,GAAG,GAAe,EAAW,GAAI,CAAK,GAAK,GAAe,EAAW,GAAkB,CAAK,GAAK,CAAC,CACpG,GACA,EAAO,GAAG,GAAO,KAAK,CACpB,EACA,EAAM,SAAW,GAAK,IAAM,EAAI,EAAa,EAAI,CACnD,CAAC,EAEJ,GAGL,KAAK,CAAC,EAAQ,EAAM,CAClB,GAAyB,EACzB,MAAM,EAAW,KAAK,iBAAiB,EAcvC,OAbA,KAAK,MAAQ,CAAC,EAAS,IAAU,CAC/B,MAAM,EAAU,EAAS,GACnB,EAAc,EAAQ,GAAG,GAC/B,GAAI,EACF,OAAO,EAET,MAAM,EAAQ,EAAM,MAAM,EAAQ,EAAE,EACpC,IAAK,EACH,MAAO,CAAC,CAAC,EAAG,EAAU,EAExB,MAAM,EAAQ,EAAM,QAAQ,GAAI,CAAC,EACjC,MAAO,CAAC,EAAQ,GAAG,GAAQ,CAAK,GAE3B,KAAK,MAAM,EAAQ,CAAI,EAEhC,gBAAgB,EAAG,CACjB,MAAM,EAAW,CAAC,EAKlB,OAJA,GAAY,QAAQ,CAAC,IAAW,CAC9B,EAAS,GAAU,KAAK,aAAa,CAAM,GAAK,EAAS,GAC1D,EACD,KAAK,WAAa,KAAK,OAAc,OAC9B,EAET,YAAY,CAAC,EAAQ,CACnB,MAAM,EAAS,CAAC,EAChB,IAAI,EAAc,IAAW,EAY7B,GAXA,CAAC,KAAK,WAAY,KAAK,MAAM,EAAE,QAAQ,CAAC,IAAM,CAC5C,MAAM,EAAW,EAAE,GAAU,OAAO,KAAK,EAAE,EAAO,EAAE,IAAI,CAAC,IAAS,CAAC,EAAM,EAAE,GAAQ,EAAK,CAAC,EAAI,CAAC,EAC9F,GAAI,EAAS,SAAW,EACtB,IAAgB,EAAc,IAC9B,EAAO,KAAK,GAAG,CAAQ,UACd,IAAW,EACpB,EAAO,KACL,GAAG,OAAO,KAAK,EAAE,EAAgB,EAAE,IAAI,CAAC,IAAS,CAAC,EAAM,EAAE,GAAiB,EAAK,CAAC,CACnF,EAEH,GACI,EACH,OAAO,SAEP,QAAO,GAAmC,CAAM,EAGtDAC5MA,IAAI,GAAc,KAAM,CACtB,WAAW,CAAC,EAAM,CAChB,KAAK,KAAO,cACZ,KAAK,QAAU,CAAC,EAChB,KAAK,OAAS,CAAC,EACf,OAAO,OAAO,KAAM,CAAI,EAE1B,GAAG,CAAC,EAAQ,EAAM,EAAS,CACzB,IAAK,KAAK,OACR,MAAM,IAAI,MAAM,EAAgC,EAElD,KAAK,OAAO,KAAK,CAAC,EAAQ,EAAM,CAAO,CAAC,EAE1C,KAAK,CAAC,EAAQ,EAAM,CAClB,IAAK,KAAK,OACR,MAAM,IAAI,MAAM,aAAa,EAE/B,MAAQ,UAAS,UAAW,KACtB,EAAM,EAAQ,OACpB,IAAI,EAAI,EACJ,EACJ,KAAO,EAAI,EAAK,IAAK,CACnB,MAAM,EAAS,EAAQ,GACvB,GAAI,CACF,EAAO,QAAQ,CAAC,IAAS,CACvB,EAAO,IAAI,GAAG,CAAI,EACnB,EACD,EAAM,EAAO,MAAM,EAAQ,CAAI,QACxB,EAAP,CACA,GAAI,aAAa,GACf,SAEF,MAAM,EAER,KAAK,MAAQ,EAAO,MAAM,KAAK,CAAM,EACrC,KAAK,QAAU,CAAC,CAAM,EACtB,KAAK,OAAc,OACnB,MAEF,GAAI,IAAM,EACR,MAAM,IAAI,MAAM,aAAa,EAG/B,OADA,KAAK,KAAO,iBAAiB,KAAK,aAAa,OACxC,KAEL,aAAY,EAAG,CACjB,GAAI,KAAK,QAAU,KAAK,QAAQ,SAAW,EACzC,MAAM,IAAI,MAAM,2CAA2C,EAE7D,OAAO,KAAK,QAAQ,GAExBAClDA,IAAI,GAAO,KAAM,CACf,WAAW,CAAC,EAAQ,EAAS,EAAU,CAMrC,GALA,KAAK,MAAQ,EACb,KAAK,OAAS,CAAC,EACf,KAAK,SAAW,GAAY,CAAC,EAC7B,KAAK,QAAU,CAAC,EAChB,KAAK,KAAO,GACR,GAAU,EAAS,CACrB,MAAM,EAAI,CAAC,EACX,EAAE,GAAU,CAAE,UAAS,aAAc,CAAC,EAAG,MAAO,EAAG,KAAM,KAAK,IAAK,EACnE,KAAK,QAAU,CAAC,CAAC,EAEnB,KAAK,SAAW,CAAC,EAEnB,MAAM,CAAC,EAAQ,EAAM,EAAS,CAC5B,KAAK,KAAO,GAAG,KAAU,IACzB,KAAK,QAAU,KAAK,MACpB,IAAI,EAAU,KACd,MAAM,EAAQ,GAAiB,CAAI,EAC7B,EAAe,CAAC,EAChB,EAAiB,CAAC,EACxB,QAAS,EAAI,EAAG,EAAM,EAAM,OAAQ,EAAI,EAAK,IAAK,CAChD,MAAM,EAAI,EAAM,GAChB,GAAI,OAAO,KAAK,EAAQ,QAAQ,EAAE,SAAS,CAAC,EAAG,CAC7C,EAAe,KAAK,GAAG,EAAQ,QAAQ,EACvC,EAAU,EAAQ,SAAS,GAC3B,MAAM,EAAW,GAAW,CAAC,EAC7B,GAAI,EACF,EAAa,KAAK,EAAS,EAAE,EAC/B,SAEF,EAAQ,SAAS,GAAK,IAAI,GAC1B,MAAM,EAAU,GAAW,CAAC,EAC5B,GAAI,EACF,EAAQ,SAAS,KAAK,CAAO,EAC7B,EAAe,KAAK,GAAG,EAAQ,QAAQ,EACvC,EAAa,KAAK,EAAQ,EAAE,EAE9B,EAAe,KAAK,GAAG,EAAQ,QAAQ,EACvC,EAAU,EAAQ,SAAS,GAE7B,IAAK,EAAQ,QAAQ,OACnB,EAAQ,QAAU,CAAC,EAErB,MAAM,EAAI,CAAC,EACL,EAAa,CACjB,UACA,eACA,KAAM,KAAK,KACX,MAAO,KAAK,KACd,EAGA,OAFA,EAAE,GAAU,EACZ,EAAQ,QAAQ,KAAK,CAAC,EACf,EAET,MAAM,CAAC,EAAM,EAAQ,EAAQ,CAC3B,MAAM,EAAc,CAAC,EACrB,QAAS,EAAI,EAAG,EAAM,EAAK,QAAQ,OAAQ,EAAI,EAAK,IAAK,CACvD,MAAM,EAAI,EAAK,QAAQ,GACjB,EAAa,EAAE,IAAW,EAAE,GAClC,GAAI,IAAoB,OACtB,EAAW,OAAS,CAAC,EACrB,EAAW,aAAa,IAAI,CAAC,IAAQ,CACnC,EAAW,OAAO,GAAO,EAAO,GACjC,EACD,EAAY,KAAK,CAAU,EAG/B,OAAO,EAET,MAAM,CAAC,EAAQ,EAAM,CACnB,MAAM,EAAc,CAAC,EACf,EAAS,CAAC,EAChB,KAAK,OAAS,CAAC,EAEf,IAAI,EAAW,CADC,IACO,EACvB,MAAM,EAAQ,GAAU,CAAI,EAC5B,QAAS,EAAI,EAAG,EAAM,EAAM,OAAQ,EAAI,EAAK,IAAK,CAChD,MAAM,EAAO,EAAM,GACb,EAAS,IAAM,EAAM,EACrB,EAAY,CAAC,EACnB,QAAS,EAAI,EAAG,EAAO,EAAS,OAAQ,EAAI,EAAM,IAAK,CACrD,MAAM,EAAO,EAAS,GAChB,EAAW,EAAK,SAAS,GAC/B,GAAI,EAEF,GADA,EAAS,OAAS,EAAK,OACnB,IAAW,GAAM,CACnB,GAAI,EAAS,SAAS,KACpB,EAAY,KAAK,GAAG,KAAK,OAAO,EAAS,SAAS,KAAM,EAAQ,EAAK,MAAM,CAAC,EAE9E,EAAY,KAAK,GAAG,KAAK,OAAO,EAAU,EAAQ,EAAK,MAAM,CAAC,MAE9D,GAAU,KAAK,CAAQ,EAG3B,QAAS,EAAI,EAAG,EAAO,EAAK,SAAS,OAAQ,EAAI,EAAM,IAAK,CAC1D,MAAM,EAAU,EAAK,SAAS,GAC9B,GAAI,IAAY,IAAK,CACnB,MAAM,EAAU,EAAK,SAAS,KAC9B,GAAI,EACF,EAAY,KAAK,GAAG,KAAK,OAAO,EAAS,EAAQ,EAAK,MAAM,CAAC,EAC7D,EAAU,KAAK,CAAO,EAExB,SAEF,GAAI,IAAS,GACX,SACF,MAAO,EAAK,GAAM,GAAW,EACvB,EAAQ,EAAK,SAAS,GACtB,GAAiB,EAAM,MAAM,CAAC,EAAE,KAAK,GAAG,EAC9C,GAAI,aAAmB,QAAU,EAAQ,KAAK,EAAc,EAAG,CAC7D,EAAO,IAAQ,GACf,EAAY,KAAK,GAAG,KAAK,OAAO,EAAO,EAAQ,IAAK,KAAW,EAAK,MAAO,CAAC,CAAC,EAC7E,SAEF,GAAI,IAAY,IAAQ,aAAmB,QAAU,EAAQ,KAAK,CAAI,GACpE,UAAW,IAAQ,SAEjB,GADA,EAAO,IAAQ,EACX,IAAW,IAEb,GADA,EAAY,KAAK,GAAG,KAAK,OAAO,EAAO,EAAQ,IAAK,KAAW,EAAK,MAAO,CAAC,CAAC,EACzE,EAAM,SAAS,KACjB,EAAY,KACV,GAAG,KAAK,OAAO,EAAM,SAAS,KAAM,EAAQ,IAAK,KAAW,EAAK,MAAO,CAAC,CAC3E,MAGF,GAAM,OAAS,IAAK,CAAO,EAC3B,EAAU,KAAK,CAAK,IAM9B,EAAW,EAKb,MAAO,CAHS,EAAY,KAAK,CAAC,EAAG,IAAM,CACzC,OAAO,EAAE,MAAQ,EAAE,MACpB,EACe,IAAI,EAAG,UAAS,OAAQ,KAAc,CAAC,EAAS,CAAO,CAAC,CAAC,EAE7EAC5IA,IAAI,GAAa,KAAM,CACrB,WAAW,EAAG,CACZ,KAAK,KAAO,aACZ,KAAK,KAAO,IAAI,GAElB,GAAG,CAAC,EAAQ,EAAM,EAAS,CACzB,MAAM,EAAU,GAAuB,CAAI,EAC3C,GAAI,EAAS,CACX,QAAW,KAAK,EACd,KAAK,KAAK,OAAO,EAAQ,EAAG,CAAO,EAErC,OAEF,KAAK,KAAK,OAAO,EAAQ,EAAM,CAAO,EAExC,KAAK,CAAC,EAAQ,EAAM,CAClB,OAAO,KAAK,KAAK,OAAO,EAAQ,CAAI,EAExCAChBA,IAAI,GAAO,cAAc,EAAS,CAChC,WAAW,CAAC,EAAU,CAAC,EAAG,CACxB,MAAM,CAAO,EACb,KAAK,OAAS,EAAQ,QAAU,IAAI,GAAY,CAC9C,QAAS,CAAC,IAAI,GAAgB,IAAI,EAAY,CAChD,CAAC,EAELACXA,IAAI,GAAa,CAAC,EAAU,CAAE,MAAO,CAAE,IAAM,CAC3C,OAAO,eAAe,CAAW,CAAC,EAAG,EAAM,CACzC,MAAM,EAAS,EAAE,IAAI,MAAM,QAAQ,GAAK,EAAE,IAAI,MAAM,QAAQ,IAAM,GAAK,GAAO,GAE9E,GADA,MAAM,EAAK,EACP,GAAU,EAAE,IAAI,QAAQ,IAAI,cAAc,GAAG,WAAW,kBAAkB,EAAG,CAC/E,MAAM,EAAM,MAAM,EAAE,IAAI,KAAK,EAC7B,EAAE,IAAM,IAAI,SAAS,KAAK,UAAU,EAAK,KAAM,EAAQ,KAAK,EAAG,EAAE,GAAGACiB1E,IAAS,WAAQ,CAAC,EAAO,CACvB,OAAO,IAAU,MAAQ,IAAe,QAEjC,WAAO,CAAC,EAAK,CACpB,OAAO,EAAI,OAAO,EAAQ,GAEnB,WAAa,CAAC,EAAK,CAC1B,OAAO,OAAO,YAAY,OAAO,QAAQ,CAAG,EAAE,OAAO,GAAI,KAAW,GAAS,CAAK,CAAC,CAAC,GAE7E,WAAM,CAAC,EAAO,CACrB,GAAI,CACF,OAAO,aAAiB,WACjB,EAAP,CACA,MAAO,KAGF,UAAQ,CAAC,EAAO,CACvB,OAAO,QAAQ,CAAK,UAAY,IAAU,WAAa,MAAM,QAAQ,CAAK,KAAO,aAAiB,QAAU,GAAO,CAAK,GAEjH,UAAS,CAAC,EAAO,CACxB,OAAO,IAAU,MAAQ,IAAe,QAEjC,UAAQ,CAAC,EAAO,CACvB,OAAO,EAAU,CAAK,UAAY,IAAU,UAErC,WAAa,CAAC,EAAO,CAC5B,OAAO,EAAU,CAAK,GAAK,MAAM,QAAQ,CAAK,GAAK,EAAM,MAAM,CAAQ,GAEhE,WAAQ,CAAC,EAAO,CACvB,OAAO,EAAU,CAAK,UAAY,IAAU,UAErC,WAAW,CAAC,EAAO,CAC1B,GAAI,GAAS,CAAK,EAChB,OAAO,EAET,GAAI,EAAS,CAAK,EAAG,CACnB,MAAM,EAAS,OAAO,CAAK,EAC3B,IAAK,OAAO,MAAM,CAAM,EACtB,OAAO,EAGX,QAEO,WAAQ,CAAC,EAAO,CACvB,GAAI,CACF,OAAO,KAAK,CAAK,QACV,EAAP,CAEA,OADY,OACD,KAAK,CAAK,EAAE,SAAS,QAAQ,IAGnC,WAAS,CAAC,EAAG,EAAG,CACvB,MAAM,EAAS,IAAK,CAAE,EACtB,QAAY,EAAK,KAAU,OAAO,QAAQ,CAAC,EACzC,GAAI,EAAS,CAAK,GAAK,EAAS,EAAO,EAAI,EACzC,EAAO,GAAO,GAAU,EAAO,GAAM,CAAK,MAE1C,GAAO,GAAO,EAGlB,OAAO,GAEA,WAAK,CAAC,EAAO,EAAW,CAC/B,MAAM,EAAS,CAAC,EAChB,QAAS,EAAI,EAAG,EAAI,EAAM,OAAQ,GAAK,EACrC,EAAO,KAAK,EAAM,MAAM,EAAG,EAAI,CAAS,CAAC,EAE3C,OAAO,GAET,eAAe,EAAO,CAAC,EAAI,CACzB,OAAO,IAAI,QAAQ,CAAC,IAAY,WAAW,EAAS,CAAE,CAAC,EAEzD,IAAS,WAAiB,CAAC,EAAI,CAC7B,IAAI,EACJ,MAAM,EAAU,IAAI,QAAQ,CAAC,IAAY,CACvC,EAAY,WAAW,IAAM,CAC3B,EAAQ,GACP,CAAE,EACN,EACD,MAAO,CACL,OAAQ,IAAM,aAAa,CAAS,EACpC,SACF,GAEO,WAAU,CAAC,EAAa,EAAQ,CACvC,MAAM,EAAU,CAAC,EAAM,IAAe,EAAK,KACzC,CAAC,IAAQ,EAAO,CAAU,EAAE,KAAK,CAAC,IAAW,CAE3C,OADA,EAAI,KAAK,CAAM,EACR,EACR,CACH,EACA,OAAO,EAAY,OAAO,EAAS,QAAQ,QAAQ,CAAC,CAAC,CAAC,GAG/C,WAAc,EAAG,CACxB,GAAI,CACF,GAAI,EAAU,OAAO,GAAK,EAAU,QAAQ,GAAG,EAC7C,MAAO,CACL,OAAQ,QAAQ,IAAI,cAAgB,GAAgB,EACpD,YAAa,QAAQ,IAAI,mBAAqB,GAAqB,EACnE,OAAQ,QAAQ,IAAI,aAAe,GAAgB,EACnD,cAAe,QAAQ,IAAI,aAC3B,oBAAqB,QAAQ,IAAI,oBACjC,mBAAoB,QAAQ,IAAI,sBAChC,mBAAoB,QAAQ,IAAI,qBAClC,QAEK,EAAP,EAEF,GAAI,CACF,GAAI,EAAS,IAAI,GAAK,EAAS,KAAK,GAAG,EACrC,MAAO,CACL,OAAQ,KAAK,IAAI,IAAI,cAAc,GAAK,GAAgB,EACxD,YAAa,KAAK,IAAI,IAAI,mBAAmB,GAAK,GAAqB,EACvE,OAAQ,KAAK,IAAI,IAAI,aAAa,GAAK,GAAgB,EACvD,cAAe,KAAK,IAAI,IAAI,cAAc,EAC1C,oBAAqB,KAAK,IAAI,IAAI,qBAAqB,EACvD,mBAAoB,KAAK,IAAI,IAAI,uBAAuB,EACxD,mBAAoB,KAAK,IAAI,IAAI,uBAAuB,CAC1D,QAEK,EAAP,EAEF,MAAO,CACL,OAAQ,GAAgB,EACxB,YAAa,GAAqB,EAClC,OAAQ,GAAgB,EACxB,cAAoB,OACpB,oBAA0B,OAC1B,mBAAyB,OACzB,mBAAyB,MAC3B,GAEO,WAAwB,EAAG,CAClC,GAAI,CACF,GAAI,EAAS,OAAO,GAAK,EAAS,QAAQ,GAAG,GAAK,QAAQ,IAAI,sBAA6B,OACzF,OAAO,QAAQ,IAAI,sBAAwB,aAEtC,EAAP,EAEF,GAAI,CACF,GAAI,EAAS,IAAI,GAAK,EAAS,KAAK,GAAG,GAAK,KAAK,IAAI,IAAI,qBAAqB,IAAW,OACvF,OAAO,KAAK,IAAI,IAAI,qBAAqB,IAAM,aAE1C,EAAP,EAEF,GAAI,CACF,OAAO,sBAAwB,IAAQ,sBAAwB,aACxD,EAAP,CACA,SAGK,WAAe,EAAG,CACzB,GAAI,CACF,OAAO,mBACA,EAAP,CACA,SAGK,WAAoB,EAAG,CAC9B,GAAI,CACF,OAAO,wBACA,EAAP,CACA,SAGK,WAAe,EAAG,CACzB,GAAI,CACF,OAAO,kBACA,EAAP,CACA,SAGK,WAAc,EAAG,CACxB,GAAI,CACF,MAAQ,eAAgB,GAAe,EACvC,OAAO,QACA,EAAP,CACA,SAGK,WAAS,EAAG,CACnB,GAAI,CACF,MAAQ,UAAW,GAAe,EAClC,OAAO,QACA,EAAP,CACA,SAGK,WAAS,EAAG,CACnB,GAAI,CACF,MAAQ,UAAW,GAAe,EAClC,OAAO,QACA,EAAP,CACA,SAGK,WAAsB,EAAG,MAAK,UAAU,CAC/C,MAAO,WAAW,KAAO,KAElB,WAAgB,EAAG,CAC1B,GAAI,CACF,MAAQ,gBAAe,sBAAqB,qBAAoB,sBAAuB,GAAe,EACtG,GAAI,EACF,OAAO,EACT,OAAQ,OACD,SAAU,CACb,IAAK,IAAuB,EAAoB,CAC9C,QAAQ,KAAK,qFAAqF,EAClG,OAEF,OAAO,GAAuB,CAAE,IAAK,EAAoB,OAAQ,CAAmB,CAAC,CACvF,EAEF,aACO,EAAP,CACA,SA4BK,WAAsB,CAAC,EAAW,CACzC,MAAM,SAAqB,QAAU,YAAc,MAAa,OAC1D,SAAyB,aAAe,YAAc,WAAW,MAAa,OAC9E,EAAY,GAAa,GAAe,EAC9C,IAAK,EACH,MAAM,IAAI,MAAM,2EAA2E,EAE7F,OAAO,GAyEA,WAAY,EAAG,CACtB,MAAO,uCAAuC,QAAQ,gBAAiB,CAAC,EAAG,CACzE,MAAM,EAAI,KAAK,OAAO,EAAI,GAAK,EAC/B,OADsC,GAAK,IAAM,EAAI,EAAI,EAAI,GACpD,SAAS,EAAE,EACrB,GAGH,eAAe,EAAQ,CAAC,EAAQ,EAAS,CACvC,MAAM,EAAS,EAAO,UAAU,EAChC,IAAI,EACJ,QAAS,EAAS,MAAM,EAAO,KAAK,GAAG,KACrC,EAAQ,EAAO,KAAK,EAGxB,IAAS,WAAQ,CAAC,EAAQ,CACxB,IAAI,EACA,EACA,EACA,EAAyB,GAC7B,gBAAgB,CAAO,CAAC,EAAK,CAC3B,GAAI,IAAgB,OAClB,EAAS,EACT,EAAW,EACX,GAAc,MAEd,GAAS,GAAO,EAAQ,CAAG,EAE7B,MAAM,EAAY,EAAO,OACzB,IAAI,EAAY,EAChB,MAAO,EAAW,EAAW,CAC3B,GAAI,EAAwB,CAC1B,GAAI,EAAO,KAAc,GACvB,IAAc,EAEhB,EAAyB,GAE3B,IAAI,GAAU,EACd,KAAO,EAAW,GAAa,KAAY,IAAM,EAC/C,OAAQ,EAAO,SACR,GACH,GAAI,KAAgB,EAClB,EAAc,EAAW,EAE3B,WACG,GACH,EAAyB,QACtB,GACH,EAAU,EACV,MAGN,GAAI,KAAY,EACd,MAEF,EAAO,EAAO,SAAS,EAAW,CAAO,EAAG,CAAW,EACvD,EAAY,EACZ,GAAc,EAEhB,GAAI,IAAc,EAChB,EAAc,eACL,IAAc,EACvB,EAAS,EAAO,SAAS,CAAS,EAClC,GAAY,IAIT,WAAW,CAAC,EAAM,EAAS,EAAW,CAC7C,IAAI,EAAU,GAAW,EACzB,MAAM,EAAU,IAAI,YACpB,gBAAgB,CAAM,CAAC,EAAM,EAAa,CACxC,GAAI,EAAK,SAAW,EAClB,IAAY,CAAO,EACnB,EAAU,GAAW,UACZ,EAAc,EAAG,CAC1B,MAAM,EAAQ,EAAQ,OAAO,EAAK,SAAS,EAAG,CAAW,CAAC,EACpD,EAAc,GAAe,EAAK,EAAc,KAAO,GAAiB,EAAI,GAC5E,EAAQ,EAAQ,OAAO,EAAK,SAAS,CAAW,CAAC,EACvD,OAAQ,OACD,OACH,EAAQ,KAAO,EAAQ,KAAO,EAAQ,KAAO,KAAO,EAAQ,EAC5D,UACG,QACH,EAAQ,MAAQ,EAChB,UACG,KACH,EAAK,EAAQ,GAAK,CAAK,EACvB,UACG,QACH,MAAM,EAAQ,SAAS,EAAO,EAAE,EAChC,IAAK,MAAM,CAAK,EACd,EAAQ,EAAQ,MAAQ,CAAK,EAE/B,UAKD,WAAM,CAAC,EAAG,EAAG,CACpB,MAAM,EAAM,IAAI,WAAW,EAAE,OAAS,EAAE,MAAM,EAG9C,OAFA,EAAI,IAAI,CAAC,EACT,EAAI,IAAI,EAAG,EAAE,MAAM,EACZ,GAEA,WAAU,EAAG,CACpB,MAAO,CACL,KAAM,GACN,MAAO,GACP,GAAI,GACJ,MAAY,MACd,GAIO,WAAgB,CAAC,GACxB,OAAQ,EACR,QAAS,EACT,OAAQ,EACR,YACA,UACA,UACA,MAAO,KACJ,GACF,CACD,OAAO,IAAI,QAAQ,CAAC,EAAS,IAAW,CACtC,MAAM,EAAU,IAAK,CAAa,EAClC,IAAK,EAAQ,OACX,EAAQ,OAAS,GAEnB,IAAI,EACJ,SAAS,CAAO,EAAG,CACjB,EAAqB,MAAM,EAE7B,GAAa,iBAAiB,QAAS,IAAM,CAC3C,EAAQ,EACR,EAAQ,EACT,EACD,MAAM,EAAY,GAAc,MAC1B,EAAS,GAAe,GAC9B,eAAe,CAAM,EAAG,CACtB,EAAuB,IAAI,gBAC3B,GAAI,CACF,MAAM,EAAW,MAAM,EAAU,EAAO,IACnC,EACH,UACA,OAAQ,EAAqB,MAC/B,CAAC,EACD,MAAM,EAAO,CAAQ,EACrB,MAAM,GACJ,EAAS,KACT,GACE,GACE,CAAC,IAAO,CACN,GAAI,EACF,EAAQ,IAAe,MAEvB,QAAO,EAAQ,KAGnB,CAAC,IAAW,GAEZ,CACF,CACF,CACF,EACA,IAAU,EACV,EAAQ,EACR,EAAQ,QACD,EAAP,GAGJ,EAAO,EACR,GAEM,WAAa,CAAC,EAAU,CAC/B,MAAM,EAAc,EAAS,SAAS,IAAI,cAAc,EACxD,IAAK,GAAa,WAAW,EAAsB,EACjD,MAAM,IAAI,MAAM,+BAA+B,eAAmC,GAAa,GA2B1F,WAAW,CAAC,EAAO,CAC1B,OAAO,EAAS,CAAK,GAAK,MAAM,QAAQ,EAAM,MAAM,GAE7C,WAAkB,CAAC,EAAO,CACjC,OAAO,EAAS,CAAK,GAAK,EAAS,EAAM,OAAO,GAEzC,WAAU,CAAC,EAAM,CACxB,GAAI,aAAgB,MAClB,OAAO,EAAK,gBACH,EAAS,CAAI,EACtB,OAAO,UACE,GAAmB,CAAI,EAChC,OAAO,EAAK,gBACH,GAAY,CAAI,EACzB,MAAO,4BAEP,OAAOAC/iBX,IAAM,GAAS,CACb,CACE,KAAM,OACN,QAAS,CACP,CAAE,KAAM,YAAa,KAAM,MAAO,EAClC,CAAE,KAAM,WAAY,KAAM,MAAO,EACjC,CAAE,KAAM,WAAY,KAAM,QAAS,EACnC,CAAE,KAAM,QAAS,KAAM,QAAS,OAAQ,EAAK,EAC7C,CAAE,KAAM,WAAY,KAAM,SAAU,OAAQ,EAAK,CACnD,CACF,CACF,EAYM,GAAiB,GAAY,EAE7B,GAAiB,CACrB,YACE,iEACJ,EAEO,MAAM,WAAmB,EAA+B,CAC7D,WAAW,CAAC,EAA6B,CACvC,MAAM,IAAK,MAAmB,CAAQ,EAAG,EAAM,EAEnD,CAEA,IAAI,GAAmC,OAE1B,GAAgB,IAAM,CACjC,GAAI,GAAU,OAAO,GAGrB,OADA,GAAW,IAAI,GACRAC/CT,IAAM,GAAM,IAAI,GACV,GAAO,GAAc,EACrB,GAAQ,GAAK,GAAG,KAAK,OAAO,EAClC,QAAQ,IAAI,EAAK,EACjB,GAAI,IAAI,IAAK,MAAO,IAAM,EAAE,KAAK,MAAM,EAAK,CAAC,EAC7C,GAAI,IAAI,OAAQ,CAAC,IAAM,EAAE,KAAK,OAAO,EAAE,IAAI,MAAM,IAAI,GAAG,CAAC,EACzD,IAAeACNf,IAAM,GAAO,IAAI,GAAK,EAAE,SAAS,MAAM,EACvC,GAAK,IAAI,IAAK,GAAW,CAAC,EAC1B,IAAM,GAAQ,GAAK,MAAM,SAAS,EAAK,EAEvC,QAAQ,IAAI,GAAK,GAAG,EAEpB,IAAe,IACX,KAAM,KACN,MAAO,GAAK,KACd",
  "debugId": "706A686246B9E15864756e2164756e21",
  "names": []
}